"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Abstract","Author Keywords","Index Keywords","Document Type","Publication Stage","Open Access","Source","EID"
"ERLICH O.; BORICH G.","ERLICH, ODED (6506667871); BORICH, GARY (16502419400)","6506667871; 16502419400","OCCURRENCE AND GENERALIZABILITY OF SCORES ON A CLASSROOM INTERACTION INSTRUMENT","1979","Journal of Educational Measurement","16","1","","11","18","7","15","10.1111/j.1745-3984.1979.tb00081.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973705922&doi=10.1111%2fj.1745-3984.1979.tb00081.x&partnerID=40&md5=52460f21e6b4860cbe24ffaa89ecb2be","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973705922"
"SHANI E.; PETROSKO J.M.","SHANI, ESTHER (57195040401); PETROSKO, JOSEPH M. (14067552800)","57195040401; 14067552800","STRUCTURAL COMPONENTS DERIVED FROM EVALUATING STANDARDIZED TESTS","1976","Journal of Educational Measurement","13","4","","283","296","13","0","10.1111/j.1745-3984.1976.tb00019.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024946956&doi=10.1111%2fj.1745-3984.1976.tb00019.x&partnerID=40&md5=581a0f54fbdb67779307c460058862f9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024946956"
"ROWLEY G.L.; TRAUB R.E.","ROWLEY, GLENN L. (7006131497); TRAUB, ROSS E. (7102034665)","7006131497; 7102034665","FORMULA SCORING, NUMBER‐RIGHT SCORING, AND TEST‐TAKING STRATEGY","1977","Journal of Educational Measurement","14","1","","15","22","7","43","10.1111/j.1745-3984.1977.tb00024.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002338889&doi=10.1111%2fj.1745-3984.1977.tb00024.x&partnerID=40&md5=a5114bd1fa4078e349917bb34249c261","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0002338889"
"ALGINA J.; NOE M.J.","ALGINA, JAMES (7003768166); NOE, MICHAEL J. (7006269965)","7003768166; 7006269965","A STUDY OF THE ACCURACY OF SUBKOVIAK'S SINGLE‐ADMINISTRATION ESTIMATE OF THE COEFFICIENT OF AGREEMENT USING TWO TRUE‐SCORE ESTIMATES","1978","Journal of Educational Measurement","15","2","","101","110","9","11","10.1111/j.1745-3984.1978.tb00061.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970135707&doi=10.1111%2fj.1745-3984.1978.tb00061.x&partnerID=40&md5=71322d202b810c578ef902edfec60eda","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84970135707"
"SCHWARTZ S.A.","SCHWARTZ, STEVEN A. (57195042460)","57195042460","A COMPREHENSIVE SYSTEM FOR ITEM ANALYSIS IN PSYCHOLOGICAL SCALE CONSTRUCTION","1978","Journal of Educational Measurement","15","2","","117","123","6","2","10.1111/j.1745-3984.1978.tb00063.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930461217&doi=10.1111%2fj.1745-3984.1978.tb00063.x&partnerID=40&md5=fa00d779344c7d96a0a6bc0e5efbdcc9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84930461217"
"WHITELY S.E.","WHITELY, SUSAN E. (16493742700)","16493742700","MODELS, MEANINGS AND MISUNDERSTANDINGS: SOME ISSUES IN APPLYING RASCH'S THEORY","1977","Journal of Educational Measurement","14","3","","227","235","8","14","10.1111/j.1745-3984.1977.tb00040.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954605089&doi=10.1111%2fj.1745-3984.1977.tb00040.x&partnerID=40&md5=2888a14b563a3574da46624667ad4bd6","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-77954605089"
"CATTELL R.B.; HORN J.L.","CATTELL, RAYMOND B. (7006243977); HORN, JOHN L. (7203079849)","7006243977; 7203079849","A CHECK ON THE THEORY OF FLUID AND CRYSTALLIZED INTELLIGENCE WITH DESCRIPTION OF NEW SUBTEST DESIGNS","1978","Journal of Educational Measurement","15","3","","139","164","25","188","10.1111/j.1745-3984.1978.tb00065.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971745630&doi=10.1111%2fj.1745-3984.1978.tb00065.x&partnerID=40&md5=11e7113da897f26eab2799b5b4cb115d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84971745630"
"SLINDE J.A.; LINN R.L.","SLINDE, JEFFREY A. (6507638009); LINN, ROBERT L. (56126633100)","6507638009; 56126633100","A NOTE ON VERTICAL EQUATING VIA THE RASCH MODEL FOR GROUPS OF QUITE DIFFERENT ABILITY AND TESTS OF QUITE DIFFERENT DIFFICULTY","1979","Journal of Educational Measurement","16","3","","159","165","6","26","10.1111/j.1745-3984.1979.tb00097.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970351802&doi=10.1111%2fj.1745-3984.1979.tb00097.x&partnerID=40&md5=877451ad547d4baa28b2fe5ebcc445f3","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84970351802"
"GOLDMAN R.D.; HEWITT B.N.","GOLDMAN, ROY D. (7402001118); HEWITT, BARBARA NEWLIN (14833726300)","7402001118; 14833726300","PREDICTING THE SUCCESS OF BLACK, CHICANO, ORIENTAL AND WHITE COLLEGE STUDENTS","1976","Journal of Educational Measurement","13","2","","107","117","10","52","10.1111/j.1745-3984.1976.tb00002.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84971724257&doi=10.1111%2fj.1745-3984.1976.tb00002.x&partnerID=40&md5=d8399d00348c5095849ab8065afe17f8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84971724257"
"BLOCK J.H.","BLOCK, JAMES H. (25953851700)","25953851700","STANDARDS AND CRITERIA: A RESPONSE","1978","Journal of Educational Measurement","15","4","","291","295","4","9","10.1111/j.1745-3984.1978.tb00076.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005371123&doi=10.1111%2fj.1745-3984.1978.tb00076.x&partnerID=40&md5=cec4f3794184d2c9f9cefaf5fe37568b","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85005371123"
"HOWARD G.S.; SCHMECK R.R.; BRAY J.H.","HOWARD, GEORGE S. (7202022063); SCHMECK, RONALD R. (6602624129); BRAY, JAMES H. (7102443229)","7202022063; 6602624129; 7102443229","INTERNAL INVALIDITY IN STUDIES EMPLOYING SELF‐REPORT INSTRUMENTS: A SUGGESTED REMEDY","1979","Journal of Educational Measurement","16","2","","129","135","6","103","10.1111/j.1745-3984.1979.tb00094.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000587084&doi=10.1111%2fj.1745-3984.1979.tb00094.x&partnerID=40&md5=eef379204d24e63b760272f6cfc2cdb0","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0000587084"
"GILLMORE G.M.; KANE M.T.; NACCARATO R.W.","GILLMORE, GERALD M. (6701577870); KANE, MICHAEL T. (36088969800); NACCARATO, RICHARD W. (57195042498)","6701577870; 36088969800; 57195042498","THE GENERALIZABILITY OF STUDENT RATINGS OF INSTRUCTION: ESTIMATION OF THE TEACHER AND COURSE COMPONENTS","1978","Journal of Educational Measurement","15","1","","1","13","12","71","10.1111/j.1745-3984.1978.tb00051.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994932183&doi=10.1111%2fj.1745-3984.1978.tb00051.x&partnerID=40&md5=4b33a9d407e7daed272add383a584d13","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84994932183"
"HARTKE A.R.","HARTKE, ALAN R. (57189188684)","57189188684","THE USE OF LATENT PARTITION ANALYSIS TO IDENTIFY HOMOGENEITY OF AN ITEM POPULATION","1978","Journal of Educational Measurement","15","1","","43","47","4","5","10.1111/j.1745-3984.1978.tb00055.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987226512&doi=10.1111%2fj.1745-3984.1978.tb00055.x&partnerID=40&md5=c05d0d3536ebf10f961a75831559cd17","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987226512"
"AMBROSINO R.J.; MCMORRIS R.F.; NOVAL L.K.","AMBROSINO, ROBERT J. (6602932389); MCMORRIS, ROBERT F. (6603270899); NOVAL, LORRAINE K. (57189185896)","6602932389; 6603270899; 57189185896","PARTITIONING METHODS FOR DETECTING MISCONCEPTIONS OF CONTENT AND TEST ITEMS","1979","Journal of Educational Measurement","16","3","","187","195","8","1","10.1111/j.1745-3984.1979.tb00100.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024961687&doi=10.1111%2fj.1745-3984.1979.tb00100.x&partnerID=40&md5=62f5f80cbc90d8e738fb22f0b6a8e7d9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024961687"
"SLINDE J.A.; LINN R.L.","SLINDE, JEFFREY A. (6507638009); LINN, ROBERT L. (56126633100)","6507638009; 56126633100","VERTICALLY EQUATED TESTS: FACT OR PHANTOM?","1977","Journal of Educational Measurement","14","1","","23","32","9","28","10.1111/j.1745-3984.1977.tb00025.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988097889&doi=10.1111%2fj.1745-3984.1977.tb00025.x&partnerID=40&md5=655d68b2575893bd9969d3d954763147","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988097889"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","OPTIMAL NUMBER OF CHOICES PER ITEM— A COMPARISON OF FOUR APPROACHES","1977","Journal of Educational Measurement","14","1","","33","38","5","63","10.1111/j.1745-3984.1977.tb00026.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003076945&doi=10.1111%2fj.1745-3984.1977.tb00026.x&partnerID=40&md5=2c4814526702f1dae40892d69c45fc3f","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0003076945"
"HALADYNA T.; THOMAS G.","HALADYNA, TOM (6602737797); THOMAS, GREGORY (57032746100)","6602737797; 57032746100","THE AFFECTIVE REPORTING SYSTEM","1979","Journal of Educational Measurement","16","1","","49","54","5","6","10.1111/j.1745-3984.1979.tb00086.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-68049092665&doi=10.1111%2fj.1745-3984.1979.tb00086.x&partnerID=40&md5=39b3bd1aab62902a08dc458572be931d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-68049092665"
"MARCO G.L.","MARCO, GARY L. (57065132200)","57065132200","ITEM CHARACTERISTIC CURVE SOLUTIONS TO THREE INTRACTABLE TESTING PROBLEMS","1977","Journal of Educational Measurement","14","2","","139","160","21","159","10.1111/j.1745-3984.1977.tb00033.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000208012&doi=10.1111%2fj.1745-3984.1977.tb00033.x&partnerID=40&md5=7be0caff44276df8d100c5e6843446c8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0000208012"
"KANE M.T.; GILLMORE G.M.; CROOKS T.J.","KANE, MICHAEL T. (36088969800); GILLMORE, GERALD M. (6701577870); CROOKS, TERENCE J. (6602188516)","36088969800; 6701577870; 6602188516","STUDENT EVALUATIONS OF TEACHING: THE GENERALIZABILITY OF CLASS MEANS","1976","Journal of Educational Measurement","13","3","","171","183","12","59","10.1111/j.1745-3984.1976.tb00009.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973772933&doi=10.1111%2fj.1745-3984.1976.tb00009.x&partnerID=40&md5=e921583ecfab540cef625368b6f3f7bf","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973772933"
"RESCHLY D.J.; SABERS D.L.","RESCHLY, DANIEL J. (6603752181); SABERS, DARRELL L. (6701710722)","6603752181; 6701710722","ANALYSIS OF TEST BIAS IN FOUR GROUPS WITH THE REGRESSION DEFINITION","1979","Journal of Educational Measurement","16","1","","1","9","8","30","10.1111/j.1745-3984.1979.tb00080.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002542999&doi=10.1111%2fj.1745-3984.1979.tb00080.x&partnerID=40&md5=de6a7c1a83ff096a0b34dc4e5b514fdb","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0002542999"
"OOSTERHOF A.C.","OOSTERHOF, ALBERT C. (55599016200)","55599016200","SIMILARITY OF VARIOUS ITEM DISCRIMINATION INDICES","1976","Journal of Educational Measurement","13","2","","145","150","5","20","10.1111/j.1745-3984.1976.tb00005.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973835914&doi=10.1111%2fj.1745-3984.1976.tb00005.x&partnerID=40&md5=c73182786c92fa07e9fdcf259522e07d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973835914"
"HUMPHREYS L.G.; STUBBS J.","HUMPHREYS, LLOYD G. (56238275200); STUBBS, JUNE (57195042058)","56238275200; 57195042058","A LONGITUDINAL ANALYSIS OF TEACHER EXPECTATION, STUDENT EXPECTATION, AND STUDENT ACHIEVEMENT","1977","Journal of Educational Measurement","14","3","","261","270","9","12","10.1111/j.1745-3984.1977.tb00043.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346500354&doi=10.1111%2fj.1745-3984.1977.tb00043.x&partnerID=40&md5=3436c6dd5602abf556e57c0f802de2bd","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0346500354"
"LEWIS W.A.; DEXTER H.G.; SMITH W.C.","LEWIS, WILLIAM A. (35525954600); DEXTER, H. GENE (57195042048); SMITH, WILLIAM C. (57213781495)","35525954600; 57195042048; 57213781495","GRADING PROCEDURES AND TEST VALIDATION: A PROPOSED NEW APPROACH","1978","Journal of Educational Measurement","15","3","","219","227","8","2","10.1111/j.1745-3984.1978.tb00071.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965588444&doi=10.1111%2fj.1745-3984.1978.tb00071.x&partnerID=40&md5=f48708c626e7f78c7ccb2324a024309e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965588444"
"WRIGHT B.D.","WRIGHT, BENJAMIN D. (7402346612)","7402346612","MISUNDERSTANDING THE RASCH MODEL","1977","Journal of Educational Measurement","14","3","","219","225","6","44","10.1111/j.1745-3984.1977.tb00039.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991440035&doi=10.1111%2fj.1745-3984.1977.tb00039.x&partnerID=40&md5=560cd69ac61aa1b5afdf2728893faa13","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84991440035"
"OLSON M.A.","OLSON, MARGOT A. (25030907500)","25030907500","AN APPLICATION OF MATRIX SAMPLING TO THE METHOD OF PAIR COMPARISONS","1978","Journal of Educational Measurement","15","1","","49","52","3","7","10.1111/j.1745-3984.1978.tb00056.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84914774346&doi=10.1111%2fj.1745-3984.1978.tb00056.x&partnerID=40&md5=ef08ffd5c0fa9164e3ce2aeece6c55b8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84914774346"
"SCHMEISER C.B.; FERGUSON R.L.","SCHMEISER, CYNTHIA B. (55607334700); FERGUSON, RICHARD L. (57189188682)","55607334700; 57189188682","PERFORMANCE OF BLACK AND WHITE STUDENTS ON TEST MATERIALS CONTAINING CONTENT BASED ON BLACK AND WHITE CULTURES","1978","Journal of Educational Measurement","15","3","","193","200","7","12","10.1111/j.1745-3984.1978.tb00068.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988098573&doi=10.1111%2fj.1745-3984.1978.tb00068.x&partnerID=40&md5=0496dd2f2d47afe8506720ae6fe3a3f2","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988098573"
"STRANG H.R.","STRANG, HAROLD R. (6603236345)","6603236345","THE EFFECTS OF TECHNICAL AND UNFAMILIAR OPTIONS ON GUESSING ON MULTIPLE‐CHOICE TEST ITEMS","1977","Journal of Educational Measurement","14","3","","253","260","7","5","10.1111/j.1745-3984.1977.tb00042.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966052034&doi=10.1111%2fj.1745-3984.1977.tb00042.x&partnerID=40&md5=29bae0a8f7ba8d62a360dd709959e3ad","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84966052034"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","PRACTICAL APPLICATIONS OF ITEM CHARACTERISTIC CURVE THEORY","1977","Journal of Educational Measurement","14","2","","117","138","21","114","10.1111/j.1745-3984.1977.tb00032.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040590134&doi=10.1111%2fj.1745-3984.1977.tb00032.x&partnerID=40&md5=7e3c96121d342814dc17991fe79355a7","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0040590134"
"SMITH M., III; WHITE K.P.; COOP R.H.","SMITH, MALBERT (56410183300); WHITE, KINNARD P. (56207164200); COOP, RICHARD H. (25953855900)","56410183300; 56207164200; 25953855900","THE EFFECT OF ITEM TYPE ON THE CONSEQUENCES OF CHANGING ANSWERS ON MULTIPLE CHOICE TESTS","1979","Journal of Educational Measurement","16","3","","203","208","5","19","10.1111/j.1745-3984.1979.tb00102.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017259026&doi=10.1111%2fj.1745-3984.1979.tb00102.x&partnerID=40&md5=4ef79bf0525822a502c3f0b1b0533aa2","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85017259026"
"ROGERS W.T.; FOLSOM R.E., JR.; KALSBEEK W.D.; CLEMMER A.F.","ROGERS, W. TODD (7402345065); FOLSOM, RALPH E. (7003688226); KALSBEEK, WILLIAM D. (7003554261); CLEMMER, ANNE F. (57195043689)","7402345065; 7003688226; 7003554261; 57195043689","ASSESSMENT OF NONRESPONSE BIAS IN SAMPLE SURVEYS. AN EXAMPLE FROM NATIONAL ASSESSMENT","1977","Journal of Educational Measurement","14","4","","297","311","14","3","10.1111/j.1745-3984.1977.tb00046.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983938840&doi=10.1111%2fj.1745-3984.1977.tb00046.x&partnerID=40&md5=07df62de61dfd39a484d5f1bfb947eef","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84983938840"
"LINN M.C.; RICE M.","LINN, MARCIA C. (7006538185); RICE, MARIAN (57190903282)","7006538185; 57190903282","A MEASURE OF SCIENTIFIC REASONING: THE SPRINGS TASK","1979","Journal of Educational Measurement","16","1","","55","58","3","12","10.1111/j.1745-3984.1979.tb00087.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960677036&doi=10.1111%2fj.1745-3984.1979.tb00087.x&partnerID=40&md5=4c0e61d91d8517f845fd66ddaa3f015c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84960677036"
"POPHAM W.J.","POPHAM, W. JAMES (6701761956)","6701761956","AS ALWAYS, PROVOCATIVE","1978","Journal of Educational Measurement","15","4","","297","300","3","36","10.1111/j.1745-3984.1978.tb00077.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0347337263&doi=10.1111%2fj.1745-3984.1978.tb00077.x&partnerID=40&md5=b8374f8174e134e37045e924ac63a1e5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0347337263"
"BRELAND H.M.; GAYNOR J.L.","BRELAND, HUNTER M. (6506538277); GAYNOR, JUDITH L. (57195040255)","6506538277; 57195040255","A COMPARISON OF DIRECT AND INDIRECT ASSESSMENTS OF WRITING SKILL","1979","Journal of Educational Measurement","16","2","","119","128","9","47","10.1111/j.1745-3984.1979.tb00093.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973852466&doi=10.1111%2fj.1745-3984.1979.tb00093.x&partnerID=40&md5=1a3428c3e8f7189eda9a85e24ae5f06b","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973852466"
"LEVIN H.M.","LEVIN, HENRY M. (57209708561)","57209708561","EDUCATIONAL PERFORMANCE STANDARDS: IMAGE OR SUBSTANCE?","1978","Journal of Educational Measurement","15","4","","309","319","10","10","10.1111/j.1745-3984.1978.tb00079.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973774407&doi=10.1111%2fj.1745-3984.1978.tb00079.x&partnerID=40&md5=a6b2efdd6695edaf0ff52288a0261d4a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973774407"
"SUBKOVIAK M.J.","SUBKOVIAK, MICHAEL J. (6506489478)","6506489478","EMPIRICAL INVESTIGATION OF PROCEDURES FOR ESTIMATING RELIABILITY FOR MASTERY TESTS","1978","Journal of Educational Measurement","15","2","","111","116","5","25","10.1111/j.1745-3984.1978.tb00062.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988089275&doi=10.1111%2fj.1745-3984.1978.tb00062.x&partnerID=40&md5=8425eb9caa038ae8d301287fe82e09d8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988089275"
"WOOD R.","WOOD, ROBERT (56936262800)","56936262800","INHIBITING BLIND GUESSING: THE EFFECT OF INSTRUCTIONS","1976","Journal of Educational Measurement","13","4","","297","307","10","7","10.1111/j.1745-3984.1976.tb00020.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988078978&doi=10.1111%2fj.1745-3984.1976.tb00020.x&partnerID=40&md5=ce2043acbaa5832660be57ca57e5f7be","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988078978"
"GLASS G.V.","GLASS, GENE V (10939588000)","10939588000","STANDARDS AND CRITERIA","1978","Journal of Educational Measurement","15","4","","237","261","24","193","10.1111/j.1745-3984.1978.tb00072.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963348047&doi=10.1111%2fj.1745-3984.1978.tb00072.x&partnerID=40&md5=d5920ebd228016e7b641b8e03c1aaf01","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84963348047"
"ERLICH O.; SHAVELSON R.J.","ERLICH, ODED (6506667871); SHAVELSON, RICHARD J. (35613093400)","6506667871; 35613093400","THE SEARCH FOR CORRELATIONS BETWEEN MEASURES OF TEACHER BEHAVIOR AND STUDENT ACHIEVEMENT: MEASUREMENT PROBLEM, CONCEPTUALIZATION PROBLEM, OR BOTH?","1978","Journal of Educational Measurement","15","2","","77","89","12","23","10.1111/j.1745-3984.1978.tb00059.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973786069&doi=10.1111%2fj.1745-3984.1978.tb00059.x&partnerID=40&md5=2f897e3fa7310f497ec55e4b658a4b2d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973786069"
"URRY V.W.","URRY, VERN W. (25953701700)","25953701700","TAILORED TESTING: A SUCCESSFUL APPLICATION OF LATENT TRAIT THEORY","1977","Journal of Educational Measurement","14","2","","181","196","15","62","10.1111/j.1745-3984.1977.tb00035.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973082107&doi=10.1111%2fj.1745-3984.1977.tb00035.x&partnerID=40&md5=682c4e5e597f896c2d72032993cd2e20","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973082107"
"CHASE C.I.","CHASE, CLINTON I. (7102500238)","7102500238","THE IMPACT OF ACHIEVEMENT EXPECTATIONS AND HANDWRITING QUALITY ON SCORING ESSAY TESTS","1979","Journal of Educational Measurement","16","1","","39","42","3","18","10.1111/j.1745-3984.1979.tb00084.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-38749136388&doi=10.1111%2fj.1745-3984.1979.tb00084.x&partnerID=40&md5=6dc5e77a876ade6b6677e264240210c0","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-38749136388"
"REMER R.","REMER, RORY (6603023365)","6603023365","THREE MODES OF STIMULUS PRESENTATION IN A SIMULATION TEST OF INTERPERSONAL COMMUNICATION COMPETENCE","1978","Journal of Educational Measurement","15","2","","125","130","5","4","10.1111/j.1745-3984.1978.tb00064.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925916564&doi=10.1111%2fj.1745-3984.1978.tb00064.x&partnerID=40&md5=96733fb7d9038a5c2d3b484833fff4b8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84925916564"
"IRONSON G.H.; SUBKOVIAK M.J.","IRONSON, GAIL H. (7006098861); SUBKOVIAK, MICHAEL J. (6506489478)","7006098861; 6506489478","A COMPARISON OF SEVERAL METHODS OF ASSESSING ITEM BIAS","1979","Journal of Educational Measurement","16","4","","209","225","16","55","10.1111/j.1745-3984.1979.tb00103.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988070444&doi=10.1111%2fj.1745-3984.1979.tb00103.x&partnerID=40&md5=dc681f41dfeb5d1fba460f863866ef12","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988070444"
"LOMAX R.G.; ALGINA J.","LOMAX, RICHARD G. (7005102434); ALGINA, JAMES (7003768166)","7005102434; 7003768166","COMPARISON OF TWO PROCEDURES FOR ANALYZING MULTITRAIT MULTIMETHOD MATRICES","1979","Journal of Educational Measurement","16","3","","177","186","9","10","10.1111/j.1745-3984.1979.tb00099.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953095205&doi=10.1111%2fj.1745-3984.1979.tb00099.x&partnerID=40&md5=dd12f2dbd617fd92b72cc542429342bb","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84953095205"
"PREDIGER D.J.; HANSON G.R.","PREDIGER, DALE J. (6602111339); HANSON, GARY R. (23030885800)","6602111339; 23030885800","SOME CONSEQUENCES OF USING RAW‐SCORE REPORTS OF VOCATIONAL INTERESTS","1977","Journal of Educational Measurement","14","4","","323","333","10","8","10.1111/j.1745-3984.1977.tb00048.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79958082085&doi=10.1111%2fj.1745-3984.1977.tb00048.x&partnerID=40&md5=dfd1c30063dbad2af54377ddc892dc48","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-79958082085"
"HAMBLETON R.K.; COOK L.L.","HAMBLETON, RONALD K. (7006242264); COOK, LINDA L. (57220707796)","7006242264; 57220707796","LATENT TRAIT MODELS AND THEIR USE IN THE ANALYSIS OF EDUCATIONAL TEST DATA","1977","Journal of Educational Measurement","14","2","","75","96","21","98","10.1111/j.1745-3984.1977.tb00030.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973723789&doi=10.1111%2fj.1745-3984.1977.tb00030.x&partnerID=40&md5=baaee805c32c6c7f935aba85f03a8abd","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973723789"
"FRISBIE D.A.; BRANDENBURG D.C.","FRISBIE, DAVID A. (7003704007); BRANDENBURG, DALE C. (16462293700)","7003704007; 16462293700","EQUIVALENCE OF QUESTIONNAIRE ITEMS WITH VARYING RESPONSE FORMATS","1979","Journal of Educational Measurement","16","1","","43","48","5","23","10.1111/j.1745-3984.1979.tb00085.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0007918921&doi=10.1111%2fj.1745-3984.1979.tb00085.x&partnerID=40&md5=caec2044e03978e59222a3201308d45f","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0007918921"
"DIAMOND J.J.; AYRER J.; FISHMAN R.; GREEN P.","DIAMOND, JAMES J. (57018442400); AYRER, JAMES (57195042854); FISHMAN, ROGER (57191935430); GREEN, PAUL (57195041041)","57018442400; 57195042854; 57191935430; 57195041041","ARE INNER CITY CHILDREN TEST‐WISE?","1977","Journal of Educational Measurement","14","1","","39","45","6","6","10.1111/j.1745-3984.1977.tb00027.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973816835&doi=10.1111%2fj.1745-3984.1977.tb00027.x&partnerID=40&md5=001612b6a967833466e6423d48a2e565","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973816835"
"HEWITT B.N.; JACOBS R.","HEWITT, BARBARA NEWLIN (14833726300); JACOBS, RICK (7401996773)","14833726300; 7401996773","STUDENT PERCEPTIONS OF GRADING PRACTICES IN DIFFERENT MAJOR FIELDS","1978","Journal of Educational Measurement","15","3","","213","218","5","3","10.1111/j.1745-3984.1978.tb00070.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011890403&doi=10.1111%2fj.1745-3984.1978.tb00070.x&partnerID=40&md5=a09f7c0f6ccbbcc2a0f33576445c7d68","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85011890403"
"RENTZ R.R.; BASHAW W.L.","RENTZ, R. ROBERT (6602080325); BASHAW, W.L. (6602482991)","6602080325; 6602482991","THE NATIONAL REFERENCE SCALE FOR READING: AN APPLICATION OF THE RASCH MODEL","1977","Journal of Educational Measurement","14","2","","161","179","18","40","10.1111/j.1745-3984.1977.tb00034.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988079254&doi=10.1111%2fj.1745-3984.1977.tb00034.x&partnerID=40&md5=0217f275679da768638056122bf6df35","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988079254"
"CALLENDER J.C.; OSBURN H.G.","CALLENDER, JOHN C. (7003766483); OSBURN, H.G. (6602478248)","7003766483; 6602478248","AN EMPIRICAL COMPARISON OF COEFFICIENT ALPHA, GUTTMAN'S LAMBDA ‐ 2, AND MSPLIT MAXIMIZED SPLIT‐HALF RELIABILITY ESTIMATES","1979","Journal of Educational Measurement","16","2","","89","99","10","52","10.1111/j.1745-3984.1979.tb00090.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039914913&doi=10.1111%2fj.1745-3984.1979.tb00090.x&partnerID=40&md5=e43e5a4f71a10fe8e0f6135ac13914d1","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0039914913"
"KOLEN M.J.; WHITNEY D.R.","KOLEN, MICHAEL J. (6603925839); WHITNEY, DOUGLAS R. (7102971846)","6603925839; 7102971846","METHODS OF SMOOTHING DOUBLE‐ENTRY EXPECTANCY TABLES APPLIED TO THE PREDICTION OF SUCCESS IN COLLEGE","1978","Journal of Educational Measurement","15","3","","201","211","10","1","10.1111/j.1745-3984.1978.tb00069.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959948973&doi=10.1111%2fj.1745-3984.1978.tb00069.x&partnerID=40&md5=8d87a076fb03cdcd19948ed6b7b74020","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84959948973"
"KHAN S.B.","KHAN, SAR B. (25954504500)","25954504500","A COMPARATIVE STUDY OF ASSESSING CHILDREN'S SCHOOL‐RELATED ATTITUDES","1978","Journal of Educational Measurement","15","1","","59","66","7","3","10.1111/j.1745-3984.1978.tb00058.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965611988&doi=10.1111%2fj.1745-3984.1978.tb00058.x&partnerID=40&md5=9124376bfd2d0ee68377a95ebfffe159","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965611988"
"BURTON N.W.","BURTON, NANCY W. (25624524300)","25624524300","SOCIETAL STANDARDS","1978","Journal of Educational Measurement","15","4","","263","271","8","14","10.1111/j.1745-3984.1978.tb00073.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973790430&doi=10.1111%2fj.1745-3984.1978.tb00073.x&partnerID=40&md5=5268a6d201c295f9ec05529ecf914170","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973790430"
"NOVICK M.R.; LINDLEY D.V.","NOVICK, MELVIN R. (16513922700); LINDLEY, DENNIS V. (7005854337)","16513922700; 7005854337","THE USE OF MORE REALISTIC UTILITY FUNCTIONS IN EDUCATIONAL APPLICATIONS","1978","Journal of Educational Measurement","15","3","","181","191","10","32","10.1111/j.1745-3984.1978.tb00067.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986954220&doi=10.1111%2fj.1745-3984.1978.tb00067.x&partnerID=40&md5=53aa32b9fc2cf194c4c66f3f98e008a8","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84986954220"
"HANNA G.S.","HANNA, GERALD S. (24325536600)","24325536600","A STUDY OF RELIABILITY AND VALIDITY EFFECTS OF TOTAL AND PARTIAL IMMEDIATE FEEDBACK IN MULTIPLE‐CHOICE TESTING","1977","Journal of Educational Measurement","14","1","","1","7","6","4","10.1111/j.1745-3984.1977.tb00022.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038959215&doi=10.1111%2fj.1745-3984.1977.tb00022.x&partnerID=40&md5=117f332ce9bd6f77c230c287718bd881","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0038959215"
"SCHEUNEMAN J.","SCHEUNEMAN, JANICE (6602613561)","6602613561","A METHOD OF ASSESSING BIAS IN TEST ITEMS","1979","Journal of Educational Measurement","16","3","","143","152","9","101","10.1111/j.1745-3984.1979.tb00095.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988065600&doi=10.1111%2fj.1745-3984.1979.tb00095.x&partnerID=40&md5=18846745b0569ba45d4f916e150a2e9e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988065600"
"RAKOW E.A.; AIRASIAN P.W.; MADAUS G.F.","RAKOW, ERNEST A. (6507461632); AIRASIAN, PETER W. (6505790573); MADAUS, GEORGE F. (6602679298)","6507461632; 6505790573; 6602679298","ASSESSING SCHOOL AND PROGRAM EFFECTIVENESS: ESTIMATING TEACHER LEVEL EFFECTS","1978","Journal of Educational Measurement","15","1","","15","21","6","13","10.1111/j.1745-3984.1978.tb00052.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995151161&doi=10.1111%2fj.1745-3984.1978.tb00052.x&partnerID=40&md5=28265ecb46729191f172e3f6938d9f2d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84995151161"
"SEDERE M.U.; FELDT L.S.","SEDERE, M.U. (57195045166); FELDT, LEONARD S. (7003911114)","57195045166; 7003911114","THE SAMPLING DISTRIBUTIONS OF THE KRISTOF RELIABILITY COEFFICIENT, THE FELDT COEFFICIENT, AND GUTTMAN'S LAMBDA‐2","1977","Journal of Educational Measurement","14","1","","53","62","9","4","10.1111/j.1745-3984.1977.tb00029.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0042547335&doi=10.1111%2fj.1745-3984.1977.tb00029.x&partnerID=40&md5=9f16100a52b9e48de1085e5ae9922622","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0042547335"
"CRONBACH L.J.","CRONBACH, LEE J. (6507971226)","6507971226","EQUITY IN SELECTION—WHERE PSYCHOMETRICS AND POLITICAL PHILOSOPHY MEET","1976","Journal of Educational Measurement","13","1","","31","41","10","38","10.1111/j.1745-3984.1976.tb00179.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987023958&doi=10.1111%2fj.1745-3984.1976.tb00179.x&partnerID=40&md5=b9ab3d8bff9be84bdd72b18afe7a1055","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987023958"
"SLINDE J.A.; LINN R.L.","SLINDE, JEFFEREY A. (6507638009); LINN, ROBERT L. (56126633100)","6507638009; 56126633100","AN EXPLORATION OF THE ADEQUACY OF THE RASCH MODEL FOR THE PROBLEM OF VERTICAL EQUATING","1978","Journal of Educational Measurement","15","1","","23","35","12","29","10.1111/j.1745-3984.1978.tb00053.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0008302472&doi=10.1111%2fj.1745-3984.1978.tb00053.x&partnerID=40&md5=7128981c671a350b160b8e9bc878de0a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0008302472"
"CONKLIN J.E.; BURSTEIN L.; KEESLING J.W.","CONKLIN, JONATHAN E. (36960687500); BURSTEIN, LEIGH (24392337600); KEESLING, J. WARD (6602560143)","36960687500; 24392337600; 6602560143","THE EFFECTS OF DATE OF TESTING AND METHOD OF INTERPOLATION ON THE USE OF STANDARDIZED TEST SCORES IN THE EVALUATION OF LARGE‐SCALE EDUCATIONAL PROGRAMS","1979","Journal of Educational Measurement","16","4","","239","246","7","0","10.1111/j.1745-3984.1979.tb00105.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024992920&doi=10.1111%2fj.1745-3984.1979.tb00105.x&partnerID=40&md5=72a073a5e0b1b3c8b30a4c75e482a555","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024992920"
"THORNDIKE R.L.","THORNDIKE, ROBERT L. (16652297900)","16652297900","CAUSATION OF BINET IQ DECREMENTS","1977","Journal of Educational Measurement","14","3","","197","202","5","17","10.1111/j.1745-3984.1977.tb00036.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0346159693&doi=10.1111%2fj.1745-3984.1977.tb00036.x&partnerID=40&md5=565b6ca4420da2f51633ec8ece856c1a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0346159693"
"CROSS L.H.; FRARY R.B.","CROSS, LAWRENCE H. (7103098312); FRARY, ROBERT B. (6602858608)","7103098312; 6602858608","AN EMPIRICAL TEST OF LORD'S THEORETICAL RESULTS REGARDING FORMULA SCORING OF MULTIPLE‐CHOICE TESTS","1977","Journal of Educational Measurement","14","4","","313","321","8","44","10.1111/j.1745-3984.1977.tb00047.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988054834&doi=10.1111%2fj.1745-3984.1977.tb00047.x&partnerID=40&md5=4c90eef859e0475bddd25469b8454e3e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988054834"
"GOLDMAN R.D.; WIDAWSKI M.H.","GOLDMAN, ROY D. (7402001118); WIDAWSKI, MEL H. (56716090500)","7402001118; 56716090500","AN ANALYSIS OF TYPES OF ERRORS IN THE SELECTION OF MINORITY COLLEGE STUDENTS","1976","Journal of Educational Measurement","13","3","","185","200","15","11","10.1111/j.1745-3984.1976.tb00010.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973814558&doi=10.1111%2fj.1745-3984.1976.tb00010.x&partnerID=40&md5=eb5cfe3c8f226f19f5183c061cc80e33","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973814558"
"MUELLER D.J.; WASSER V.","MUELLER, DANIEL J. (8967208200); WASSER, VIRGINIA (57195045444)","8967208200; 57195045444","IMPLICATIONS OF CHANGING ANSWERS ON OBJECTIVE TEST ITEMS","1977","Journal of Educational Measurement","14","1","","9","13","4","36","10.1111/j.1745-3984.1977.tb00023.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0003064126&doi=10.1111%2fj.1745-3984.1977.tb00023.x&partnerID=40&md5=6ab546a3bb070f00852727c17300a06a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0003064126"
"KNAPP T.R.","KNAPP, THOMAS R. (24366321400)","24366321400","THE RELIABILITY OF A DICHOTOMOUS TEST‐ITEM: A “CORRELATIONLESS” APPROACH","1977","Journal of Educational Measurement","14","3","","237","252","15","10","10.1111/j.1745-3984.1977.tb00041.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970317001&doi=10.1111%2fj.1745-3984.1977.tb00041.x&partnerID=40&md5=28293f9967eccc5bae517dff80399a7d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84970317001"
"BEJAR I.I.; DOYLE K.O.","BEJAR, ISAAC I. (6602577229); DOYLE, KENNETH O. (7102114373)","6602577229; 7102114373","THE EFFECT OF PRIOR EXPECTATIONS ON THE STRUCTURE OF STUDENT RATINGS OF INSTRUCTION","1976","Journal of Educational Measurement","13","2","","151","154","3","4","10.1111/j.1745-3984.1976.tb00006.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965855072&doi=10.1111%2fj.1745-3984.1976.tb00006.x&partnerID=40&md5=aad743b1a17f4848de66bc060c61b31f","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965855072"
"LIVINGSTON S.A.; WINGERSKY M.S.","LIVINGSTON, SAMUEL A. (35864363200); WINGERSKY, MARILYN S. (6507024898)","35864363200; 6507024898","ASSESSING THE RELIABILITY OF TESTS USED TO MAKE PASS/FAIL DECISIONS","1979","Journal of Educational Measurement","16","4","","247","260","13","17","10.1111/j.1745-3984.1979.tb00106.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988087525&doi=10.1111%2fj.1745-3984.1979.tb00106.x&partnerID=40&md5=225a604e5b2690a97e36ed34d19bef99","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988087525"
"TUCKMAN B.W.","TUCKMAN, BRUCE WAYNE (6603786542)","6603786542","THE TUCKMAN TEACHER FEEDBACK FORM (TTFF)","1976","Journal of Educational Measurement","13","3","","233","237","4","10","10.1111/j.1745-3984.1976.tb00014.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024944296&doi=10.1111%2fj.1745-3984.1976.tb00014.x&partnerID=40&md5=b2b69a6dc037c132f4a01bbed2649a9c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024944296"
"SCRIVEN M.","SCRIVEN, MICHAEL (7003407896)","7003407896","HOW TO ANCHOR STANDARDS","1978","Journal of Educational Measurement","15","4","","273","275","2","14","10.1111/j.1745-3984.1978.tb00074.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932338774&doi=10.1111%2fj.1745-3984.1978.tb00074.x&partnerID=40&md5=1138f7967034724b06fe185bed1ef0d5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84932338774"
"HAMBLETON R.K.","HAMBLETON, RONALD K. (7006242264)","7006242264","ON THE USE OF CUT‐OFF SCORES WITH CRITERION‐REFERENCED TESTS IN INSTRUCTIONAL SETTINGS","1978","Journal of Educational Measurement","15","4","","277","290","13","43","10.1111/j.1745-3984.1978.tb00075.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84974824902&doi=10.1111%2fj.1745-3984.1978.tb00075.x&partnerID=40&md5=fc32e60011e2fb470655a2131be0f63a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84974824902"
"TERWILLIGER J.S.; LELE K.","TERWILLIGER, JAMES S. (38962286700); LELE, KAUSTUBH (57195042131)","38962286700; 57195042131","SOME RELATIONSHIPS AMONG INTERNAL CONSISTENCY, REPRODUCIBILITY, AND HOMOGENEITY","1979","Journal of Educational Measurement","16","2","","101","108","7","7","10.1111/j.1745-3984.1979.tb00091.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973839643&doi=10.1111%2fj.1745-3984.1979.tb00091.x&partnerID=40&md5=75113c2b6c235cc450c9c8fbba40f90b","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973839643"
"BAJTELSMIT J.W.","BAJTELSMIT, JOHN W. (6505854618)","6505854618","TEST‐WISENESS AND SYSTEMATIC DESENSITIZATION PROGRAMS FOR INCREASING ADULT TEST‐TAKING SKILLS","1977","Journal of Educational Measurement","14","4","","335","341","6","4","10.1111/j.1745-3984.1977.tb00049.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84972610705&doi=10.1111%2fj.1745-3984.1977.tb00049.x&partnerID=40&md5=d9e93ed52fa8fa51ab7be28f09c0966d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84972610705"
"RINDLER S.E.","RINDLER, SUSAN ELLERIN (57189187269)","57189187269","PITFALLS IN ASSESSING TEST SPEEDEDNESS","1979","Journal of Educational Measurement","16","4","","261","270","9","33","10.1111/j.1745-3984.1979.tb00107.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039186576&doi=10.1111%2fj.1745-3984.1979.tb00107.x&partnerID=40&md5=b03025f3a9cad6ffd3ea1dc8eb5c4995","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0039186576"
"SUBKOVIAK M.J.; LEVIN J.R.","SUBKOVIAK, MICHAEL J. (6506489478); LEVIN, JOEL R. (7403286430)","6506489478; 7403286430","FALLIBILITY OF MEASUREMENT AND THE POWER OF A STATISTICAL TEST","1977","Journal of Educational Measurement","14","1","","47","52","5","11","10.1111/j.1745-3984.1977.tb00028.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-11744378579&doi=10.1111%2fj.1745-3984.1977.tb00028.x&partnerID=40&md5=c5f1917825fab9db13c25de950a401cd","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-11744378579"
"ROWLEY G.","ROWLEY, GLENN (7006131497)","7006131497","THE RELATIONSHIP OF RELIABILITY IN CLASSROOM RESEARCH TO THE AMOUNT OF OBSERVATION: AN EXTENSION OF THE SPEARMAN‐BROWN FORMULA","1978","Journal of Educational Measurement","15","3","","165","180","15","31","10.1111/j.1745-3984.1978.tb00066.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011213213&doi=10.1111%2fj.1745-3984.1978.tb00066.x&partnerID=40&md5=333a65b181841d1c7686b9cbe35eaa8d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85011213213"
"CARLSON J.S.; DILLON R.","CARLSON, JERRY S. (36902392100); DILLON, RONNA (24392680700)","36902392100; 24392680700","EFFECTS OF TESTING CONDITIONS ON PIAGET MATRICES AND ORDER OF APPEARANCE PROBLEMS: A STUDY OF COMPETENCE VERSUS PERFORMANCE","1979","Journal of Educational Measurement","16","1","","19","26","7","6","10.1111/j.1745-3984.1979.tb00082.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987000893&doi=10.1111%2fj.1745-3984.1979.tb00082.x&partnerID=40&md5=ffc469a7ce3c3f2d7affe513f7da78f3","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987000893"
"PLAKE B.S.; HOOVER H.D.","PLAKE, BARBARA S. (6603689848); HOOVER, H.D. (56600179100)","6603689848; 56600179100","THE COMPARABILITY OF EQUAL RAW SCORES OBTAINED FROM IN‐LEVEL AND OUT‐OF‐LEVEL TESTING: ONE SOURCE OF THE DISCREPANCY BETWEEN IN‐LEVEL AND OUT‐OF‐LEVEL GRADE EQUIVALENT SCORES","1979","Journal of Educational Measurement","16","4","","271","278","7","3","10.1111/j.1745-3984.1979.tb00108.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984437092&doi=10.1111%2fj.1745-3984.1979.tb00108.x&partnerID=40&md5=07308bb6487430fa006fe005af7ef3d2","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84984437092"
"MOSS J.D.; BROWN F.G.","MOSS, JACQUE D. (57195042266); BROWN, F.G. (7401462347)","57195042266; 7401462347","SEX BIAS AND ACADEMIC PERFORMANCE: AN EMPIRICAL STUDY","1979","Journal of Educational Measurement","16","3","","197","201","4","3","10.1111/j.1745-3984.1979.tb00101.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965682162&doi=10.1111%2fj.1745-3984.1979.tb00101.x&partnerID=40&md5=a6e111a96916ef60ae6a0156795ff130","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965682162"
"SUBKOVIAK M.J.; ROECKS A.L.","SUBKOVIAK, MICHAEL J. (6506489478); ROECKS, ALAN L. (36921204300)","6506489478; 36921204300","A CLOSER LOOK AT THE ACCURACY OF ALTERNATIVE DATA‐COLLECTION METHODS FOR MULTIDIMENSIONAL SCALING","1976","Journal of Educational Measurement","13","4","","309","317","8","4","10.1111/j.1745-3984.1976.tb00021.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005514845&doi=10.1111%2fj.1745-3984.1976.tb00021.x&partnerID=40&md5=a3ae726b063b7008d5d7c629eec3ce31","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85005514845"
"SINGLETON R., JR.; SMITH E.R.","SINGLETON, ROYCE (35978626100); SMITH, ELIOT R. (7408616829)","35978626100; 7408616829","DOES GRADE INFLATION DECREASE THE RELIABILITY OF GRADES?","1978","Journal of Educational Measurement","15","1","","37","41","4","12","10.1111/j.1745-3984.1978.tb00054.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965848626&doi=10.1111%2fj.1745-3984.1978.tb00054.x&partnerID=40&md5=1e0a3f28e2274555e8cb7697cbe9f6a5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965848626"
"Sirotnik K.; Wellington R.","Sirotnik, Kenneth (56360886700); Wellington, Roger (16511728500)","56360886700; 16511728500","INCIDENCE SAMPLING: AN INTEGRATED THEORY FOR “MATRIX SAMPLING”","1977","Journal of Educational Measurement","14","4","","343","399","56","26","10.1111/j.1745-3984.1977.tb00050.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011142400&doi=10.1111%2fj.1745-3984.1977.tb00050.x&partnerID=40&md5=e58d9f6cd81b46e54c250d2fddf2a24a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85011142400"
"GUSTAFSSON J.‐E.","GUSTAFSSON, JAN‐ERIC (55684486900)","55684486900","THE RASCH MODEL IN VERTICAL EQUATING OF TESTS: A CRITIQUE OF SLINDE AND LINN","1979","Journal of Educational Measurement","16","3","","153","158","5","15","10.1111/j.1745-3984.1979.tb00096.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970351228&doi=10.1111%2fj.1745-3984.1979.tb00096.x&partnerID=40&md5=3770531a9d665432aa4dabd71dc7af95","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84970351228"
"STAYROOK N.; CORNO L.","STAYROOK, NICHOLAS (6507350673); CORNO, LYN (6602570318)","6507350673; 6602570318","AN APPLICATION OF GENERALIZABILITY THEORY IN DISATTENUATING A PATH MODEL OF TEACHING AND LEARNING","1979","Journal of Educational Measurement","16","4","","227","237","10","1","10.1111/j.1745-3984.1979.tb00104.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948073920&doi=10.1111%2fj.1745-3984.1979.tb00104.x&partnerID=40&md5=54710f39ad764083412399d84b363a4d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84948073920"
"SAWYER R.; MAXEY J.","SAWYER, RICHARD (7201516630); MAXEY, JAMES (9533296100)","7201516630; 9533296100","THE VALIDITY OF COLLEGE GRADE PREDICTION EQUATIONS OVER TIME","1979","Journal of Educational Measurement","16","4","","279","284","5","3","10.1111/j.1745-3984.1979.tb00109.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956348836&doi=10.1111%2fj.1745-3984.1979.tb00109.x&partnerID=40&md5=c0a7c7e1010a26998be134184a4d7f0f","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84956348836"
"KORTH B.","KORTH, BRUCE (24551273700)","24551273700","RELATIONSHIP OF EXTRANEOUS VARIABLES TO STUDENT RATINGS OF INSTRUCTORS","1979","Journal of Educational Measurement","16","1","","27","37","10","10","10.1111/j.1745-3984.1979.tb00083.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977019109&doi=10.1111%2fj.1745-3984.1979.tb00083.x&partnerID=40&md5=a3dc4f6bb9c1c0914f2172127bd99388","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84977019109"
"HUMPHREYS L.G.; PARSONS C.K.; PARK R.K.","HUMPHREYS, LLOYD G. (56238275200); PARSONS, CHARLES K. (59040730900); PARK, RANDOLPH K. (57215634295)","56238275200; 59040730900; 57215634295","DIMENSIONS INVOLVED IN DIFFERENCES AMONG SCHOOL MEANS OF COGNITIVE MEASURES","1979","Journal of Educational Measurement","16","2","","63","76","13","6","10.1111/j.1745-3984.1979.tb00088.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983617171&doi=10.1111%2fj.1745-3984.1979.tb00088.x&partnerID=40&md5=8247e67b2945b79887ed4f74005606e9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84983617171"
"BEUCHERT A.K.; MENDOZA J.L.","BEUCHERT, A. KENT (57195041331); MENDOZA, JORGE L. (16492251300)","57195041331; 16492251300","A MONTE CARLO COMPARISON OF TEN ITEM DISCRIMINATION INDICES","1979","Journal of Educational Measurement","16","2","","109","117","8","9","10.1111/j.1745-3984.1979.tb00092.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991758142&doi=10.1111%2fj.1745-3984.1979.tb00092.x&partnerID=40&md5=730115c7e1d396cc252428f3f85b596c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84991758142"
"LONG J.V.; SCHAFFRAN J.A.; KELLOGG T.M.","LONG, JOHN V. (57191455497); SCHAFFRAN, JEROME A. (57195040180); KELLOGG, THEODORE M. (57017678800)","57191455497; 57195040180; 57017678800","EFFECTS OF OUT‐OF‐LEVEL SURVEY TESTING ON READING ACHIEVEMENT SCORES OF TITLE I, ESEA STUDENTS","1977","Journal of Educational Measurement","14","3","","203","213","10","8","10.1111/j.1745-3984.1977.tb00037.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925909853&doi=10.1111%2fj.1745-3984.1977.tb00037.x&partnerID=40&md5=341696028233f32344aef3128bfc7f82","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84925909853"
"WILCOX R.R.; HARRIS C.W.","WILCOX, RAND R. (7202527113); HARRIS, CHESTER W. (16535830400)","7202527113; 16535830400","ON EMRICK'S “AN EVALUATION MODEL FOR MASTERY TESTING”","1977","Journal of Educational Measurement","14","3","","215","218","3","5","10.1111/j.1745-3984.1977.tb00038.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970261050&doi=10.1111%2fj.1745-3984.1977.tb00038.x&partnerID=40&md5=43b95f5902ba3b1c6b1156b548633813","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84970261050"
"DAVID J.L.; PELAVIN S.H.","DAVID, JANE L. (57195044805); PELAVIN, SOL H. (57195041735)","57195044805; 57195041735","EVALUATING COMPENSATORY EDUCATION: OVER WHAT PERIOD OF TIME SHOULD ACHIEVEMENT BE MEASURED?","1978","Journal of Educational Measurement","15","2","","91","99","8","5","10.1111/j.1745-3984.1978.tb00060.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973704063&doi=10.1111%2fj.1745-3984.1978.tb00060.x&partnerID=40&md5=7de08ca13ca6f905c79800b89446e630","An assumption fundamental to compensatory education is that greater achievement can change the academic future of disadvantaged students, which may in turn enhance their “life chances.” Therefore, one of the goals of compensatory education is to increase the achievement of disadvantaged students. To change students' futures, this increase in achievement should be evident subsequent to participation in a compensatory‐education program. At a minimum, an increase in achievement should persist over the summer following a school‐year program. Evaluations of compensatory education in general, however, and of Title I of the Elementary and Secondary Education Act (ESEA) in particular, have not included measures of sustained achievement. Instead, judgments of program success have been based on students' achievement during the school year: that is, on a spring posttest score adjusted in some way for the preceding fall pretest score. Copyright © 1978, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973704063"
"GARVIN A.D.","GARVIN, ALFRED D. (35102087800)","35102087800","A SIMPLE, ACCURATE APPROXIMATION OF THE STANDARD ERROR OF MEASUREMENT","1976","Journal of Educational Measurement","13","2","","101","105","4","0","10.1111/j.1745-3984.1976.tb00001.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024985057&doi=10.1111%2fj.1745-3984.1976.tb00001.x&partnerID=40&md5=a6df5d48230f1bff3b1e6571fcaf6d35","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024985057"
"SMITH P.L.","SMITH, PHILIP L. (57028742000)","57028742000","THE GENERALIZABILITY OF STUDENT RATINGS OF COURSES: ASKING THE RIGHT QUESTIONS","1979","Journal of Educational Measurement","16","2","","77","87","10","12","10.1111/j.1745-3984.1979.tb00089.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990440743&doi=10.1111%2fj.1745-3984.1979.tb00089.x&partnerID=40&md5=795703113de9815b3aceede5e1465b97","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84990440743"
"HUCK S.W.","HUCK, SCHUYLER W. (7006803001)","7006803001","TEST PERFORMANCE UNDER THE CONDITION OF KNOWN ITEM DIFFICULTY","1978","Journal of Educational Measurement","15","1","","53","58","5","2","10.1111/j.1745-3984.1978.tb00057.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973825110&doi=10.1111%2fj.1745-3984.1978.tb00057.x&partnerID=40&md5=39c584e6f804112395fa9025d25048b3","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973825110"
"BRENNAN R.L.; KANE M.T.","BRENNAN, ROBERT L. (34975092300); KANE, MICHAEL T. (36088969800)","34975092300; 36088969800","AN INDEX OF DEPENDABILITY FOR MASTERY TESTS","1977","Journal of Educational Measurement","14","3","","277","289","12","108","10.1111/j.1745-3984.1977.tb00045.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33644993623&doi=10.1111%2fj.1745-3984.1977.tb00045.x&partnerID=40&md5=4763af141a0d62224d8c3041c8b1f6a0","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-33644993623"
"DE AVILA E.; PULOS S.","DE AVILA, EDWARD (57168003900); PULOS, STEVEN (6603328945)","57168003900; 6603328945","GROUP ASSESSMENT OF COGNITIVE LEVEL BY PICTORIAL PIAGETIAN TASKS","1979","Journal of Educational Measurement","16","3","","167","175","8","4","10.1111/j.1745-3984.1979.tb00098.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987170062&doi=10.1111%2fj.1745-3984.1979.tb00098.x&partnerID=40&md5=a8973622bbdab8032dc18fb0a376a19c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987170062"
"WRIGHT B.D.","WRIGHT, BENJAMIN D. (7402346612)","7402346612","SOLVING MEASUREMENT PROBLEMS WITH THE RASCH MODEL","1977","Journal of Educational Measurement","14","2","","97","116","19","405","10.1111/j.1745-3984.1977.tb00031.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847429533&doi=10.1111%2fj.1745-3984.1977.tb00031.x&partnerID=40&md5=878ee33498c191930d3a00b65366b44e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-33847429533"
"MARCO G.L.","MARCO, GARY L. (57065132200)","57065132200","USE OF THE LOGISTIC MODEL AS AN ALTERNATIVE TO LINEAR INTERPOLATION FOR COMPUTING PERCENTILE RANKS","1977","Journal of Educational Measurement","14","3","","271","275","4","1","10.1111/j.1745-3984.1977.tb00044.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024970252&doi=10.1111%2fj.1745-3984.1977.tb00044.x&partnerID=40&md5=1fe434524ee3c810bc29c9a447ef4820","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024970252"
"YOSHIDA R.K.","YOSHIDA, ROLAND K. (24548936000)","24548936000","OUT‐OF‐LEVEL TESTING OF SPECIAL EDUCATION STUDENTS WITH A STANDARDIZED ACHIEVEMENT BATTERY","1976","Journal of Educational Measurement","13","3","","215","221","6","4","10.1111/j.1745-3984.1976.tb00012.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973825103&doi=10.1111%2fj.1745-3984.1976.tb00012.x&partnerID=40&md5=e7e623c7ce4b0fb6dbe016fecafa75a5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973825103"
"LINN R.L.","LINN, ROBERT L. (56126633100)","56126633100","DEMANDS, CAUTIONS, AND SUGGESTIONS FOR SETTING STANDARDS","1978","Journal of Educational Measurement","15","4","","301","308","7","18","10.1111/j.1745-3984.1978.tb00078.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005329919&doi=10.1111%2fj.1745-3984.1978.tb00078.x&partnerID=40&md5=4bcd66ccffde3ac317d2c62048b3b146","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85005329919"
"HALADYNA T.M.","HALADYNA, THOMAS MICHAEL (6602737797)","6602737797","EFFECTS OF DIFFERENT SAMPLES ON ITEM AND TEST CHARACTERISTICS OF CRITERION‐REFERENCED TESTS","1974","Journal of Educational Measurement","11","2","","93","99","6","15","10.1111/j.1745-3984.1974.tb00977.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-78650040787&doi=10.1111%2fj.1745-3984.1974.tb00977.x&partnerID=40&md5=2fed56b39525d99847fc4050d0e33bc2","Although many have rejected classical test construction and analysis procedures for criterion‐referenced tests, the present study was concerned with the possibility that classical procedures are both applicable and appropriate when samples of both mastery and nonmastery examinees are employed. A rationale for using these samples was presented, and empirical evidence was gathered which supported the practice of combining samples to increase the variance of test scores and thereby permit the proper estimate of reliability and item validities. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-78650040787"
"ROEDER H.H.","ROEDER, HAROLD H. (57195043893)","57195043893","TEACHER EDUCATION CURRICULA–YOUR FINAL GRADE IS F","1973","Journal of Educational Measurement","10","2","","141","143","2","11","10.1111/j.1745-3984.1973.tb00791.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984527235&doi=10.1111%2fj.1745-3984.1973.tb00791.x&partnerID=40&md5=0a0014a3449d4a73216a963eecae4858","This manuscript presents the results of a nationwide teacher education survey which attempted to ascertain how adequately colleges and universities are preparing prospective elementary teachers in the area of “tests and measures.” Nine hundred forty institutions were mailed a questionnaire which requested data on the specific requirements which undergraduates were expected to fulfill in order to be graduated and awarded state certification. Over 97% of the institutions which were originally surveyed returned questionnaires. The data indicate that upon graduation from college, most prospective elementary classroom teachers are better prepared to conduct impromptu art and music lessons than they are to evaluate pupil performance. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84984527235"
"KAGERER R.L.","KAGERER, RUDOLPH L. (57190149050)","57190149050","TOWARD AN AFFECTIVE OUTCOME OF HIGHER EDUCATION","1974","Journal of Educational Measurement","11","3","","203","208","5","0","10.1111/j.1745-3984.1974.tb00991.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024935782&doi=10.1111%2fj.1745-3984.1974.tb00991.x&partnerID=40&md5=5e45259eb31e139f2f747877c374326f","A test was developed for measuring the ability of college students to analyze emotional and nonemotional subject matter. The rationale for the test was that students should become able to analyze material more objectively as they pass through the 4 years of college. Results of convergent and discriminant validation indicated that subject responses to “emotional” items appeared to change at an increasing rate with years in college, while responses to nonemotional items did not. Lack of correlation of the test with cognitive materials, adequate internal reliability, and performance consistent with expectations gave support to the construct, labeled “analytical objectivity.” Initial structuring of a nomological net for support of the validity of the construct was achieved. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024935782"
"SUBKOVIAK M.J.","SUBKOVIAK, MICHAEL J. (6506489478)","6506489478","ESTIMATING RELIABILITY FROM A SINGLE ADMINISTRATION OF A CRITERION‐REFERENCED TEST","1976","Journal of Educational Measurement","13","4","","265","276","11","73","10.1111/j.1745-3984.1976.tb00017.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002422503&doi=10.1111%2fj.1745-3984.1976.tb00017.x&partnerID=40&md5=c38e1a6a6cbbecf811691a8bced75af9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0002422503"
"SUBKOVIAK M.J.; LEVIN J.R.","SUBKOVIAK, MICHAEL J. (6506489478); LEVIN, JOEL R. (7403286430)","6506489478; 7403286430","DETERMINING THE CHARACTERISTICS OF THE IDEAL PROFESSOR: AN ALTERNATIVE APPROACH","1974","Journal of Educational Measurement","11","4","","269","276","7","11","10.1111/j.1745-3984.1974.tb00999.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010959361&doi=10.1111%2fj.1745-3984.1974.tb00999.x&partnerID=40&md5=dcd9bfa85311591264a1a56c2d62aa4c","In a recently conducted study it was found that an effective college teacher could be characterized chiefly in terms of “research,”“teaching,” and “service to the university.” The present experiment corroborated these findings using a relatively unknown approach to data collection, analysis, and interpretation. A free‐response method of data collection, in conjunction with nonmetric multidimensional scaling, produced results highly similar to those of the previous study. In addition, the solution permitted a straight‐forward means of assessing the performance of individual faculty members. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0010959361"
"POHLMANN J.T.; BEGGS D.L.","POHLMANN, JOHN T. (8921675000); BEGGS, DONALD L. (7003657448)","8921675000; 7003657448","A STUDY OF THE VALIDITY OF SELF‐REPORTED MEASURES OF ACADEMIC GROWTH","1974","Journal of Educational Measurement","11","2","","115","119","4","45","10.1111/j.1745-3984.1974.tb00980.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000974088&doi=10.1111%2fj.1745-3984.1974.tb00980.x&partnerID=40&md5=814988c13851ea8194e0a20278963389","This study was undertaken to examine the relationship between self‐reported and pre‐post measures of academic growth. Self‐reported and pre‐post measures were obtained in three areas, simple cognitive, complex cognitive, and attitudinal. The subjects were 162 graduate students enrolled in six different graduate courses. Partial correlations relating self‐reported measures of growth to posttest performance on measures of achievement (simple and complex cognitive)and attitude, controlling for pretest performance indicated that self‐reported measures of academic growth were primarily related to growth in attitudes toward the subject matter of a course. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0000974088"
"GREENWOOD G.E.; BRIDGES C.M., JR; WARE W.B.; MCLEAN J.E.","GREENWOOD, GORDON E. (16509901500); BRIDGES, CHARLES M. (57191121534); WARE, WILLIAM B. (7006828442); MCLEAN, JAMES E. (57024458500)","16509901500; 57191121534; 7006828442; 57024458500","STUDENT EVALUATION OF COLLEGE TEACHING BEHAVIORS","1974","Journal of Educational Measurement","11","2","","141","143","2","2","10.1111/j.1745-3984.1974.tb00986.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939299752&doi=10.1111%2fj.1745-3984.1974.tb00986.x&partnerID=40&md5=32858832d1a10f1835d7802be1663aaa","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84939299752"
"SIMON A.J.; JOINER L.M.","SIMON, ALAN J. (57195041219); JOINER, LEE M. (6603807223)","57195041219; 6603807223","A MEXICAN VERSION OF THE PEABODY PICTURE VOCABULARY TEST","1976","Journal of Educational Measurement","13","2","","137","143","6","1","10.1111/j.1745-3984.1976.tb00004.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79951606002&doi=10.1111%2fj.1745-3984.1976.tb00004.x&partnerID=40&md5=c972e0bd026e50a5a8714b18df3930c0","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-79951606002"
"SWAMINATHAN H.; HAMBLETON R.K.; ALGINA J.","SWAMINATHAN, H. (6602382602); HAMBLETON, RONALD K. (7006242264); ALGINA, JAMES (7003768166)","6602382602; 7006242264; 7003768166","A BAYESIAN DECISION‐THEORETIC PROCEDURE FOR USE WITH CRITERION‐REFERENCED TESTS","1975","Journal of Educational Measurement","12","2","","87","98","11","32","10.1111/j.1745-3984.1975.tb01011.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010216024&doi=10.1111%2fj.1745-3984.1975.tb01011.x&partnerID=40&md5=809fc916c2d39c1bf4cc4fc9d08d6912","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0010216024"
"LaVOIE A.L.; BENTLER P.M.","LaVOIE, ALLAN L. (24580579900); BENTLER, P.M. (7005482427)","24580579900; 7005482427","A SHORT‐FORM MEASURE OF THE EXPANDED SEVEN‐DIMENSIONAL SEMANTIC SPACE","1974","Journal of Educational Measurement","11","1","","65","66","1","2","10.1111/j.1745-3984.1974.tb00974.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925887641&doi=10.1111%2fj.1745-3984.1974.tb00974.x&partnerID=40&md5=e1edd858cbb40f523adc5ee784560de6","A short‐form measure of an expanded seven‐dimensional semantic differential was developed. The shorter scales were shown to correlate highly with the longer scales, and their internal consistencies were sufficiently high to warrant use in most educational settings. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84925887641"
"ANDERSON T.H.","ANDERSON, THOMAS H. (56971798700)","56971798700","CLOZE MEASURES AS INDICES OF ACHIEVEMENT COMPREHENSION WHEN LEARNING FROM EXTENDED PROSE","1974","Journal of Educational Measurement","11","2","","83","92","9","10","10.1111/j.1745-3984.1974.tb00976.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993826108&doi=10.1111%2fj.1745-3984.1974.tb00976.x&partnerID=40&md5=0e088616052b7b4c2f8cf87c84e6231a","The hypothesis that cloze measures are a function of content achievement among adult learners and, consequently, should be sensitive to instructional treatments was tested in two experimental studies. College juniors and seniors took tests immediately before (pre), immediately after (post) and four weeks after (delay) studying a prose passage. The types of tests administered in each session were: (I) a 20‐item multiple‐choice test, (2) a reproduction passage cloze test, (3) a recognition passage cloze test, (4) a reproduction summary cloze test, and (5) a recognition summary cloze test. All tests show significant differences between pre‐ and posteonditions, and between recognition and reproduction modes. The reproduction summary cloze test was found to be the most sensitive to the instructional treatment, as indicated by an oJ 2 statistic on pre‐post measures. The summary cloze tests were resistant to forgetting while the cloze passage and multiple‐choice tests show significant decreases in performance over the four week delay interval. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84993826108"
"JACOBS S.S.","JACOBS, STANLEY S. (7402313169)","7402313169","BEHAVIOR ON OBJECTIVE TESTS UNDER THEORETICALLY ADEQUATE, INADEQUATE AND UNSPECIFIED SCORING RULES","1975","Journal of Educational Measurement","12","1","","19","29","10","1","10.1111/j.1745-3984.1975.tb01005.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954643209&doi=10.1111%2fj.1745-3984.1975.tb01005.x&partnerID=40&md5=1d32f4283b54db3c0664b804ff53d264","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84954643209"
"O'SULLIVAN M.; GUILFORD J.P.","O'SULLIVAN, MAUREEN (57195375531); GUILFORD, J.P. (7004163624)","57195375531; 7004163624","SIX FACTORS OF BEHAVIORAL COGNITION: UNDERSTANDING OTHER PEOPLE","1975","Journal of Educational Measurement","12","4","","255","271","16","31","10.1111/j.1745-3984.1975.tb01027.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015531656&doi=10.1111%2fj.1745-3984.1975.tb01027.x&partnerID=40&md5=6d89964bb4dacbf567a9f3361af9e4bf","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85015531656"
"KANSUP W.; HAKSTIAN A.R.","KANSUP, WANLOP (57195043408); HAKSTIAN, A. RALPH (6701603762)","57195043408; 6701603762","A COMPARISON OF SEVERAL METHODS OF ASSESSING PARTIAL KNOWLEDGE IN MULTIPLE‐CHOICE TESTS: I. SCORING PROCEDURES","1975","Journal of Educational Measurement","12","4","","219","230","11","23","10.1111/j.1745-3984.1975.tb01023.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014091259&doi=10.1111%2fj.1745-3984.1975.tb01023.x&partnerID=40&md5=229e51729a9394677314c4060a35289c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85014091259"
"ALEAMONI L.M.; GRAHAM M.H.","ALEAMONI, LAWRENCE M. (8252944000); GRAHAM, MARGARET H. (57215758125)","8252944000; 57215758125","THE RELATIONSHIP BETWEEN CEQ RATINGS AND INSTRUCTOR'S RANK, CLASS SIZE, AND COURSE LEVEL","1974","Journal of Educational Measurement","11","3","","189","202","13","33","10.1111/j.1745-3984.1974.tb00990.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84979446674&doi=10.1111%2fj.1745-3984.1974.tb00990.x&partnerID=40&md5=3c9a65a1d55e1167f07f89c63d1be518","A study was conducted to determine if the tendency for faculty members of higher rank to receive the highest ratings on the Illinois Course Evaluation Questionnaire (CEQ) remained when variables such as class size and course level were taken into account. The relationship between CEQ ratings and instructor's rank, class size, and level of course was examined by means of multivariate analysis of variance (MANOVA). Dependent variables were the six subscales of the CEQ. As hypothesized there were no significant differences in ratings assigned by students in small (1‐20 students), medium (21‐40 students), and large (over 40 students) classes, or received by teaching assistants, instructors, and assistant, associate, and full professors. Highly significant differences, however, were found in ratings assigned by students in freshman, sophomore, junior, senior, and graduate level courses. In addition, significant size by level and size by rank interaction effects were found. Discriminant functions computed for effects found to be significant yielded information concerning the extent and direction of these significant differences. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84979446674"
"CARDINET J.; TOURNEUR W.; ALLAL L.","CARDINET, JEAN (16545382900); TOURNEUR, WAN (57195040957); ALLAL, LINDA (23033009400)","16545382900; 57195040957; 23033009400","THE SYMMETRY OF GENERALIZABILITY THEORY: APPLICATIONS TO EDUCATIONAL MEASUREMENT","1976","Journal of Educational Measurement","13","2","","119","135","16","96","10.1111/j.1745-3984.1976.tb00003.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911350097&doi=10.1111%2fj.1745-3984.1976.tb00003.x&partnerID=40&md5=8760973ece4528431954cf94edf0bf47","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84911350097"
"HARRIS C.W.","HARRIS, CHESTER W. (16535830400)","16535830400","NOTE ON THE VARIANCES AND COVARIANCES OF THREE ERROR TYPES","1973","Journal of Educational Measurement","10","1","","49","50","1","2","10.1111/j.1745-3984.1973.tb00781.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024989203&doi=10.1111%2fj.1745-3984.1973.tb00781.x&partnerID=40&md5=1683ef24e710fb1ffed618a57a036400","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024989203"
"WILLIAMS T.H.","WILLIAMS, TREVOR H. (57212730665)","57212730665","THE WECHSLER SCALES: PARENTS AND (MALE) CHILDREN","1975","Journal of Educational Measurement","12","2","","119","128","9","2","10.1111/j.1745-3984.1975.tb01015.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-12144280411&doi=10.1111%2fj.1745-3984.1975.tb01015.x&partnerID=40&md5=3b3586682b0cc41cec8a9466c67e0e58","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-12144280411"
"DARLINGTON R.B.","DARLINGTON, RICHARD B. (59025395800)","59025395800","A DEFENSE OF “RATIONAL” PERSONNEL SELECTION, AND TWO NEW METHODS","1976","Journal of Educational Measurement","13","1","","43","52","9","8","10.1111/j.1745-3984.1976.tb00180.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84924499695&doi=10.1111%2fj.1745-3984.1976.tb00180.x&partnerID=40&md5=f61879755828214ddb43c90d0914543b","This paper presents two new techniques for use in personnel selection. One is a simple graphical technique which non‐technical personnel can use to help in deciding how many minority applicants to admit to an institution. The other is a large‐scale computer technique which an institution can use to increase personnel diversity on many variables (including culture) simultaneously. Both techniques appear to have major advantages over the particular technique this author advocated previously (1971). However, the new techniques are based on the same general view the author has expressed earlier (1971, 1973): that personnel selection questions concerning culture must be handled rationally—that is, by human judgment—rather than by mechanical formulas. Early sections of the paper summarize and defend that view. Copyright © 1976, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84924499695"
"JENSEN A.R.","JENSEN, ARTHUR R. (7403021170)","7403021170","THE EFFECT OF RACE OF EXAMINER ON THE MENTAL TEST SCORES OF WHITE AND BLACK PUPILS","1974","Journal of Educational Measurement","11","1","","1","14","13","9","10.1111/j.1745-3984.1974.tb00965.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014198647&doi=10.1111%2fj.1745-3984.1974.tb00965.x&partnerID=40&md5=bbd41116dd43d92ac5b1f1ded4320660","An entire elementary school system with 60% white and 40% black pupils was given several abiity tests group‐administered by 12 white and eight black examiners (Es). The tests measured verbal and nonverbal IQ, perceptual‐motor cognitive development, “speed and persistence” under neutral and motivating instructions, listening‐attention, and short‐term rote memory for numbers. With the exception of the “speed and persistence” test, on which white Es yielded significantly and consistently higher mean scores than black Es for both white and black pupils across grades one to six, the results for the various cognitive ability tests showed that the race of the E did not produce large or consistent effects in the testing of white and black pupils. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85014198647"
"HOEPFNER R.; DOHERTY W.J.","HOEPFNER, RALPH (6603567303); DOHERTY, WILLIAM J. (57195042280)","6603567303; 57195042280","PRIORITIES OF TEST PUBLISHERS","1973","Journal of Educational Measurement","10","2","","85","93","8","0","10.1111/j.1745-3984.1973.tb00786.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024939202&doi=10.1111%2fj.1745-3984.1973.tb00786.x&partnerID=40&md5=b81e7755c8b05bd17a5561bf55eeaec2","The profiles of seven major publishers of elementary‐level tests were prepared from systematic ratings of the qualities of their tests. Meaningful rating differences among the publishers’ priorities were found and three types of publishers could be identified and described. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024939202"
"HANNA G.S.","HANNA, GERALD S. (24325536600)","24325536600","INCREMENTAL RELIABILITY AND VALIDITY OF MULTIPLE‐CHOICE TESTS WITH AN ANSWER‐UNTIL‐CORRECT PROCEDURE","1975","Journal of Educational Measurement","12","3","","175","178","3","15","10.1111/j.1745-3984.1975.tb01019.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994764134&doi=10.1111%2fj.1745-3984.1975.tb01019.x&partnerID=40&md5=f9e848033fbb2df760e2b3d6a3a9cc23","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84994764134"
"GOLDMAN R.D.; RICHARDS R.","GOLDMAN, ROY D. (7402001118); RICHARDS, REGINA (57195045097)","7402001118; 57195045097","THE SAT PREDICTION OF GRADES FOR MEXICAN‐AMERICAN VERSUS ANGLO‐AMERICAN STUDENTS AT THE UNIVERSITY OF CALIFORNIA, RIVERSIDE","1974","Journal of Educational Measurement","11","2","","129","135","6","14","10.1111/j.1745-3984.1974.tb00983.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973819714&doi=10.1111%2fj.1745-3984.1974.tb00983.x&partnerID=40&md5=cd776b14a5f0a8540ffcfe36d9e311e8","The regression equations for second quarter freshman grade point averages on SAT scores were calculated for Anglo‐American and Mexican‐American students at the University of California, Riverside. These regression equations differed significantly for the two groups. However, the use of the regression equation derived from the Anglo‐American sample to predict grades of Mexican‐American students resulted in overprediction. An examination of the standardized regression weights revealed a significant difference in the weight given to SATM. A replication on a much larger sample revealed a similar outcome. These results were considered as a possible heuristic to suggest a scholastic “'strategy” difference between the two ethnic groups. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973819714"
"MARCO G.L.","MARCO, GARY L. (57065132200)","57065132200","A COMPARISON OF SELECTED SCHOOL EFFECTIVENESS MEASURES BASED ON LONGITUDINAL DATA","1974","Journal of Educational Measurement","11","4","","225","234","9","16","10.1111/j.1745-3984.1974.tb00994.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988055457&doi=10.1111%2fj.1745-3984.1974.tb00994.x&partnerID=40&md5=074e16857a231367b61915d57d5f16f4","The purpose of this study was to compare nine school effectiveness indices computed by five different methods from longitudinal data. The data consisted of Total Reading scores from the Metropolitan Primary II Achievement Test administered to third‐graders in 70 elementary schools. The various school effectiveness indices differed somewhat from one another and had different correlational patterns with other variables. Further, most of the school effectiveness indices were highly stable across samples. The methods should be tried out in schools of reputed quality, so that the validities of the various indices can be studied. The stabilities of the various school effectiveness indices over time should also be studied. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988055457"
"WASHINGTON W.N.; GODFREY R.R.","WASHINGTON, WILLIAM N. (57030066200); GODFREY, R. RICHARD (57195041021)","57030066200; 57195041021","THE EFFECTIVENESS OF ILLUSTRATED ITEMS","1974","Journal of Educational Measurement","11","2","","121","124","3","5","10.1111/j.1745-3984.1974.tb00981.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911149174&doi=10.1111%2fj.1745-3984.1974.tb00981.x&partnerID=40&md5=3ce8ded845c08fedde920b706d4434e5","Two problems in test development relate to the use of illustrations: (1) Do illustrated items perform better than written items, and (2) Does item performance vary as a function of the type and size of the illustration? A sample of 63 tests was drawn from all the Air Force Specialty Knowledge Tests containing illustrations. These 63 tests had been administered to approximately 28,261 airmen under operational conditions. Item statistics between illustrated and written items drawn from the same content areas were compared using F ratios. The results indicated: (1) That illustrated items in general performed slightly better than matched written items; (2) That the best‐performing category of illustrated items was tables. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84911149174"
"BAUSELL R.B.; SCHWARTZ S.; PUROHIT A.","BAUSELL, R. BARKER (7003552786); SCHWARTZ, STANLEY (57215758385); PUROHIT, ANAL (57215759712)","7003552786; 57215758385; 57215759712","AN EXAMINATION OF THE CONDITIONS UNDER WHICH VARIOUS STUDENT RATING PARAMETERS REPLICATE ACROSS TIME","1975","Journal of Educational Measurement","12","4","","273","280","7","15","10.1111/j.1745-3984.1975.tb01028.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017269448&doi=10.1111%2fj.1745-3984.1975.tb01028.x&partnerID=40&md5=c871fc79a56ae04ba44b438ec356a0b4","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85017269448"
"DIAMOND J.J.","DIAMOND, JAMES J. (57018442400)","57018442400","A PRELIMINARY STUDY OF THE RELIABILITY AND VALIDITY OF A SCORING PROCEDURE BASED UPON CONFIDENCE AND PARTIAL INFORMATION","1975","Journal of Educational Measurement","12","2","","129","133","4","5","10.1111/j.1745-3984.1975.tb01016.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977046451&doi=10.1111%2fj.1745-3984.1975.tb01016.x&partnerID=40&md5=432a646925d37a5a3b42d3626131640a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84977046451"
"RAMOS R.A.; STERN J.","RAMOS, ROBERT A. (57646203800); STERN, JUNE (57195041228)","57646203800; 57195041228","ITEM BEHAVIOR ASSOCIATED WITH CHANGES IN THE NUMBER OF ALTERNATIVES IN MULTIPLE CHOICE ITEMS","1973","Journal of Educational Measurement","10","4","","305","310","5","8","10.1111/j.1745-3984.1973.tb00808.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973845252&doi=10.1111%2fj.1745-3984.1973.tb00808.x&partnerID=40&md5=6f394b0a17cc304457187638fba9d47b","Language reading examinations in French and Spanish were administered to students in order to compare the behavior of “natural” four‐choice items with “natural” five‐choice items rescored as four‐choice items after removing the least popular incorrect alternative. No significant differences in the regression systems of these items were found. However, “natural” four‐choice items were significantly less reliable than “natural” five‐choice items. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973845252"
"MUELLER D.J.; SHWEDEL A.","MUELLER, DANIEL J. (8967208200); SHWEDEL, ALLAN (6506824959)","8967208200; 6506824959","SOME CORRELATES OF NET GAIN RESULTANT FROM ANSWER CHANGING ON OBJECTIVE ACHIEVEMENT TEST ITEMS","1975","Journal of Educational Measurement","12","4","","251","254","3","25","10.1111/j.1745-3984.1975.tb01026.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988050680&doi=10.1111%2fj.1745-3984.1975.tb01026.x&partnerID=40&md5=6a51102e4bfd46c5a62c6ee4d3f72c22","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988050680"
"BECK M.D.","BECK, MICHAEL D. (58381248900)","58381248900","ACHIEVEMENT TEST RELIABILITY AS A FUNCTION OF PUPIL‐RESPONSE PROCEDURES","1974","Journal of Educational Measurement","11","2","","109","114","5","3","10.1111/j.1745-3984.1974.tb00979.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85023731780&doi=10.1111%2fj.1745-3984.1974.tb00979.x&partnerID=40&md5=ec6dc39db9cb714e7b99b1ab90b71c01","Muller, Calhoun, and Orling (1972) conclude that test reliability is dependent on the type of answer document used by elementary pupils. The present study was designed in part to assess the differential effect of two pupil response procedures (answering directly in the test booklet versus on a separate answer folder) on Metropolitan Achievement Tests scores of grades 3 and 4 pupils. Over 4000 pupils from nine school systems took the Metropolitan, half responding in their booklets and half using answer folders. The two groups were matched by grade in general scholastic aptitude. Although the separate answer folder group received lower scores than did the group responding in the test booklets, the score reliabilities did not differ significantly for any test. Additionally, these reliabilities did not differ significantly from comparable Metropolitan normative reliabilities. For survey achievement tests such as Metropolitan, test reliability would not appear to depend on pupil response mode. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85023731780"
"TRENTHAM L.L.","TRENTHAM, LANDA L. (6505586268)","6505586268","THE EFFECT OF DISTRACTIONS ON SIXTH‐GRADE STUDENTS IN A TESTING SITUATION","1975","Journal of Educational Measurement","12","1","","13","16","3","2","10.1111/j.1745-3984.1975.tb01004.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950617124&doi=10.1111%2fj.1745-3984.1975.tb01004.x&partnerID=40&md5=cbe2bad6a12ca308041c2a46c70c0a4e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-77950617124"
"WOODSON M.I.CHAS.E.","WOODSON, M.I.CHAS.E. (6602718801)","6602718801","THE ISSUE OF ITEM AND TEST VARIANCE FOR CRITERION‐REFERENCED TESTS","1974","Journal of Educational Measurement","11","1","","63","64","1","7","10.1111/j.1745-3984.1974.tb00973.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024955247&doi=10.1111%2fj.1745-3984.1974.tb00973.x&partnerID=40&md5=1d1b78466fd22b7c893549afccb02644","It has been argued that item variance and test variance are not necessary characteristics for criterion‐referenced tests, although they are necessary for normreferenced tests. This position is in error because it considers sample statistics as the criteria for evaluating items and tests. Within a particular sample, an item or test may have no variance, but in the population of observations for which the test was designed, calibrated, and evaluated, both items and tests must have variance. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024955247"
"BHUSHAN V.","BHUSHAN, VIDYA (57189189656)","57189189656","ADAPTATION OF AN INTELLIGENCE TEST FROM ENGLISH TO FRENCH","1974","Journal of Educational Measurement","11","1","","43","48","5","2","10.1111/j.1745-3984.1974.tb00969.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965928412&doi=10.1111%2fj.1745-3984.1974.tb00969.x&partnerID=40&md5=dabd3a95836e95c9118130f682314254","This study aimed to discover the usefulness of adapting the Otis Quick‐Scoring Mental Ability Tests for the French culture. Beta Test (Forms EM and FM) were translated into French and administered to 635 students of grades four to eight. To correct invalid items or distractors, a revision followed the statistical analysis. Revised tests were then administered to 1,686 students of grades five to nine. From this and related studies, it is concluded that an intelligence test developed for a particular culture may be invalid when simply translated for another. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965928412"
"SWAMINATHAN H.; HAMBLETON R.K.; ALGINA J.","SWAMINATHAN, H. (6602382602); HAMBLETON, RONALD K. (7006242264); ALGINA, JAMES (7003768166)","6602382602; 7006242264; 7003768166","RELIABILITY OF CRITERION‐REFERENCED TESTS: A DECISION‐THEORETIC FORMULATION","1974","Journal of Educational Measurement","11","4","","263","267","4","65","10.1111/j.1745-3984.1974.tb00998.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951580160&doi=10.1111%2fj.1745-3984.1974.tb00998.x&partnerID=40&md5=fbd8fac5527f99c4d6194e37734052df","It has been suggested that the primary purpose for criterion‐referenced testing in objective‐based instructional programs is to classify examinees into mastery states or categories on the objectives included in the test. We have proposed that the reliability of the criterion‐referenced test scores be defined in terms of the consistency of the decision‐making process across repeated administrations of the test. Specifically, reliability is defined as a measure of agreement over and above that which can be expected by chance between the decisions made about examinee mastery states in repeated test administrations for each objective measured by the criterion‐referenced test. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84951580160"
"GRIER J.B.","GRIER, J. BROWN (57197379059)","57197379059","THE NUMBER OF ALTERNATIVES FOR OPTIMUM TEST RELIABILITY","1975","Journal of Educational Measurement","12","2","","109","112","3","52","10.1111/j.1745-3984.1975.tb01013.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982967044&doi=10.1111%2fj.1745-3984.1975.tb01013.x&partnerID=40&md5=ba63c60e71e375a4927439de4793bcf4","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84982967044"
"REILLY R.R.; JACKSON R.","REILLY, RICHARD R. (7102935742); JACKSON, REX (57195041622)","7102935742; 57195041622","EFFECTS OF EMPIRICAL OPTION WEIGHTING ON RELIABILITY AND VALIDITY OF AN ACADEMIC APTITUDE TEST","1973","Journal of Educational Measurement","10","3","","185","193","8","17","10.1111/j.1745-3984.1973.tb00796.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011868239&doi=10.1111%2fj.1745-3984.1973.tb00796.x&partnerID=40&md5=685cece6de005870b67af13d5b630102","Item options of shortened forms of the GRE Verbal and Quantitative tests were empirically weighted by two variants of a method originally attributed to Guttman (1941). When compared with formula scores, it was found that tests scored with the empirical weights were more reliable but less valid when correlated with undergraduate GPA. A factor analysis revealed large increases in variance accounted for by the first factor. It was suggested that the weighting procedures used tended to capitalize on omitting behavior which, although a highly reliable tendency, may be invalid. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85011868239"
"GOLDMAN R.D.; HEWITT B.N.","GOLDMAN, ROY D. (7402001118); HEWITT, BARBARA NEWLIN (14833726300)","7402001118; 14833726300","AN INVESTIGATION OF TEST BIAS FOR MEXICAN‐AMERICAN COLLEGE STUDENTS","1975","Journal of Educational Measurement","12","3","","187","196","9","8","10.1111/j.1745-3984.1975.tb01021.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-66749152313&doi=10.1111%2fj.1745-3984.1975.tb01021.x&partnerID=40&md5=586d25dc5b073cf2207ffb526e8e89f2","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-66749152313"
"LEVIN J.R.","LEVIN, JOEL R. (7403286430)","7403286430","DETERMINING SAMPLE SIZE FOR PLANNED AND POST HOC ANALYSIS OF VARIANCE COMPARISONS","1975","Journal of Educational Measurement","12","2","","99","108","9","39","10.1111/j.1745-3984.1975.tb01012.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039516289&doi=10.1111%2fj.1745-3984.1975.tb01012.x&partnerID=40&md5=14fe93df6611fd348e33a24c4777d9bd","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0039516289"
"CREHAN K.D.; KOEHLER R.A.; SLAKTER M.J.","CREHAN, KEVIN D. (6603214066); KOEHLER, ROGER A. (57029863300); SLAKTER, MALCOLM J. (6603541799)","6603214066; 57029863300; 6603541799","LONGITUDINAL STUDIES OF TEST‐WISENESS","1974","Journal of Educational Measurement","11","3","","209","212","3","9","10.1111/j.1745-3984.1974.tb00992.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970467365&doi=10.1111%2fj.1745-3984.1974.tb00992.x&partnerID=40&md5=ded28ea2ba3acd6853322737f29f55a6","Longitudinal studies were conducted to examine test‐wiseness (tw) with respect to (a) grade differences, (b) grade by sex interaction, and (c) stability. Included in the tw measure were stem‐option, absurd‐options, similar‐options, and specific‐determiners. Ss were students in grades 5 through 11; 539 Ss were observed twice with a 2 year interval between observations. Results indicated (a) significant increases on tw in four of five cases, (b) no sex by grade interaction, and (c) tw as a stable characteristic over the grade levels studied. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970467365"
"TAMIR P.","TAMIR, PINCHAS (6603410369)","6603410369","AN INQUIRY ORIENTED LABORATORY EXAMINATION","1974","Journal of Educational Measurement","11","1","","25","33","8","52","10.1111/j.1745-3984.1974.tb00967.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989144134&doi=10.1111%2fj.1745-3984.1974.tb00967.x&partnerID=40&md5=db7d8c88cc0adf6352d19b8f93e5f29e","Having discussed the dearth of testing of actual performance in real situations, a variety of arguments are raised to support the need for assessment in the Practical mode, and the development and nature of an inquiry oriented laboratory examination is described. One test problem is presented in detail including materials, instructions to examinees, instructions for administration and scoring as well as sample answers. Data regarding validity and reliability are provided together with findings pertaining to the relationship between the various skills assessed by the examination. Moderation procedures for determining the individual scores in an examination in which different students perform different test problems are suggested. The author contends that the type of examination described reflects the inquiry objectives of the BSCS philosophy and provides a valid and reliable measure of problem solving ability in a practical laboratory setting. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84989144134"
"NOVICK M.R.; PETERSEN N.S.","NOVICK, MELVIN R. (16513922700); PETERSEN, NANCY S. (57195042674)","16513922700; 57195042674","TOWARDS EQUALIZING EDUCATIONAL AND EMPLOYMENT OPPORTUNITY","1976","Journal of Educational Measurement","13","1","","77","88","11","13","10.1111/j.1745-3984.1976.tb00183.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040791512&doi=10.1111%2fj.1745-3984.1976.tb00183.x&partnerID=40&md5=8fe92ccf8f41f17d020197f509632f8e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0040791512"
"DAVIS G.A.; SUBKOVIAK M.J.","DAVIS, GARY A. (7404343458); SUBKOVIAK, MICHAEL J. (6506489478)","7404343458; 6506489478","MULTIDIMENSIONAL ANALYSIS OF A PERSONALITY‐BASED TEST OF CREATIVE POTENTIAL","1975","Journal of Educational Measurement","12","1","","37","43","6","43","10.1111/j.1745-3984.1975.tb01007.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954676939&doi=10.1111%2fj.1745-3984.1975.tb01007.x&partnerID=40&md5=c6cbd717edc3f2f5cba2a5672e70898a","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84954676939"
"MARCO G.L.; MURPHY R.T.; QUIRK T.J.","MARCO, GARY L. (57065132200); MURPHY, RICHARD T. (57195041269); QUIRK, THOMAS J. (15521541800)","57065132200; 57195041269; 15521541800","A CLASSIFICATION OF METHODS OF USING STUDENT DATA TO ASSESS SCHOOL EFFECTIVENESS","1976","Journal of Educational Measurement","13","4","","243","252","9","3","10.1111/j.1745-3984.1976.tb00015.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954652893&doi=10.1111%2fj.1745-3984.1976.tb00015.x&partnerID=40&md5=05e48708c9e0cf8b8a341f55b94c3fa6","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-77954652893"
"ROWLEY G.L.","ROWLEY, GLENN L. (7006131497)","7006131497","WHICH EXAMINEES ARE MOST FAVOURED BY THE USE OF MULTIPLE CHOICE TESTS?","1974","Journal of Educational Measurement","11","1","","15","23","8","19","10.1111/j.1745-3984.1974.tb00966.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037650719&doi=10.1111%2fj.1745-3984.1974.tb00966.x&partnerID=40&md5=be4f84b4838b28792dce15f17f6ada14","Scores were obtained from 198 ninth grade students on achievement motivation, test anxiety, testwiseness, and risktaking. Tests in mathematics and vocabulary were constructed in free response and multiple choice form, and administered to the subjects in that order, with an interval of 5 weeks between administrations. Partial correlations were computed between scores on the multiple choice tests and achievement motivation, test anxiety, testwiseness, and risktaking, with free response scores partialled out. The partial correlations were corrected for the unreliability in the free response scores, and tested for significance. All partials involving achievement motivation and test anxiety were nonsignificant, as were all partials based on mathematics scores. The partial correlations of vocabulary scores with testwiseness and risktaking were significant without exception. It was concluded that the use of multiple choice tests can favour certain examinees those who are highly testwise and willing to take risks in the test situation. It was noted that the extent to which these examinees were favoured was dependent on the nature of the test, and that a verbal test seemed more susceptible than a numerical test. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0037650719"
"BRELAND H.M.; IRONSON G.H.","BRELAND, HUNTER M. (6506538277); IRONSON, GAIL H. (7006098861)","6506538277; 7006098861","DEFUNIS RECONSIDERED: A COMPARATIVE ANALYSIS OF ALTERNATIVE ADMISSIONS STRATEGIES","1976","Journal of Educational Measurement","13","1","","89","99","10","10","10.1111/j.1745-3984.1976.tb00184.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901704854&doi=10.1111%2fj.1745-3984.1976.tb00184.x&partnerID=40&md5=17dcf175d7fd60098030127f1e0098e4","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84901704854"
"MATHEWS W.M.","MATHEWS, WALTER M. (7102188507)","7102188507","NARRATIVE FORMAT TESTING REPORTS AND TRADITIONAL TESTING REPORTS: A COMPARATIVE STUDY","1973","Journal of Educational Measurement","10","3","","171","178","7","1","10.1111/j.1745-3984.1973.tb00794.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024959317&doi=10.1111%2fj.1745-3984.1973.tb00794.x&partnerID=40&md5=8c7687274977e62987d609880fc0703f","This article reports a comparative study of teacher acceptance of two kinds of testing reports that were generated for Form A of the Iowa Tests of Basic Skills at the fourth‐grade level. Locally produced reports similar to the traditional ones provided by the test publisher were evaluated against experimental reports that were computer generated in a narrative format. On a random basis, 52 teachers from 16 schools received either the traditional or experimental testing reports for their class, and were asked to evaluate the reports on six scales: clear, useful, meaningful, valuable, sufficient, and accurate, for each of three purposes: information for the teacher on individual students, class‐summary information, and information for use at a parent‐teacher meeting. On 15 of the 18 comparisons between the traditional and experimental reports, the experimental reports were rated significantly higher. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024959317"
"WRIGHT R.J.; BEAN A.G.","WRIGHT, ROBERT J. (57012365400); BEAN, ANDREW G. (56987232600)","57012365400; 56987232600","THE INFLUENCE OF SOCIOECONOMIC STATUS ON THE PREDICTABILITY OF COLLEGE PERFORMANCE","1974","Journal of Educational Measurement","11","4","","277","284","7","11","10.1111/j.1745-3984.1974.tb01000.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965576208&doi=10.1111%2fj.1745-3984.1974.tb01000.x&partnerID=40&md5=bbe80ad85e33358a388803006fcb0e6e","Although numerous studies have examined the validity of scholastic aptitude measures as predictors of college performance for black and white students, few studies have investigated the validity of these predictors for different socioeconomic levels within a racially homogeneous population. To study the influence of socioeconomic status (SES) on the predictability of college performance, a sample of 1,631 white freshmen attending a large urban university was divided into homogeneous subgroups on each of three measures: (a) family income, (b) father's occupation, and (c) mother's education. Verbal and Quantitative Scholastic Aptitude Test scores and high school class rank were used to predict freshman grade‐point average within each subgroup. For all three socioeconomic measures, lower cross‐validated multiple correlations were associated with lower levels of SES. Possible explanations for these results are discussed and implications for research are presented. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965576208"
"GOLDMAN R.D.","GOLDMAN, ROY D. (7402001118)","7402001118","HIDDEN OPPORTUNITIES IN THE PREDICTION OF COLLEGE GRADES FOR DIFFERENT SUBGROUPS","1973","Journal of Educational Measurement","10","3","","205","210","5","2","10.1111/j.1745-3984.1973.tb00798.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024977926&doi=10.1111%2fj.1745-3984.1973.tb00798.x&partnerID=40&md5=9295c797a4676633a43ea77659ef8a0a","The purpose of this paper was to examine the problems and opportunities of academic prediction for different ethnic groups. Several recent studies of academic prediction for blacks and whites were reviewed in regard to: 1) the situation in which the data were obtained; 2) the prediction technique employed, and 3) the data distribution likely to give rise to the obtained prediction indices. It was suggested that a total‐group regression equation which “benefits” a minority group by overpredicting mean grade may actually be very disadvantageous if accompanied by a large error of estimate. The damage can be produced by precluding selection of the most qualified minority group members and thus lowering the groups’ performance. Differential process theory was proposed as a potential source of explanations for differential prediction. It was proposed that alternative strategic approaches to scholastic tasks might alter the covariance of predictor tests with grades. Finally, it was suggested that, under certain circumstances, the patterns of standardized regression weights in the prediction of grades, might suggest group difference in problem‐solving strategies. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024977926"
"LEWY A.; SHAVIT S.","LEWY, ARIEH (56968378400); SHAVIT, SHLOMO (57195044387)","56968378400; 57195044387","TYPES OF EXAMINATIONS IN HISTORY STUDIES","1974","Journal of Educational Measurement","11","1","","35","42","7","1","10.1111/j.1745-3984.1974.tb00968.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846912896&doi=10.1111%2fj.1745-3984.1974.tb00968.x&partnerID=40&md5=0444380ee01f3eebd8cb6496f2a1c306","In psychometric studies disagreement among experts is frequently treated as error void of informational value. The present study deviates from this approach and utilizes disagreement among experts in item classification as a source for examining the structural characteristics of the classification scheme. Guttman's smallest space analysis applied to an agreement‐disagreement matrix suggests that the item‐classification scheme reflects two different approaches to testing outcomes of studying history: that of the cognitive psychology and that of the philosophy of history. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-33846912896"
"JESSELL J.C.; SULLINS W.L.","JESSELL, JOHN C. (16420423200); SULLINS, WALTER L. (57189192443)","16420423200; 57189192443","THE EFFECT OF KEYED RESPONSE SEQUENCING OF MULTIPLE CHOICE ITEMS ON PERFORMANCE AND RELIABILITY","1975","Journal of Educational Measurement","12","1","","45","48","3","9","10.1111/j.1745-3984.1975.tb01008.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009865724&doi=10.1111%2fj.1745-3984.1975.tb01008.x&partnerID=40&md5=4de0633b38c3b9b1a5ca5e0a50ce369d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85009865724"
"POHLMANN J.T.; ELMORE P.B.","POHLMANN, JOHN T. (8921675000); ELMORE, PATRICIA B. (8633569000)","8921675000; 8633569000","THE INSTRUCTIONAL IMPROVEMENT QUESTIONNAIRE","1976","Journal of Educational Measurement","13","2","","161","163","2","1","10.1111/j.1745-3984.1976.tb00008.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79955376614&doi=10.1111%2fj.1745-3984.1976.tb00008.x&partnerID=40&md5=1b8efe05a925f38a48d850311264a0ac","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-79955376614"
"THISSEN D.M.","THISSEN, DAVID M. (7003712685)","7003712685","INFORMATION IN WRONG RESPONSES TO THE RAVEN PROGRESSIVE MATRICES","1976","Journal of Educational Measurement","13","3","","201","214","13","53","10.1111/j.1745-3984.1976.tb00011.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000584576&doi=10.1111%2fj.1745-3984.1976.tb00011.x&partnerID=40&md5=a4d6c947a082a0a717577361b360fad1","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0000584576"
"HUYNH H.","HUYNH, HUYNH (16512875100)","16512875100","ON THE RELIABILITY OF DECISIONS IN DOMAIN‐REFERENCED TESTING","1976","Journal of Educational Measurement","13","4","","253","264","11","95","10.1111/j.1745-3984.1976.tb00016.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000347934&doi=10.1111%2fj.1745-3984.1976.tb00016.x&partnerID=40&md5=3c32bb8a2edfe0fbeaf2405835928aef","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0000347934"
"ORY J.C.; POGGIO J.P.","ORY, JOHN C. (7004670778); POGGIO, JOHN P. (16442357300)","7004670778; 16442357300","THE EMPIRICAL DEVELOPMENT OF A MEASURE OF ACHIEVEMENT MOTIVATION","1976","Journal of Educational Measurement","13","2","","157","159","2","1","10.1111/j.1745-3984.1976.tb00007.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948071686&doi=10.1111%2fj.1745-3984.1976.tb00007.x&partnerID=40&md5=e808148575ab72d5d593bf1e5e941e03","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84948071686"
"CENTRA J.A.","CENTRA, JOHN A. (6603207332)","6603207332","THE INFLUENCE OF DIFFERENT DIRECTIONS ON STUDENT RATINGS OF INSTRUCTION","1976","Journal of Educational Measurement","13","4","","277","282","5","20","10.1111/j.1745-3984.1976.tb00018.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965780764&doi=10.1111%2fj.1745-3984.1976.tb00018.x&partnerID=40&md5=8e51eceb6b73c264f61a0b2f6341e0b9","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84965780764"
"HAKSTIAN A.R.; KANSUP W.","HAKSTIAN, A. RALPH (6701603762); KANSUP, WANLOP (57195043408)","6701603762; 57195043408","A COMPARISON OF SEVERAL METHODS OF ASSESSING PARTIAL KNOWLEDGE IN MULTIPLE‐CHOICE TESTS: II. TESTING PROCEDURES","1975","Journal of Educational Measurement","12","4","","231","239","8","24","10.1111/j.1745-3984.1975.tb01024.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988077824&doi=10.1111%2fj.1745-3984.1975.tb01024.x&partnerID=40&md5=d8f8fdcb2cb1819dc6dd53f68eb16088","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84988077824"
"MILLMAN J.; POPHAM W.J.","MILLMAN, JASON (25954577400); POPHAM, W. JAMES (6701761956)","25954577400; 6701761956","THE ISSUE OF ITEM AND TEST VARIANCE FOR CRITERION‐REFERENCED TESTS: A CLARIFICATION","1974","Journal of Educational Measurement","11","2","","137","138","1","5","10.1111/j.1745-3984.1974.tb00984.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024980957&doi=10.1111%2fj.1745-3984.1974.tb00984.x&partnerID=40&md5=6a41db7d30a4056a86f04530f588c1bb","This note contends that item or score variability is an unnecessary characteristic of criterion‐referenced tests as they have been traditionally conceived, namely, as measures of well defined classes of examinee behaviors. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024980957"
"GOLDMAN R.D.; HEWITT B.N.","GOLDMAN, ROY D. (7402001118); HEWITT, BARBARA NEWLIN (14833726300)","7402001118; 14833726300","ADAPTATION‐LEVEL AS AN EXPLANATION FOR DIFFERENTIAL STANDARDS IN COLLEGE GRADING","1975","Journal of Educational Measurement","12","3","","149","161","12","29","10.1111/j.1745-3984.1975.tb01017.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000303326&doi=10.1111%2fj.1745-3984.1975.tb01017.x&partnerID=40&md5=b29895a1272142cebfdae7337389b6e5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0000303326"
"CENTRA J.A.","CENTRA, JOHN A. (6603207332)","6603207332","SELF‐RATINGS OF COLLEGE TEACHERS: A COMPARISON WITH STUDENT RATINGS","1973","Journal of Educational Measurement","10","4","","287","295","8","40","10.1111/j.1745-3984.1973.tb00806.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016368002&doi=10.1111%2fj.1745-3984.1973.tb00806.x&partnerID=40&md5=27b51630bec0647ba43c4eff26370e35","College teachers’ self‐ratings were investigated in this study by comparing them to ratings given by students. The sample consisted of 343 teaching faculty from five colleges; these teachers, as well as the students in one of their classes, responded to a 21‐item instructional report questionnaire. Teacher self‐ratings had only a modest relationship with the ratings given by students (a median correlation of .21 for the items). In addition to the general lack of agreement between self and student evaluations, there was also a tendency for teachers as a group to give themselves better ratings than their students did. Discrepancies between individual teacher ratings and ratings given by the class were further analyzed for: (a) sex of the teacher (no difference found); (b) number of years of teaching experience (no difference); and (c) subject area of the course (differences noted for natural science courses vs. those in education and applied areas). Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85016368002"
"SAWYER R.L.; COLE N.S.; COLE J.W.L.","SAWYER, RICHARD L. (7201516630); COLE, NANCY S. (38961260400); COLE, JAMES W. L. (56951434900)","7201516630; 38961260400; 56951434900","UTILITIES AND THE ISSUE OF FAIRNESS IN A DECISION THEORETIC MODEL FOR SELECTION","1976","Journal of Educational Measurement","13","1","","59","76","17","22","10.1111/j.1745-3984.1976.tb00182.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039013059&doi=10.1111%2fj.1745-3984.1976.tb00182.x&partnerID=40&md5=14a231745fd74688d8d3a10ae23b0fd1","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0039013059"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","VARIANCE STABILIZING TRANSFORMATION OF THE STEPPED‐UP RELIABILITY COEFFICIENT","1974","Journal of Educational Measurement","11","1","","55","57","2","6","10.1111/j.1745-3984.1974.tb00971.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33748776745&doi=10.1111%2fj.1745-3984.1974.tb00971.x&partnerID=40&md5=60e163aece30b0e5197c7dfcc26b08f5","The stepped‐up reliability coefficient does not have the same standard error as an ordinary correlation coefficient. Fisher's z‐transformation should not be applied to it. Appropriate procedures are suggested. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-33748776745"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","QUICK ESTIMATES OF THE RELATIVE EFFICIENCY OF TWO TESTS AS A FUNCTION OF ABILITY LEVEL","1974","Journal of Educational Measurement","11","4","","247","254","7","8","10.1111/j.1745-3984.1974.tb00996.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77952665718&doi=10.1111%2fj.1745-3984.1974.tb00996.x&partnerID=40&md5=4ae1bb5065bb2b8e7e993bf99b32e6ab","When comparing two tests that measure the same trait, an overall comparison is not enough. Separate comparisons should be made at different levels of the trait. A simple, practical, approximate formula is given for doing this. The adequacy of the approximation is illustrated using data comparing seven nationally known sixth‐grade reading tests. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-77952665718"
"WHITELY S.E.; DAWIS R.V.","WHITELY, SUSAN E. (16493742700); DAWIS, RENÁ V. (6508131132)","16493742700; 6508131132","THE NATURE OF OBJECTIVITY WITH THE RASCH MODEL","1974","Journal of Educational Measurement","11","3","","163","178","15","33","10.1111/j.1745-3984.1974.tb00988.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970329584&doi=10.1111%2fj.1745-3984.1974.tb00988.x&partnerID=40&md5=b255bff0fdb472bac300339f285e9304","Although it has been claimed that the Rasch model leads to a higher degree of objectivity in measurement than has been previously possible, this model has had little impact on test development. Population‐invariant item and ability calibrations, together with the statistical equivalency of any two item subsets, are supposedly possible if the item pool has been calibrated by the Rasch model. Initial research has been encouraging, but the implications of underlying assumptions and operational computations in the Rasch model for trait theory have not been clear from previous work. The current paper presents an analysis of the conditions under which the claims of objectivity will be substantiated, with special emphasis on the nature of equivalent forms. It is concluded that the real advantages of the Rasch model will not be apparent until the technology of trait measurement becomes more sophisticated. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84970329584"
"PATNAIK D.; TRAUB R.E.","PATNAIK, DURGADAS (57195041437); TRAUB, ROSS E. (7102034665)","57195041437; 7102034665","DIFFERENTIAL WEIGHTING BY JUDGED DEGREEOF CORRECTNESS","1973","Journal of Educational Measurement","10","4","","281","286","5","14","10.1111/j.1745-3984.1973.tb00805.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988132913&doi=10.1111%2fj.1745-3984.1973.tb00805.x&partnerID=40&md5=4e485160045d80fd96d6b37afa20f48d","Two conventional scores and a weighted score on a group test of general intelligence were compared for reliability and predictive validity. One conventional score consisted of the number of correct answers an examinee gave in responding to 69 multiple‐choice questions; the other was the formula score obtained by subtracting from the number of correct answers a fraction of the number of wrong answers. A weighted score was obtained by assigning weights to all the response alternatives of all the questions and adding the weights associated with the responses, both correct and incorrect, made by the examinee. The weights were derived from degree‐of‐correctness judgments of the set of response alternatives to each question. Reliability was estimated using a split‐half procedure; predictive validity was estimated from the correlation between test scores and mean school achievement. Both conventional scores were found to be significantly less reliable but significantly more valid than the weighted scores. (The formula scores were neither significantly less reliable nor significantly more valid than number‐correct scores.) Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988132913"
"FRISBIE D.A.","FRISBIE, DAVID A. (7003704007)","7003704007","MULTIPLE CHOICE VERSUS TRUE‐FALSE: A COMPARISON OF RELIABILITIES AND CONCURRENT VALIDITIES","1973","Journal of Educational Measurement","10","4","","297","304","7","25","10.1111/j.1745-3984.1973.tb00807.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005230500&doi=10.1111%2fj.1745-3984.1973.tb00807.x&partnerID=40&md5=f8376a6e0e9ce11c496ca75b33aadd8e","The purpose of this study was to compare the reliabilities of true‐false (TF) and multiple choice (MC) tests and to determine the concurrent validities of both. Two methods, judgmental and discrimination, were devised for objectively converting MC items to TF form. The TF items generated by the two methods from 70‐item MC natural science and social studies tests were incorporated in eight final forms which were differentiated by subject matter, conversion method, and item form order. A sample of 1018 nonurban high school students each responded to one of the eight forms. Examinees tried three TF items for every pair of MC items attempted. The TF tests were significantly less reliable than the MC tests but did tend to measure the same thing as the corresponding MC tests. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85005230500"
"LOEB J.; BOWERS J.","LOEB, JANE (55186213500); BOWERS, JOHN (56951937400)","55186213500; 56951937400","PROGRAMS OF STUDY AS A BASIS FOR SELECTION, PLACEMENT AND GUIDANCE OF COLLEGE STUDENTS","1973","Journal of Educational Measurement","10","2","","131","139","8","0","10.1111/j.1745-3984.1973.tb00790.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024992363&doi=10.1111%2fj.1745-3984.1973.tb00790.x&partnerID=40&md5=9cc27a734dcece1c6ca642fd4c3ced38","Studies of collegiate success and attrition are generally conducted at the all‐college level. The definition of academic programs that are homogeneous in the abilities and interests of their students and the grading standards of their faculties may lead to more accurate prediction of success and more effective control of attrition. Homogeneous curricular groups were defined via Ward's hierarchical grouping analysis applied to curricular means on high school percentile rank, four ACT subscores, first semester GPA, and 16 Kuder scores. Programs so defined differed on scientific‐verbal and competitive level dimensions. Prediction of grades was more accurate within programs than colleges. Drop and transfer rates were correlated with discriminant scores. The programs are discussed as promising units within which differential selection and placement strategies might reduce attrition. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024992363"
"AIRASIAN P.W.; BART W.M.","AIRASIAN, PETER W. (6505790573); BART, WILLIAM M. (6602762607)","6505790573; 6602762607","VALIDATING A PRIORI INSTRUCTIONAL HIERARCHIES","1975","Journal of Educational Measurement","12","3","","163","173","10","14","10.1111/j.1745-3984.1975.tb01018.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987255601&doi=10.1111%2fj.1745-3984.1975.tb01018.x&partnerID=40&md5=737e94a5d3e0dc6b69c38fa8813ade1e","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987255601"
"STRANG H.R.; BRIDGEMAN B.; CARRICO M.F.","STRANG, HAROLD R. (6603236345); BRIDGEMAN, BRENT (7005526936); CARRICO, MARY F. (57195043755)","6603236345; 7005526936; 57195043755","EFFECTS OF “GAME” VERSUS “TEST” TASK DEFINITION FOR THIRD GRADE CHILDREN ON THREE SUBTESTS OF THE WECHSLER INTELLIGENCE SCALE FOR CHILDREN","1974","Journal of Educational Measurement","11","2","","125","128","3","6","10.1111/j.1745-3984.1974.tb00982.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011188973&doi=10.1111%2fj.1745-3984.1974.tb00982.x&partnerID=40&md5=214790753a1330ba314d33c5ea792b70","Forty‐six male and forty‐six female third grade children were assigned to one of two experimental conditions. In one condition Ss were told that they were going to take several tests and were than administered three subtests from the nonverbal battery of the WISC. In the second condition Ss were told that they were going to play several games and were than administered the same three subtests. An analysis of variance applied to the resulting summed scores revealed one significant main effect, task definition (p < .01). Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85011188973"
"POHLMANN J.T.","POHLMANN, JOHN T. (8921675000)","8921675000","A DESCRIPTION OF TEACHING EFFECTIVENESS AS MEASURED BY STUDENT RATINGS","1975","Journal of Educational Measurement","12","1","","49","54","5","16","10.1111/j.1745-3984.1975.tb01009.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994942571&doi=10.1111%2fj.1745-3984.1975.tb01009.x&partnerID=40&md5=d60e189fa62feda98c0a13c38b28bd7b","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84994942571"
"TOWLE N.J.; MERRILL P.F.","TOWLE, NELSON J. (57030287200); MERRILL, PAUL F. (24828783400)","57030287200; 24828783400","EFFECTS OF ANXIETY TYPE AND ITEM‐DIFFICULTY SEQUENCING ON MATHEMATICS TEST PERFORMANCE","1975","Journal of Educational Measurement","12","4","","241","249","8","24","10.1111/j.1745-3984.1975.tb01025.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988091859&doi=10.1111%2fj.1745-3984.1975.tb01025.x&partnerID=40&md5=0ab8fad2d513c3c520d02a912babc496","[No abstract available]","","","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84988091859"
"PETERSEN N.S.; NOVICK M.R.","PETERSEN, NANCY S. (57195042674); NOVICK, MELVIN R. (16513922700)","57195042674; 16513922700","AN EVALUATION OF SOME MODELS FOR CULTURE‐FAIR SELECTION","1976","Journal of Educational Measurement","13","1","","3","29","26","147","10.1111/j.1745-3984.1976.tb00178.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001924845&doi=10.1111%2fj.1745-3984.1976.tb00178.x&partnerID=40&md5=bba4ccf8eefb585d39ce4951c22faee7","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-0001924845"
"PERRIN D.W.; WHITNEY D.R.","PERRIN, DAVID W. (57195041122); WHITNEY, DOUGLAS R. (7102971846)","57195041122; 7102971846","METHODS FOR SMOOTHING EXPECTANCY TABLES APPLIED TO THE PREDICTION OF SUCCESS IN COLLEGE","1976","Journal of Educational Measurement","13","3","","223","231","8","3","10.1111/j.1745-3984.1976.tb00013.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934375585&doi=10.1111%2fj.1745-3984.1976.tb00013.x&partnerID=40&md5=f9b0011c0ac44a17318e2db58307a394","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84934375585"
"HALES L.W.; TOKAR E.","HALES, LOYDE W. (57011056600); TOKAR, EDWARD (57068494100)","57011056600; 57068494100","THE EFFECT OF THE QUALITY OF PRECEDING RESPONSES ON THE GRADES ASSIGNED TO SUBSEQUENT RESPONSES TO AN ESSAY QUESTION","1975","Journal of Educational Measurement","12","2","","115","117","2","30","10.1111/j.1745-3984.1975.tb01014.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911274234&doi=10.1111%2fj.1745-3984.1975.tb01014.x&partnerID=40&md5=643d9d83c8c5973e2f945e49bd6bd544","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84911274234"
"SIROTNIK K.; WELLINGTON R.","SIROTNIK, KEN (56360886700); WELLINGTON, ROGER (16511728500)","56360886700; 16511728500","SCRAMBLING CONTENT IN ACHIEVEMENT TESTING: AN APPLICATION OF MULTIPLE MATRIX SAMPLING IN EXPERIMENTAL DESIGN","1974","Journal of Educational Measurement","11","3","","179","188","9","5","10.1111/j.1745-3984.1974.tb00989.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84932743458&doi=10.1111%2fj.1745-3984.1974.tb00989.x&partnerID=40&md5=5d85a3ea11c892762ccd1a6e0db7d9a1","This study was designed to research the question of scrambling item content in the construction of achievement tests, so that very general implications could be drawn for both examinee and item populations. To achieve this generality, the methodology of multiple matrix sampling was combined with a simple two group experimental design: a random group of 8th graders responded to mathematics, science, social studies, reading, and language arts achievement items organized in a scrambled (random) test format, while another random group responded to the same items organized in a fixed (segregated by subject matter) test format. The results indicated that scrambling cognitive test items has minimal or no effect on mean examinee test performance or on any of the other parameters included in the analysis. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84932743458"
"WEN S.‐S.","WEN, SHIH‐SUNG (7201439859)","7201439859","THE RELATIONSHIP BETWEEN VERBAL‐MEANING TEST SCORES AND DEGREE OF CONFIDENCE IN ITEM RESPONSES","1975","Journal of Educational Measurement","12","3","","197","200","3","0","10.1111/j.1745-3984.1975.tb01022.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024961413&doi=10.1111%2fj.1745-3984.1975.tb01022.x&partnerID=40&md5=34a6e1e70bfac25ec47299e311870c72","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024961413"
"EBEL R.L.","EBEL, ROBERT L. (16050366400)","16050366400","CAN TEACHERS WRITE GOOD TRUE‐FALSE TEST ITEMS?","1975","Journal of Educational Measurement","12","1","","31","35","4","6","10.1111/j.1745-3984.1975.tb01006.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-5144230450&doi=10.1111%2fj.1745-3984.1975.tb01006.x&partnerID=40&md5=7c2642d566fa6ad1a9836dd5dc30b777","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-5144230450"
"HAMBLETON R.K.; NOVICK M.R.","HAMBLETON, RONALD K. (7006242264); NOVICK, MELVIN R. (16513922700)","7006242264; 16513922700","TOWARD AN INTEGRATION OF THEORY AND METHOD FOR CRITERION‐REFERENCED TESTS","1973","Journal of Educational Measurement","10","3","","159","170","11","135","10.1111/j.1745-3984.1973.tb00793.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005366630&doi=10.1111%2fj.1745-3984.1973.tb00793.x&partnerID=40&md5=9c0e3ebe58d3bc6eee4272287f3f7126","In this paper, an attempt has been made to synthesize some of the current thinking in the area of criterion‐referenced testing as well as to provide the beginning of an integration of theory and method for such testing. Since criterion‐referenced testing is viewed from a decision‐theoretic point of view, approaches to reliability and validity estimation consistent with this philosophy are suggested. Also, to improve the decision‐making accuracy of criterion‐referenced tests, a Bayesian procedure for estimating true mastery scores has been proposed. This Bayesian procedure uses information about other members of a student's group (collateral information), but the resulting estimation is still criterion referenced rather than norm referenced in that the student is compared to a standard rather than to other students. In theory, the Bayesian procedure increases the “effective length” of the test by improving the reliability, the validity, and more importantly, the decision‐making accuracy of the criterion‐referenced test scores. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85005366630"
"MEDLEY D.M.; QUIRK T.J.","MEDLEY, DONALD M. (16448650500); QUIRK, THOMAS J. (15521541800)","16448650500; 15521541800","THE APPLICATION OF A FACTORIAL DESIGN TO THE STUDY OF CULTURAL BIAS IN GENERAL CULTURE ITEMS ON THE NATIONAL TEACHER EXAMINATION","1974","Journal of Educational Measurement","11","4","","235","245","10","20","10.1111/j.1745-3984.1974.tb00995.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040517889&doi=10.1111%2fj.1745-3984.1974.tb00995.x&partnerID=40&md5=bdb3fb8ba9fd0687ce669ca019a278fc","This article describes a series of studies performed with the National Teacher Examinations which were designed to study the relationship between the cultural content of special sets of general culture test items and the performance of blacks and whites on these experimental items. Significant differences between the performance of blacks and whites were found in terms of black, modern, and traditional test items. A replication of the study with the same test items, and also with a different group of test items, is also described. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0040517889"
"KOEHLER R.A.","KOEHLER, ROGER A. (57029863300)","57029863300","OVERCONFIDENCE ON PROBABILISTIC TESTS","1974","Journal of Educational Measurement","11","2","","101","108","7","7","10.1111/j.1745-3984.1974.tb00978.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988137275&doi=10.1111%2fj.1745-3984.1974.tb00978.x&partnerID=40&md5=20ea679854f0d6857ed7822aab50174c","A potentially valuable measure of overconfidence on confidence response multiple‐choice tests was evaluated. The measure of overconfidence was based on probabilistic responses to seven nonsense items embedded in a 33 item vocabulary test. The test was administered under both confidence response and conventional choice response directions to 208 undergraduate educational psychology students. Measures of vocabulary knowledge based on confidence and choice responses, overconfidence, and risk‐taking propensity were obtained. The results indicated that overconfidence was significantly related in a negative direction to confidence response vocabulary scores and essentially unrelated to choice response vocabulary scores. A moderate correlation was found between overconfidence and risk‐taking propensity. However, the scatter plot for these measures showed that this relationship may have been spurious. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988137275"
"HUMPHREYS L.G.; TABER T.","HUMPHREYS, LLOYD G. (56238275200); TABER, THOMAS (24459500600)","56238275200; 24459500600","POSTDICTION STUDY OF THE GRADUATE RECORD EXAMINATION AND EIGHT SEMESTERS OF COLLEGE GRADES","1973","Journal of Educational Measurement","10","3","","179","184","5","24","10.1111/j.1745-3984.1973.tb00795.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973805508&doi=10.1111%2fj.1745-3984.1973.tb00795.x&partnerID=40&md5=45b0a02d76581364312e605dafa3ce62","Data from a postdictive study of the tests of the Graduate Record Examination and the eight semesters of undergraduate grade averages, each semester's average being computed independently of the rest, are presented. Postdictive validities of the aptitude portions of the GRE are essentially similar to predictive validities obtained earlier by the senior author. Both predictive and postdictive validity gradients over the eight semesters are relatively steep, with freshman grades having the highest correlations with the tests. The validity gradient for all advanced tests combined does not follow the pattern for the aptitude tests, but neither does it show the opposite gradient. Advanced test results are most highly correlated with sophomore grades, but the validity gradient over the eight semesters is relatively flat. A small scale extension of this research into post baccalaureate training indicated that senior grades were most predictive of graduate criteria, but a larger scale study is clearly called for. Possible implications for ability theory and for selection of graduate students are discussed. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973805508"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","FORMULA SCORING AND NUMBER‐RIGHT SCORING","1975","Journal of Educational Measurement","12","1","","7","11","4","85","10.1111/j.1745-3984.1975.tb01003.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939313613&doi=10.1111%2fj.1745-3984.1975.tb01003.x&partnerID=40&md5=97eccbd093ca092ab80ac1e8d6c6cc41","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84939313613"
"CALLENBACH C.","CALLENBACH, CARL (57195044436)","57195044436","THE EFFECTS OF INSTRUCTION AND PRACTICE IN CONTENT‐INDEPENDENT TEST‐TAKING TECHNIQUES UPON THE STANDARDIZED READING TEST SCORES OF SELECTED SECOND‐GRADE STUDENTS","1973","Journal of Educational Measurement","10","1","","25","29","4","19","10.1111/j.1745-3984.1973.tb00778.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976955382&doi=10.1111%2fj.1745-3984.1973.tb00778.x&partnerID=40&md5=45f0931a4365310029e165c36384efba","Twenty‐four relatively test‐naive second‐grade students received eight 30‐minute periods of deliberate instruction and practice in content‐independent standardized test‐taking techniques over a four‐week period. Immediate and delayed effects of treatment were assessed through an analysis of improvement in standardized reading test scores as measured by the difference between experimental and control groups in the Stanford Reading Test. The results showed that students who received instruction and practice in test‐taking techniques achieved significantly higher scores on both the immediate posttest administered the week following treatment and the delayed posttest administered four months after treatment. Mean differences were about a quarter of a standard deviation. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84976955382"
"THOMAS J.E.; ROSSON J.; SCHOEMER J.R.","THOMAS, JAMES E. (57046197700); ROSSON, JAY (57195043380); SCHOEMER, JAMES R. (57195044398)","57046197700; 57195043380; 57195044398","EFFECT OF NON‐TRADITIONAL GRADES ON HIRING PRACTICES OF PUBLIC SCHOOL SYSTEMS","1974","Journal of Educational Measurement","11","3","","213","217","4","0","10.1111/j.1745-3984.1974.tb00993.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024967242&doi=10.1111%2fj.1745-3984.1974.tb00993.x&partnerID=40&md5=6a70738c1477101cb29a74a1facf659d","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024967242"
"SOCKLOFF A.L.; PAPACOSTAS A.C.","SOCKLOFF, ALAN L. (7801335831); PAPACOSTAS, ARTHUR C. (57195043339)","7801335831; 57195043339","UNIFORMITY OF FACULTY ATTITUDE TOWARD EFFECTIVE TEACHING IN LECTURE/DISCUSSION COURSES","1975","Journal of Educational Measurement","12","4","","281","293","12","2","10.1111/j.1745-3984.1975.tb01029.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973731519&doi=10.1111%2fj.1745-3984.1975.tb01029.x&partnerID=40&md5=c8a9b0993af381a3e750a24a39c24e6c","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973731519"
"HUNTER J.E.","HUNTER, JOHN EDWARD (7403251927)","7403251927","METHODS OF REORDERING THE CORRELATION MATRIX TO FACILITATE VISUAL INSPECTION AND PRELIMINARY CLUSTER ANALYSIS","1973","Journal of Educational Measurement","10","1","","51","61","10","35","10.1111/j.1745-3984.1973.tb00782.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986816473&doi=10.1111%2fj.1745-3984.1973.tb00782.x&partnerID=40&md5=372e79cb675dc2d20e5021a167df6760","Using the notion of parallel items this paper presents a family of new criteria for cluster analysis. Instead of looking at the item correlation matrix one could look at a matrix of similarity coefficients. These coefficients are standardized raw dot products of columns in the correlation matrix or related numbers. After discussing the properties of this matrix the discussion will move to a classic example of a factor analytic problem in personality assessment, an item pool concerned with Fromm's marketing orientation, and a brief discussion of problems outside of cluster analysis will conclude the paper. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84986816473"
"BASKIN D.","BASKIN, DAVID (57195041171)","57195041171","A CONFIGURATION‐SCORING PARADIGM FOR IDENTICAL RAW SCORES","1975","Journal of Educational Measurement","12","1","","3","5","2","0","10.1111/j.1745-3984.1975.tb01002.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024983275&doi=10.1111%2fj.1745-3984.1975.tb01002.x&partnerID=40&md5=89daf100ca10d78776ef98bcd2ece097","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024983275"
"FELDT L.S.; FORSYTH R.A.","FELDT, LEONARD S. (7003911114); FORSYTH, ROBERT A. (57029929200)","7003911114; 57029929200","AN EXAMINATION OF THE CONTEXT EFFECT IN ITEM SAMPLING","1974","Journal of Educational Measurement","11","2","","73","82","9","5","10.1111/j.1745-3984.1974.tb00975.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915136958&doi=10.1111%2fj.1745-3984.1974.tb00975.x&partnerID=40&md5=555c4976684e68a9414da9ed2281eed8","Item sampling and/or multiple matrix sampling techniques have been recommended for a variety of purposes. For some of these purposes, it must be assumed that examinee performance on a set of items is unaffected by the conditions under which the items are taken (i.e., no context effect exists). In this paper factors that may lead to a context effect among high school students are discussed. The net effect of such factors on examinee scores for an English test and a mathematics test is investigated empirically. For the English test there was little support for the existence of a context effect, However, a definite context effect was found for the mathematics test. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84915136958"
"PYRCZAK F.","PYRCZAK, FRED (24760979900)","24760979900","VALIDITY OF THE DISCRIMINATION INDEX AS A MEASURE OF ITEM QUALITY","1973","Journal of Educational Measurement","10","3","","227","231","4","18","10.1111/j.1745-3984.1973.tb00801.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990378831&doi=10.1111%2fj.1745-3984.1973.tb00801.x&partnerID=40&md5=55425b63145741aa4dc1c2ac4e1729da","Numerous writers have suggested that the discrimination index may be helpful in identifying faulty test items. The purpose of this study was to investigate systematically the validity of the index for this purpose. To attain this objective, two forms of an arithmetic‐reasoning test were written. In each form, the items were designed to vary in quality with respect to nine item‐writing principles, and on the basis of the responses of 364 examinees, a discrimination index was computed for each item. Next, the items were rated independently for quality by three judges who used a check list of the nine item‐writing principles. The average of their ratings for each item was used as the criterion for determining the validity of the indices. The results indicate that the discrimination index is a moderately valid measure of item quality. The implications of this finding are discussed. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84990378831"
"EVANS F.R.; PIKE L.W.","EVANS, FRANKLIN R. (7103220085); PIKE, LEWIS W. (57189655647)","7103220085; 57189655647","THE EFFECTS OF INSTRUCTION FOR THREE MATHEMATICS ITEM FORMATS","1973","Journal of Educational Measurement","10","4","","257","271","14","19","10.1111/j.1745-3984.1973.tb00803.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988098355&doi=10.1111%2fj.1745-3984.1973.tb00803.x&partnerID=40&md5=cda8a27c5b21fdf04435881ab917f29c","Different instructional programs were developed for three mathematics aptitude item formats to determine the relative susceptibility of each to special instruction. Subjects were male and female high school junior volunteers in 12 schools. In the seven weeks between a pre‐ and posttest, experimental Ss received 21 hours of instruction for one of the three formats; control Ss received no special instrucion. Each of the three formats was found susceptible to instruction directed toward it. The complex formats were most susceptible. Female Ss were slightly less able mathematically at the outset and benefited less from instruction than males. Mean gains of nearly a full standard deviation for groups instructed for the complex formats were considered to be of practical consequence. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988098355"
"LINN R.L.","LINN, ROBERT L. (56126633100)","56126633100","IN SEARCH OF FAIR SELECTION PROCEDURES","1976","Journal of Educational Measurement","13","1","","53","58","5","22","10.1111/j.1745-3984.1976.tb00181.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951409730&doi=10.1111%2fj.1745-3984.1976.tb00181.x&partnerID=40&md5=72faacd8e0695519aa670693436671b5","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84951409730"
"FAGGEN‐STECKLER J.; McCARTHY K.A.; TITTLE C.K.","FAGGEN‐STECKLER, JANE (25954157800); McCARTHY, KAREN A. (55423540000); TITTLE, CAROL K. (16489527900)","25954157800; 55423540000; 16489527900","A QUANTITATIVE METHOD FOR MEASURING SEX “BIAS” IN STANDARDIZED TESTS","1974","Journal of Educational Measurement","11","3","","151","161","10","10","10.1111/j.1745-3984.1974.tb00987.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911548700&doi=10.1111%2fj.1745-3984.1974.tb00987.x&partnerID=40&md5=eac2101c7d73d1eef43e08b3cc2746b5","The item content of eight standardized tests was examined for sex imbalance as well as for stereotyped representations of women. A quantitative method for classifying tests with respect to sex imbalance was devised which depended upon the frequency counts of male and female nouns and pronouns. Applications of this method revealed that all eight of the standardized tests exhibited considerable sex imbalance and, further, that this sex imbalance was not due to the language restrictions of English. For 19 of the 27 batteries analyzed, males are referred to more than twice as often as females. For only one battery, females were referred to more often than males. Test constructors, editors, and publishers are invited to make use of the index to measure sex imbalance in new, as well as already published testing materials. In this way, the undesirable reinforcement of discriminating sex‐role stereotyping can be curtailed, and the preponderance of male noun and pronoun references can be eliminated. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84911548700"
"SHAVELSON R.J.; STANTON G.C.","SHAVELSON, RICHARD J. (35613093400); STANTON, GEORGE C. (57189177569)","35613093400; 57189177569","CONSTRUCT VALIDATION: METHODOLOGY AND APPLICATION TO THREE MEASURES OF COGNITIVE STRUCTURE","1975","Journal of Educational Measurement","12","2","","67","85","18","63","10.1111/j.1745-3984.1975.tb01010.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84925894227&doi=10.1111%2fj.1745-3984.1975.tb01010.x&partnerID=40&md5=af34145fa34aa4d894f124936071d6f1","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84925894227"
"CREHAN K.D.","CREHAN, KEVIN D. (6603214066)","6603214066","ITEM ANALYSIS FOR TEACHER‐MADE MASTERY TESTS","1974","Journal of Educational Measurement","11","4","","255","261","6","9","10.1111/j.1745-3984.1974.tb00997.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970681085&doi=10.1111%2fj.1745-3984.1974.tb00997.x&partnerID=40&md5=4bc21cbc47a31439e0d412c5b5f11b03","Various item selection techniques are compared on resultant criterionreferenced reliability and validity. Techniques compared include three nominal criterion‐referenced methods, a traditional point biserial selection, teacher selection, and random selection. Eighteen volunteer junior and senior high school teachers supplied behavioral objectives and item pools ranging from 26 to 40 items. Each teacher obtained reponses from four classes. Pairs of tests of various length were developed by each item selection method. Estimates of test reliability and validity were obtained using responses independent of the test construction sample. Resultant reliability and validity estimates were compared across item selection techniques. Two of the criterion‐referenced item selection methods resulted in consistently higher observed validity. However, the small magnitude of improvement over teacher or random selection raises a question as to whether the benefit warrants the necessary extra effort on the part of the classroom teacher. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970681085"
"RAFFELD P.","RAFFELD, PAUL (57204226538)","57204226538","THE EFFECTS OF GUTTMAN WEIGHTS ON THE RELIABILITY AND PREDICTIVE VALIDITY OF OBJECTIVE TESTS WHEN OMISSIONS ARE NOT DIFFERENTIALLY WEIGHTED","1975","Journal of Educational Measurement","12","3","","179","185","6","8","10.1111/j.1745-3984.1975.tb01020.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85011817685&doi=10.1111%2fj.1745-3984.1975.tb01020.x&partnerID=40&md5=84c4b59bee92ada50718acbebfbf0e07","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85011817685"
"SHOEMAKER D.M.; KNAPP T.R.","SHOEMAKER, DAVID M. (57029927000); KNAPP, THOMAS R. (24366321400)","57029927000; 24366321400","A NOTE ON TERMINOLOGY AND NOTATION IN MATRIX SAMPLING","1974","Journal of Educational Measurement","11","1","","59","61","2","3","10.1111/j.1745-3984.1974.tb00972.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965884660&doi=10.1111%2fj.1745-3984.1974.tb00972.x&partnerID=40&md5=e092c38589ee85a2f5159b192b37a787","The proliferation of terminology in matrix sampling is beginning to cause some minor problems. Presented herein is one set of terms and notation which hopefully will facilitate communication among individuals engaged in all aspects of matrix sampling. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965884660"
"FELDT L.S.","FELDT, LEONARD S. (7003911114)","7003911114","WHAT SIZE SAMPLES FOR METHODS/MATERIALS EXPERIMENTS?","1973","Journal of Educational Measurement","10","3","","221","226","5","9","10.1111/j.1745-3984.1973.tb00800.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007645803&doi=10.1111%2fj.1745-3984.1973.tb00800.x&partnerID=40&md5=d9af113c2b2fbbc5bc31f54411f2d8f5","Careful planning of educational experiments includes decisions about the sample size to be used. This paper provides a guide to the minimum size of treatment groups, inferred from the relationships between pupil norms and norms for class averages of standardized achievement tests. With “highly effective” treatments and simple random assignment of subjects to conditions, 60 to 85 subjects is derived as the minimum number per group. With “moderately effective” treatments, the minimum number is 235 or more. Use of stratified samples reduces the minimum by fifteen to forty percent. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85007645803"
"ABELES H.F.","ABELES, HAROLD F. (26121056600)","26121056600","A FACET‐FACTORIAL APPROACH TO THE CONSTRUCTION OF RATING SCALES TO MEASURE COMPLEX BEHAVIORS","1973","Journal of Educational Measurement","10","2","","145","151","6","2","10.1111/j.1745-3984.1973.tb00792.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976972669&doi=10.1111%2fj.1745-3984.1973.tb00792.x&partnerID=40&md5=8fb081232364d1db12dd737b5ec79672","The purpose of this study was to examine a technique for the development of performance rating scales to measure achievement in courses whose objectives require complex behaviors not easily measurable with paper and pencil achievement tests. A facet‐factorial approach to rating scale construction was employed (i.e. the behavior was conceptualized as multidimensional and items for the scales were selected by employing factor analytical techniques) to construct scales to measure clarinet music performance. The three major results of the study were: 1) a thirty‐item rating scale based on a six factor structure of clarinet music performance; 2) high inter‐judge reliability estimates for both the total score (above .90) and the scale scores (above .60); and, 3) criterion‐related validity coefficients greater than .80. Results of the investigation suggest that the facet‐factorial approach can be an effective technique for the construction of rating scales to measure complex behavior such as music performance. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84976972669"
"MASTERS E.R.","MASTERS, ES R. (57195042691)","57195042691","THE RELATIONSHIP BETWEEN NUMBER OF RESPONSE CATEGORIES AND RELIABILITY OF LIKERT‐TYPE QUESTIONNAIRES","1974","Journal of Educational Measurement","11","1","","49","53","4","71","10.1111/j.1745-3984.1974.tb00970.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986566517&doi=10.1111%2fj.1745-3984.1974.tb00970.x&partnerID=40&md5=b79e37e35dd8e6ceb973bf4093426cf9","The purpose of the study was to investigate the relationship between number of response categories employed and internal‐consistency reliability of Likert‐type questionnaires. Two questionnaires, each composed of items with high loadings on one factor, were scaled with 2, 3, 4, 5, 6, and 7 categories. The questionnaires were administered to graduate students in education and coefficient alpha reliabilities were computed both for random samples of items and for each total questionnaire. The results indicated that in situations where low total score variability is achieved with a small number of categories, reliability can be increased through increasing the number of categories employed, in situations where pinion is widely divided toward the content being measured, reliability appeared to be independent of the number of response categories. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84986566517"
"BRIDGEMAN B.; STRANG H.R.; BUTTRAM J.","BRIDGEMAN, BRENT (7005526936); STRANG, HAROLD R. (6603236345); BUTTRAM, JOAN (55287202700)","7005526936; 6603236345; 55287202700","“GAME” VERSUS “TEST” INSTRUCTIONS FOR THE WISC","1974","Journal of Educational Measurement","11","4","","285","288","3","3","10.1111/j.1745-3984.1974.tb01001.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052404703&doi=10.1111%2fj.1745-3984.1974.tb01001.x&partnerID=40&md5=57626a72f6bcec6f00e486319ab070ef","“Game” or “test” instructions on either verbal or nonverbal WISC scales were given to 160 third‐ and sixth‐grade children. Ss in one condition were told they were going to take several tests, while Ss in the other condition were told they were going to play several games. Significant differences in performance due to task definition were found only on verbal tasks at the sixth‐grade level with test instructions yielding superior performance. Results at the third‐grade level failed to replicate previous results which suggested game instructions produce superior performance on nonverbal tasks. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-80052404703"
"WOODSON M.I.CHAS.E.","WOODSON, M.I.CHAS.E. (6602718801)","6602718801","THE ISSUE OF ITEM AND TEST VARIANCE FOR CRITERION‐REFERENCED TESTS: A REPLY","1974","Journal of Educational Measurement","11","2","","139","140","1","22","10.1111/j.1745-3984.1974.tb00985.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970261040&doi=10.1111%2fj.1745-3984.1974.tb00985.x&partnerID=40&md5=6602c27b39c7e09cc254cc2981c66bed","It is a necessary condition that items and tests have variance and discrimination in the range of interest (population of observations) for which they are calibrated and selected. The basis for selection of the calibration sample determines the kind of scale which will be developed, A random sample from a population of individuals leads to a norm‐referenced scale, and a sample representative of abilities of a range of a characteristic leads to a criterion‐referenced scale. Copyright © 1974, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970261040"
"KOEHLER R.A.","KOEHLER, ROGER A. (57029863300)","57029863300","A COMPARISON OF THE VALIDITIES OF CONVENTIONAL CHOICE TESTING AND VARIOUS CONFIDENCE MARKING PROCEDURES","1971","Journal of Educational Measurement","8","4","","297","303","6","13","10.1111/j.1745-3984.1971.tb00942.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965875421&doi=10.1111%2fj.1745-3984.1971.tb00942.x&partnerID=40&md5=6945b9ba20c0feb9bcbf845e540538b6","This study compared the convergent and discriminant validity of two confidence marking techniques with that of conventional choice testing. Achievement in vocabulary, social studies, and science (traits) was measured by a 60‐item test containing true‐false and 5‐alternative items (methods). The test was administered to three randomly assigned groups (one for each response system), totaling 535 Ss. The results indicated very slight differences in convergent and discriminant validity that favored conventional choice testing over confidence marking techniques. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965875421"
"WOOD D.A.; LANGEVIN M.J.","WOOD, DONALD A. (55468922700); LANGEVIN, MICHAEL J. (57195040800)","55468922700; 57195040800","MODERATING THE PREDICTION OF GRADES IN FRESHMAN ENGINEERING","1972","Journal of Educational Measurement","9","4","","311","320","9","1","10.1111/j.1745-3984.1972.tb00963.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970274877&doi=10.1111%2fj.1745-3984.1972.tb00963.x&partnerID=40&md5=0fd1d980e6cbb3ee57273779aa1e27f8","This study concerned the identification of an optimal moderator within a test battery for enhancing prediction of first semester engineering grades for 522 college freshmen. Moderated multiple regression disclosed high school rank (HSR) as the best moderator of SAT‐M, the best predictor, in both a validation and hold‐out group. SAT‐M overall validity of .39 was increased to .53 and an overall R of .47 was raised to .61 when only those highest in HSR were considered. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970274877"
"WORTHEN B.R.; CLARK P.M.","WORTHEN, BLAINE R. (6603235314); CLARK, PHILIP M. (57010670000)","6603235314; 57010670000","TOWARD AN IMPROVED MEASURE OF REMOTE ASSOCIATIONAL ABILITY","1971","Journal of Educational Measurement","8","2","","113","123","10","44","10.1111/j.1745-3984.1971.tb00914.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900537585&doi=10.1111%2fj.1745-3984.1971.tb00914.x&partnerID=40&md5=65a64581b48d3093c831b9b4a6b098a9","A lack of satisfaction with existing measures of creativity and the need for a more theoretically sophisticated approach to measurement in this area were identified Mednick's remote association theory of creative behavior was reviewed, and Mednick and Mednick's operationalization of that position, the Remote Associates Test (RAT), was analyzed both logically and empirically. An alternative measure of remote associational ability, the Functionally Remote Associates Test (FRAT), was offered as a more logical extension of Mednick's theory. Empirical data were presented which suggest the superiority of FRAT to RAT as a measure of creativity. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84900537585"
"REARDON F.; SENIER J.; LEWIS J.","REARDON, FRANCIS (7004365711); SENIER, JOHN (57195040434); LEWIS, JAMES (57195040774)","7004365711; 57195040434; 57195040774","THE DEVELOPMENT AND EVALUATION OF AN OCCUPATIONAL INVENTORY","1972","Journal of Educational Measurement","9","2","","151","153","2","0","10.1111/j.1745-3984.1972.tb00772.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024972047&doi=10.1111%2fj.1745-3984.1972.tb00772.x&partnerID=40&md5=0e6ada763da3a7cb8e19272468c29fe1","An occupational inventory was developed by the Pennsylvania Department of Education for consideration as part of the state assessment project. This instrument measures 7tb grade student knowledge of the world of work. The summary phase of field testing involving 255 students revealed a reliability of .828 and a standard error of measurement of 2.60. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024972047"
"JENKINS J.R.; DENO S.L.","JENKINS, JOSEPH R. (7402867621); DENO, STANLEY L. (7003486142)","7402867621; 7003486142","ASSESSING KNOWLEDGE OF CONCEPTS AND PRINCIPLES","1971","Journal of Educational Measurement","8","2","","95","101","6","4","10.1111/j.1745-3984.1971.tb00911.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970372901&doi=10.1111%2fj.1745-3984.1971.tb00911.x&partnerID=40&md5=87737295c846653fb0ea467bd23b2a8a","Several item‐types which may be used to test for the acquisition of subject‐matter concepts and principles are described. Each item‐type is discussed in terms of its ability to tap more than reproductive capabilities. Research hypotheses deducible from the item‐types are presented and discussed. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970372901"
"STUFFLEBEAM D.L.","STUFFLEBEAM, DANIEL L. (56631885700)","56631885700","THE USE OF EXPERIMENTAL DESIGN IN EDUCATIONAL EVALUATION","1971","Journal of Educational Measurement","8","4","","267","274","7","27","10.1111/j.1745-3984.1971.tb00936.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041387282&doi=10.1111%2fj.1745-3984.1971.tb00936.x&partnerID=40&md5=f44d3be3f97b5e9499fda1d20490c113","Considerable controversy has existed concerning the utility of experimental design in educational evaluation. The polar positions are that experimental design has no utility in educational evaluation and that experimental design is the only valid evaluation strategy. This article examines these positions in terms of conceptualizations of evaluation according to the‘LCIPP Evaluation Model “and of experimental design according to the “true comparative experiment.” An alternative position including three main points is developed: (a) The methodology of educational evaluation includes much more than the methodology of experimental design; (b) Experimental design does have potential utility in the areas of input and product evaluation, but not within the areas of context and process evaluation; (c) The utility of experimental design can be increased by following a set of procedures that do not require the use of common criterion instruments and uniform decision rules for all students in an experiment; this allows judgment of a program in terms of the number of students for whom it was successful. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0041387282"
"HUMPHREYS L.G.; TABER T.","HUMPHREYS, LLOYD G. (56238275200); TABER, THOMAS (24459500600)","56238275200; 24459500600","ABILITY FACTORS AS A FUNCTION OF ADVANTAGED AND DISADVANTAGED GROUPS","1973","Journal of Educational Measurement","10","2","","107","114","7","14","10.1111/j.1745-3984.1973.tb00788.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965804470&doi=10.1111%2fj.1745-3984.1973.tb00788.x&partnerID=40&md5=b8b7af22488d6f47767327b2077f68e3","Preliminary factor analyses of predictor tests in advantaged and disadvantaged groups is recommended as a way of forming a priori expectations concerning validities of the predictors to guide both use and research. Factor analyses of Project Talent ability measures are reported for groups defined by top and bottom quartile placement in intelligence and socio‐economic status. There are no important differences in results associated with differences in socio‐economic status, but there are fairly numerous differences in loadings for individual measures in groups defined by level of intelligence. Most of these differences can be explained by the characteristics of the scales of measurement. For a small number of measures, however, there is evidence for differences in loadings as a function of the intellectual level of the subjects per se. These latter measures would be expected to have differential validities for similarly selected intelligence groups, but not for socio‐economic groups. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965804470"
"GAFFNEY R.F.; MAGUIRE T.O.","GAFFNEY, RICHARD F. (57195040995); MAGUIRE, THOMAS O. (7005604484)","57195040995; 7005604484","USE OF OPTICALLY SCORED TEST ANSWER SHEETS WITH YOUNG CHILDREN","1971","Journal of Educational Measurement","8","2","","103","106","3","4","10.1111/j.1745-3984.1971.tb00912.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965950240&doi=10.1111%2fj.1745-3984.1971.tb00912.x&partnerID=40&md5=85d895721d8446d667698bca7cbce4ab","By testing a sample of 840 school children from an urban school district, the authors examined the practical limitations of the use of an optically scored answer sheet. The independent variables were grade (two through nine) and degree of instruction and practice (three levels). The dependent variable was the number of easy items (embedded within a set of ordinary test items) that were correctly answered. The easy items, which were different for the various grades, were selected because other children, comparable to those used in the experiment, were able to answer them virtually without error when answering on a test booklet rather than on the answer sheet. The findings indicated that students in grades two and three, in the fall of the year, were unable to make valid responses. Students in grades four and five seemed able to make valid responses only after receiving specific instructions and a practice session. Above grade five, students made valid responses regardless of the types of instructions they received. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965950240"
"VEAL L.R.; BIESBROCK E.F.","VEAL, L. RAMON (57188899265); BIESBROCK, EDIEANN F. (57011353500)","57188899265; 57011353500","PRIMARY ESSAY TESTS","1971","Journal of Educational Measurement","8","1","","45","46","1","0","10.1111/j.1745-3984.1971.tb00905.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024951507&doi=10.1111%2fj.1745-3984.1971.tb00905.x&partnerID=40&md5=80a16535e4b3a6b6f9abe4c654d1b1bf","A summary of the development of an experimental test to measure composition ability in young children. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024951507"
"GLUSKINOS U.M.","GLUSKINOS, URY M. (6506002216)","6506002216","CRITERIA FOR STUDENT ENGINEERING CREATIVITY AND THEIR RELATIONSHIP TO COLLEGE GRADES","1971","Journal of Educational Measurement","8","3","","189","195","6","8","10.1111/j.1745-3984.1971.tb00924.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85015973501&doi=10.1111%2fj.1745-3984.1971.tb00924.x&partnerID=40&md5=5e7e3510857c2ef25100f663231ecab8","The creativity of engineering students was assessed through divergent problems relevant to engineering content. These problems were constructed, administered and scored by faculty members from the mechanical (ME), civil (CE), and electrical (EE) engineering departments at a large university. The problems, administered to 60 MEs, 81 CEs, and 173 EEs, were scored on the basis of the number of solutions (fluency), the number of categories of solutions (flexibility), the originality of the solutions (novelty), and the appropriateness of the solutions (appropriateness). Interrater reliabilities indicated that the fluency and flexibility scores were sufficiently reliable; the novelty and appropriateness scores were less so. The adequacy of substituting the fluency score in lieu of the novelty score was discussed. No significant relationships were found between creativity and grade point average (GPA). Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85015973501"
"JACOBS S.S.","JACOBS, STANLEY S. (7402313169)","7402313169","CORRELATES OF UNWARRANTED CONFIDENCE IN RESPONSES TO OBJECTIVE TEST ITEMS","1971","Journal of Educational Measurement","8","1","","15","20","5","12","10.1111/j.1745-3984.1971.tb00901.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977007309&doi=10.1111%2fj.1745-3984.1971.tb00901.x&partnerID=40&md5=aedb30a2d414cac52aed621cc71e4e71","Investigated were the effects of several variables on the expression of unwarranted confidence in the accuracy of responses to objective test items. A final examination was administered to 72 subjects under confidence‐weighting instructions with two levels of penalty for incorrect responses. A 2‐way ANOVA revealed no significant main effects or interaction attributable to level of penalty or sex. Although increased penalty level had no effect on confidence‐expression, the test's reliability decreased from .85 to .39, and the correlation between conventional and weighted scores dropped from .88 to .095. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84977007309"
"FARR R.; ROELKE P.","FARR, ROGER (24786322400); ROELKE, PATRICIA (57195042877)","24786322400; 57195042877","MEASURING SUBSKILLS OF READING: INTERCORRELATIONS BETWEEN STANDARDIZED READING TESTS, TEACHERS’ RATINGS, AND READING SPECIALISTS’ RATINGS","1971","Journal of Educational Measurement","8","1","","27","32","5","12","10.1111/j.1745-3984.1971.tb00903.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973195398&doi=10.1111%2fj.1745-3984.1971.tb00903.x&partnerID=40&md5=d9c827c2526daf62a8db022f157d1821","The study examined the convergent and discriminant validity of three methods for assessing three subskills of reading: word analysis, vocabulary, and comprehension. These three subskills were measured by teachers’ ratings, specialists’ ratings, and standardized tests. Correlations of all three skills, each measured by the three different methods, were studied by the multi‐trait‐multimethod procedure. Although there was some support for convergent validity, the study revealed a total lack of discriminant validity for any of the three subskills of reading. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973195398"
"LOEB J.; FERBER M.","LOEB, JANE (55186213500); FERBER, MARIANNE (7006536542)","55186213500; 7006536542","SEX AS PREDICTIVE OF SALARY AND STATUS ON A UNIVERSITY FACULTY","1971","Journal of Educational Measurement","8","4","","235","244","9","23","10.1111/j.1745-3984.1971.tb00932.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986993226&doi=10.1111%2fj.1745-3984.1971.tb00932.x&partnerID=40&md5=485e5ba75749135174647c72b9c895df","An investigation of the existence and extent of sex‐based inequities in rank and pay on a University faculty yielded several suggestions of discrimination against women. Data on professional experience, publications, honors, rank and pay were collected by means of a questionnaire distributed to 372 faculty members. Within a sample of 128 who answered all requisite items, sex added significantly to the predictability of salary beyond that achieved by multiple measures of merit and experience, including mean salary for rank and department. Sex itself did not predict rank or a measure designed to reflect speed of advancement through the ranks. Terms reflecting interactions of sex and merit were capable of improving prediction of all three status measures, however, suggesting differences in the reward structure for the sexes. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84986993226"
"MARKS E.; LINDSAY C.A.","MARKS, EDMOND (25954348600); LINDSAY, CARL A. (16463709700)","25954348600; 16463709700","SOME RESULTS RELATING TO TEST EQUATING UNDER RELAXED TEST FORM EQUIVALENCE","1972","Journal of Educational Measurement","9","1","","45","56","11","1","10.1111/j.1745-3984.1972.tb00760.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954831740&doi=10.1111%2fj.1745-3984.1972.tb00760.x&partnerID=40&md5=8b7645ff8c997e25a68bc4878c0bf6fe","Educational measurement specialists in undertaking test equating in applied settings have been plagued by the absence of a logically or mathematically compelling rationale for their test equating efforts. Classical test theory and other test theories based on the assumption of identically distributed true scores are tautological in terms of test equating. The present study examined (by means of a Monte Carlo procedure) the effects of four parameters on the accuracy of test equating under a relaxed definition of test form equivalence. The four parameters studied were sample size, test form length, test form reliability, and the correlation between the true scores of the test forms to be equated. Significant interactions involving sample size and the other parameters indicated that smaller samples of observations yielded disproportionately larger errors in test equating for fixed values of the test form parameters. In terms of main effects, sample size emerged as most important in controlling equating error. Taken together, the results suggest that when test equating is carried out on larger samples of observations, errors of equating will tend to be relatively small even though the test forms are not strictly parallel. For arbitrarily small samples, however, errors of equating will tend to be larger regardless of how equivalent the test forms are. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84954831740"
"HANSEN R.","HANSEN, RICHARD (57010721700)","57010721700","THE INFLUENCE OF VARIABLES OTHER THAN KNOWLEDGE ON PROBABILISTIC TESTS","1971","Journal of Educational Measurement","8","1","","9","14","5","9","10.1111/j.1745-3984.1971.tb00900.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84976991310&doi=10.1111%2fj.1745-3984.1971.tb00900.x&partnerID=40&md5=6dc8dfa2e43f7eaf536e5c93c3e7fb79","In probabilistic test and scoring systems the examinee is required to respond to each of the options of a multiple‐choice test with a probability which represents the confidence he has in that option. It seems reasonable to assume that for such tests to yield valid information about the examinees, the knowledge they have should be the primary influence on the probabilities they assign. The purpose of this study was to seek the relationship between the degree to which examinees display certainty in their responses and certain personality variables. Proponents of probabilistic testing would expect such correlations to be low. In this stud), it was found that individuals do respond to multiple‐choice questions with a characteristic certainty that cannot be accounted for on the basis of their knowledge. This certainty was related to scores of both the F Scale and the Kogan and Wallach risk taking measure. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84976991310"
"COLLET L.S.","COLLET, LEVERNE S. (56890747100)","56890747100","ELIMINATION SCORING: AN EMPIRICAL EVALUATION","1971","Journal of Educational Measurement","8","3","","209","214","5","18","10.1111/j.1745-3984.1971.tb00927.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973811808&doi=10.1111%2fj.1745-3984.1971.tb00927.x&partnerID=40&md5=5fbf0b317f3a1de5e0fc6077413353f3","The purpose of this paper was to provide an empirical test of the hypothesis that elimination scores are more reliable and valid than classical corrected for‐guessing scores or weighted‐choice scores. The evidence presented supports the hypothesized superiority of elimination scoring. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973811808"
"SHOEMAKER D.M.","SHOEMAKER, DAVID M. (57029927000)","57029927000","AN APPLICATION OF ITEM‐EXAMINEE SAMPLING TO SCALING ATTITUDES","1971","Journal of Educational Measurement","8","4","","279","282","3","16","10.1111/j.1745-3984.1971.tb00938.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973751936&doi=10.1111%2fj.1745-3984.1971.tb00938.x&partnerID=40&md5=bea7c028849f1a8bfb0c6413ee0e7955","The post mortem item‐examinee sampling investigation described herein explored the feasibility of using item‐examinee sampling to estimate scale values denoting degree of affect toward stimuli when measured by the method of paired‐comparisons. Results indicate that such scale values can be approximated satisfactorily through item‐examinee sampling. Defining one observation as the response made by one examinee to one item, the similarity between the estimated scale values and normative scale values increased generally with increases in the number of observations acquired by the sampling plan. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973751936"
"BRANDENBURG D.C.; WHITNEY D.R.","BRANDENBURG, DALE C. (16462293700); WHITNEY, DOUGLAS R. (7102971846)","16462293700; 7102971846","MATCHED PAIR TRUE‐FALSE SCORING: EFFECT ON RELIABILITY AND VALIDITY","1972","Journal of Educational Measurement","9","4","","297","302","5","2","10.1111/j.1745-3984.1972.tb00961.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988099382&doi=10.1111%2fj.1745-3984.1972.tb00961.x&partnerID=40&md5=d7a6cc2396360f66dcd72acdd9f0b57f","The matched pair technique for writing and scoring true‐false items was designed to compensate for the acquiescence response set of primary grade children. The claim that this technique increases reliability to an appreciable extent over traditional true‐false scoring was investigated by comparing alpha internal consistency coefficients computed for the matched pair true‐false, traditional true‐false, and three other scoring schemes. Both the total sample coefficients and individual classroom coefficients were computed from the standardization sample of a primary grade economics achievement test (Primary Test of Economic Understanding). Classroom reliability coefficients computed from the matched pair scores were found to be higher than those from scores computed by the other methods. Total sample coefficients obtained from four of the five methods were nearly equal. Evidence of the effects of each scoring technique on concurrent validity is also presented. Contrary to expectations, the correlations of traditional and matched pair scores with Iowa Test of Basic Skills (ITBS) subtests (when adjusted for differing reliabilities) were approximately equal. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988099382"
"D'AGOSTINO R.B.","D'AGOSTINO, RALPH B. (36065675100)","36065675100","A SECOND LOOK AT ANALYSIS OF VARIANCE ON DICHOTOMOUS DATA","1971","Journal of Educational Measurement","8","4","","327","333","6","57","10.1111/j.1745-3984.1971.tb00947.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970738612&doi=10.1111%2fj.1745-3984.1971.tb00947.x&partnerID=40&md5=67d7b18b668f72c57c4941a09b27f418","The work of Lunney (1970) concerning the appropriateness of analysis of variance (ANOVA) techniques on dichotomous data is discussed and extended. Relations between standard statistical techniques for analyzing dichotomous data and ANOVA procedures are indicated. The need for usefulness of analyzing transformed data as opposed to direct analysis of dichotomous data are discussed. Required statistical procedures employing transformed data are outlined. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970738612"
"REED C.L.; FELDHUSEN J.F.; VAN MONDFRANS A.P.","REED, CHERYL L. (7402210437); FELDHUSEN, JOHN F. (6701343149); VAN MONDFRANS, ADRIAN P. (24785471800)","7402210437; 6701343149; 24785471800","PREDICTION OF GRADE POINT AVERAGES IN NURSING SCHOOLS USING SECOND‐ORDER MULTIPLE REGRESSION MODELS","1972","Journal of Educational Measurement","9","3","","181","187","6","1","10.1111/j.1745-3984.1972.tb00950.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965613225&doi=10.1111%2fj.1745-3984.1972.tb00950.x&partnerID=40&md5=73ce157ecc1f129289f1cf9851f3b5f0","The present study was concerned with the prediction of first year grade point averages of associate degree nursing students. The primary objective of this investigation was to determine whether the inclusion of quadratic and/or interaction terms in a regression model would improve the prediction of student nurses’ grade averages. The predictor battery included cognitive, biographical, and personality variables. Results indicated that interaction and quadratic terms improve both the predictability of grade point averages and the replicability of these predictions. The inclusion of higher order terms in prediction research is suggested as a means of improving predictive efficiency. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965613225"
"LINN R.L.; WERTS C.E.","LINN, ROBERT L. (56126633100); WERTS, CHARLES E. (24751673300)","56126633100; 24751673300","CONSIDERATIONS FOR STUDIES OF TEST BIAS","1971","Journal of Educational Measurement","8","1","","1","4","3","76","10.1111/j.1745-3984.1971.tb00898.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973705349&doi=10.1111%2fj.1745-3984.1971.tb00898.x&partnerID=40&md5=a16cf629f5bc1ab841b238691a46d327","Discussed are two problems in the investigation of predictive bias in tests: (a) the effect of unreliability of the predictors, and (b) the effect of excluding a predictor from the regression equation on which there are preexisting group differences. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973705349"
"BERDIE F.S.","BERDIE, FRANCES S. (57195045350)","57195045350","WHAT TEST QUESTIONS ARE LIKELY TO OFFEND THE GENERAL PUBLIC","1971","Journal of Educational Measurement","8","2","","87","93","6","1","10.1111/j.1745-3984.1971.tb00910.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84869093088&doi=10.1111%2fj.1745-3984.1971.tb00910.x&partnerID=40&md5=79f572f8e89e8f94a6e32a41ad0ed136","The purpose of the research reported here was to assure that materials used in the National Assessment of Education would not be offensive to any large group of people. The method used of asking the opinions of lay people actively interested in education about the possible offensiveness of assessment exercises is discussed and types of potentially offensive materials are described. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84869093088"
"STALLINGS W.M.; SMOCK H.R.","STALLINGS, WILLIAM M. (16437347300); SMOCK, H. RICHARD (16488824900)","16437347300; 16488824900","THE PASS‐FAIL GRADING OPTION AT A STATE UNIVERSITY: A FIVE SEMESTER EVALUATION","1971","Journal of Educational Measurement","8","3","","153","160","7","5","10.1111/j.1745-3984.1971.tb00919.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005519264&doi=10.1111%2fj.1745-3984.1971.tb00919.x&partnerID=40&md5=e22ec80d8b8d72333ebf1d13e4364f32","To evaluate the pass‐fail grading option, course and grade data were generated each semester. Faculty and student attitudinal data were obtained once. Because pass‐fail students were not identified to instructors, all students were given traditional A‐E grades. During administrative data processing, the A‐E grades of pass‐fail students were converted to pass or fail. In comparison with traditionally graded students in the same classes, pass‐fail students received lower grades on the average. The pass‐fail option proved to be popular. Students favored the pass‐fail option, although their reasons for electing the option were not necessarily in accord with the official rationale, to foster exploration. Perhaps because they perceived students as abusing the option, the small faculty sample had somewhat negative attitudes toward the pass‐fail system. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85005519264"
"McMORRIS R.F.; AMBROSINO R.J.","McMORRIS, ROBERT F. (6603270899); AMBROSINO, ROBERT J. (6602932389)","6603270899; 6602932389","SELF‐REPORT PREDICTORS: A REMINDER","1973","Journal of Educational Measurement","10","1","","13","17","4","12","10.1111/j.1745-3984.1973.tb00776.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039581676&doi=10.1111%2fj.1745-3984.1973.tb00776.x&partnerID=40&md5=2122cd2af492f5d76aa94c04004b2258","How do tests and self‐reports compare as predictors of academic performance? Do tests add to the predictability from self‐reports? College seniors in eight sections of an evaluation course were administered the Quantitative Evaluative Device, the Cooperative English Test: Reading Comprehension, the Concept Mastery Test, and two questionnaires concerning past academic performance, student‐estimated abilities, and reading habits. The criteria were composite test scores and letter grades. The best predictors were two self‐reported variables, GPA and grade in an educational psychology course, and a test variable, the QED. Multiple Rs using questionnaire data for the predictors were increased slightly by adding the test scores, but on cross‐validation the rs for the two predictor sets were essentially identical. The utility of the tests, then, was not supported either by zero‐order correlations or by cross‐validated increments. Therefore an investigator is reminded at least to include self‐report measures in his set of predictors. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0039581676"
"KATZ M.; NORRIS L.","KATZ, MARTIN (16429462400); NORRIS, LILA (57213303494)","16429462400; 57213303494","THE CONTRIBUTION OF ACADEMIC INTEREST MEASURES TO THE DIFFERENTIAL PREDICTION OF MARKS","1972","Journal of Educational Measurement","9","1","","1","11","10","3","10.1111/j.1745-3984.1972.tb00755.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84984054560&doi=10.1111%2fj.1745-3984.1972.tb00755.x&partnerID=40&md5=d7b67e7b76a918d5a5eff748e4a6614a","In a study of differential predictions of course marks in grades 12 and 13 interest measures were found to add appreciably to differential validities, particularly at the high school level. Differential validities remained quite low; however–typically in the .20's and .30's‐probably because of high intercorrelations among the criteria. The relationship between intercorrelations of actual criteria and intercorrelations of predicted criteria was examined, and the implications of this relationship for differential validities were discussed. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84984054560"
"BOARD C.; WHITNEY D.R.","BOARD, CYNTHIA (57195043178); WHITNEY, DOUGLAS R. (7102971846)","57195043178; 7102971846","THE EFFECT OF SELECTED POOR ITEM‐WRITING PRACTICES ON TEST DIFFICULTY, RELIABILITY AND VALIDITY","1972","Journal of Educational Measurement","9","3","","225","233","8","17","10.1111/j.1745-3984.1972.tb00956.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973796316&doi=10.1111%2fj.1745-3984.1972.tb00956.x&partnerID=40&md5=63b31e62bbc47c0895e087f5a9d2b576","Violations of four selected principles of writing multiple choice items were introduced into an undergraduate political science examination. Three of the four poor practices had no overall effect on test difficulty. A significant (α= .05) interaction effect between the poor practices and course achievement occurred for one of the four practices, with the poorer students generally gaining most from the poorly written items. KR20 values were significantly lower for sets of items with the same flaws than for “good” versions of the items in three of four comparisons. The reductions in reliability were equivalent to those expected to result from shortening the test by 13 to 56 percent. Concurrent validity (correlation of experimental test scores with final examination scores) was significantly lower in two of four cases. The reductions in validity were equivalent to those expected to result from shortening the test by 56 to 83 percent. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973796316"
"BAIRD L.L.","BAIRD, LEONARD L. (16427085000)","16427085000","THE FUNCTIONS OF COLLEGE ENVIRONMENTAL MEASURES","1971","Journal of Educational Measurement","8","2","","83","86","3","2","10.1111/j.1745-3984.1971.tb00909.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939311664&doi=10.1111%2fj.1745-3984.1971.tb00909.x&partnerID=40&md5=d68b72a8f20f9f80edcc2350d5e41cf9","Current college environmental measures are examined with reference to several criteria: whether they are designed to obtain general knowledge or to aid decision making, whether they provide information that distinguishes among institutions or within institutions, and whether they focus on an institution's characteristics or on the people in the institution. Current measures do not seem to be expressly designed to provide information for decision making or information about problems within institutions. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84939311664"
"SPEEDIE S.M.; ASHER J.W.; TREFFINGER D.J.","SPEEDIE, STUART M. (6701410941); ASHER, J. WILLIAM (7005419654); TREFFINGER, DONALD J. (6603004180)","6701410941; 7005419654; 6603004180","COMMENT ON “FLUENCY AS A PERVASIVE ELEMENT IN THE MEASUREMENT OF CREATIVITY”","1971","Journal of Educational Measurement","8","2","","125","126","1","6","10.1111/j.1745-3984.1971.tb00915.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84868177274&doi=10.1111%2fj.1745-3984.1971.tb00915.x&partnerID=40&md5=646e6049814c88bbad6cfdefb090a54e","Clark and Mirels reported a “correction procedure” for fluency in scoring figural divergent thinking measures, which resulted in a reduction from .40 to .20 in the average inter‐correlation of scores excluding fluency. Since their correction involved shortening the test, at least part of the reduction of the inter‐correlations can be explained by the reduced reliability of the test. Estimates of the magnitude of this effect were provided. It was concluded that the “correction” reported is at best a partial correction, and that the potential merit of other procedures should be considered. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84868177274"
"JENKINS J.R.; BAUSELL R.B.; MAGOON A.J.","JENKINS, JOSEPH R. (7402867621); BAUSELL, R. BARKER (7003552786); MAGOON, A. JON (6506450293)","7402867621; 7003552786; 6506450293","SELECTION OF PROSE MATERIAL FOR TESTING","1972","Journal of Educational Measurement","9","2","","97","103","6","1","10.1111/j.1745-3984.1972.tb00764.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950343342&doi=10.1111%2fj.1745-3984.1972.tb00764.x&partnerID=40&md5=a26c6670109725f45fe5a9662bb1ae4e","The study investigated teachers' selection of prose material for testing. Thirty elementary school social studies teachers wrote test questions based on a 1900 word passage from a commercial social studies text. Moderate consensus was observed among the teachers as to those segments of the passage chosen for testing. Additional analyses to determine the characteristics of the passage segments selected for testing were performed. The most frequently selected text segments were sentences which either contained a list or were themselves an entry in a list. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-77950343342"
"AKEJU S.A.","AKEJU, S.A. (57195042851)","57195042851","THE RELIABILITY OF GENERAL CERTIFICATE OF EDUCATION EXAMINATION ENGLISH COMPOSITION PAPERS IN WEST AFRICA","1972","Journal of Educational Measurement","9","3","","175","180","5","5","10.1111/j.1745-3984.1972.tb00949.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248960821&doi=10.1111%2fj.1745-3984.1972.tb00949.x&partnerID=40&md5=a86b8fa249c5eeed0d419713ffa53e77","After going through the West African Examinations Council (WAEC) usual standardization procedures for marking essay‐type tests, ten trained examiners independently marked the English Composition scripts of 100 Ghana candidates in General Certificate of Education Examination of June 1970. The marks awarded to 96 of the candidates by seven of the examiners were analysed to evaluate the extent to which the standardization procedures ensured: (a) high inter‐rater (reading) reliability, and (b) comparability of marks. An analysis of variance of the scores revealed that the examiners used different standards for marking and that the inter‐rater (reader) reliability was not satisfactory. Suggestions were made for the improvement of the reliability and comparability and for the use of multiple‐choice type tests to measure writing ability. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-34248960821"
"THORNDIKE R.L.","THORNDIKE, ROBERT L. (16652297900)","16652297900","CONCEPTS OF CULTURE‐FAIRNESS","1971","Journal of Educational Measurement","8","2","","63","70","7","146","10.1111/j.1745-3984.1971.tb00907.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0038197700&doi=10.1111%2fj.1745-3984.1971.tb00907.x&partnerID=40&md5=31999b9ddcc260d7e0a012dc0f9a67a8","Fairness of a test relates to fair use. One definition of fair use states that a common qualifying score may be used with two groups if the regression line based on one group does not systematically over‐ or under‐predict criterion performance in the other. However, it is shown that when the two groups differ appreciably in mean test score, the above procedure, which is “fair” to individual members of the group scoring lower on the test, is “unfair” to the lower group as a whole in the sense that the proportion qualified on the test will be smaller, relative to the higher‐scoring group, than the proportion that will reach any specified level of criterion performance. An alternate definition would specify that the qualifying scores on a test should be set at levels that will qualify applicants in the two groups in proportion to the fraction of the two groups reaching a specified level of criterion performance. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0038197700"
"WILSON R.C.; DIENST E.R.; WATSON N.L.","WILSON, ROBERT C. (57195043891); DIENST, EVELYN R. (6507649614); WATSON, NANCY L. (57195042696)","57195043891; 6507649614; 57195042696","CHARACTERISTICS OF EFFECTIVE COLLEGE TEACHERS AS PERCEIVED BY THEIR COLLEAGUES","1973","Journal of Educational Measurement","10","1","","31","37","6","9","10.1111/j.1745-3984.1973.tb00779.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-52849086579&doi=10.1111%2fj.1745-3984.1973.tb00779.x&partnerID=40&md5=7bb0f7db3790393a26825e3b14c7d76e","The purpose of the research was to study the dimensions faculty members associate with being a good teacher. One hundred nineteen faculty members described the most effective and least effective teacher they knew using a set of 67 statements. A principal‐components analysis of the descriptions of effective teachers produced 5 factors: Research Activity and Recognition, Participation in the Academic Community, Intellectual Breadth, Relations with Students, and Concern for Teaching. Only Research Activity and Recognition was significantly related to the academic rank and discipline of teachers nominated as effective. Rank, discipline, age and length of teaching experience of the nominators were unrelated to their descriptions of effective teachers. However, faculty with heavier teaching loads were more likely to assign high scores on Concern for Teaching and low scores on Research Activity and Recognition to the teacher they nominated as effective. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-52849086579"
"BUNDA M.A.","BUNDA, MARY ANNE (6508173177)","6508173177","AN INVESTIGATION OF AN EXTENSION OF ITEM SAMPLING WHICH YIELDS INDIVIDUAL SCORES","1973","Journal of Educational Measurement","10","2","","117","130","13","4","10.1111/j.1745-3984.1973.tb00789.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915061262&doi=10.1111%2fj.1745-3984.1973.tb00789.x&partnerID=40&md5=23cad4fd9acc693ec909b28ae7c1a10f","The sampling procedures were designed so that the full matrix of item variances and covariances could be estimated. Three subtest sizes were investigated‐ subtests of size five, nine and sixteen items. In each of these implementations a double cross validation was used yielding two predicted scores for each individual. Discrepancy measures were also computed showing the difference between the observed and the predicted scores. The prediction of individual scores was accomplished within various ranges of error. The correlations between predicted scores and observed scores ranged from the .70′s to the .90′s, depending on the number of predictor variables used. The procedure is applicable in situations in which large numbers of individuals are tested or in situations where multiple measures are taken. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84915061262"
"PAGE E.B.","PAGE, ELLIS BATTEN (7103396107)","7103396107","SEEKING A MEASURE OF GENERAL EDUCATIONAL ADVANCEMENT: THE BENTEE","1972","Journal of Educational Measurement","9","1","","33","43","10","8","10.1111/j.1745-3984.1972.tb00759.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973760671&doi=10.1111%2fj.1745-3984.1972.tb00759.x&partnerID=40&md5=e122993461a548129c5519fa19afec5b","An urgent need is for some overall unit of educational benefit, and it is here proposed that such be established by certain scaling techniques. Groups of judges are asked to render overall evaluations on “students” of specified characteristics. Their evaluations are studied for correlation with the student traits, and the resultant coefficients, loaded with latent and applied values, become defensible weights to describe other students' overall educational advancement. The general unit so developed, when normalized for the target population, may be termed a “benefit T‐score”, or more simply “bentee”. Recursive features of the scaling process, applicable at different levels of generality, should provide for a shift from value‐space to test‐space, and from societal to expert opinion. Discovered weightings should illuminate differing values of lay and professional groups within society. And the bentee could provide an objective function suitable for optimizing in management‐science techniques, now largely neglected in curriculum and administration. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973760671"
"KALLINGAL A.","KALLINGAL, ANTHONY (57195042866)","57195042866","THE PREDICTION OF GRADES FOR BLACK AND WHITE STUDENTS AT MICHIGAN STATE UNIVERSITY","1971","Journal of Educational Measurement","8","4","","263","265","2","15","10.1111/j.1745-3984.1971.tb00935.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0040653732&doi=10.1111%2fj.1745-3984.1971.tb00935.x&partnerID=40&md5=d343d009770ee2b165fd7e8c507d9a76","The regression equations of sophomore year cumulative grade point averages on five ability and achievement test scores for blacks and whites at Michigan State University showed a significant difference. However, use of these separate regression equations would not be in favor of black students. The variance accounted for by the predictors was similar for both groups. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0040653732"
"ROSSMAN B.B.; HORN J.L.","ROSSMAN, B.B. (6602562751); HORN, J.L. (7203079849)","6602562751; 7203079849","COGNITIVE, MOTIVATIONAL AND TEMPERAMENTAL INDICANTS OF CREATIVITY AND INTELLIGENCE","1972","Journal of Educational Measurement","9","4","","265","286","21","35","10.1111/j.1745-3984.1972.tb00959.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84989746392&doi=10.1111%2fj.1745-3984.1972.tb00959.x&partnerID=40&md5=2e105807c1fdb512f1fc14258e7f4574","Relationships between measures of creativity and measures of intelligence were analysed to show that even when the intercorrelations among the former are not appreciably larger than correlations between creativity and intelligence measures, dimensions of creativity are found to be psychometrically and conceptually distinct from dimensions of intelligence. One hundred eighty‐eight art and engineering college students were administered objective tests and questionnaires designed to tap a number of ability and nonability indicants of creativity and intelligence. Some of these measures were of a kind that some investigators would regard as “criterion” measures of creativity and intelligence. Data were analysed by means of correlational and factor analytic procedures. Eight major influences were indicated by independent factors rotated to approximate simple structure. The influences represented by these factors were identified as: fluid intelligence, crystallized intelligence, memory, fluency, rule‐orientation versus intuitive thinking, and self‐sufficient‐calculated‐risk‐taking. The fourth, seventh, and eighth factors were discussed as representing distinct cognitive, motivational, and temperamental aspects of creativity. At the level of test intercorrelations discriminant validity did not obtain–measures of creativity did not intercorrelate more highly among themselves than they correlated with measures of intelligence. The putative factors of creativity did correlate more highly with creativity criteria, however, than did the factors identified as representing intelligence. Moreover, the intelligence factors were more highly related to intelligence criteria than to creativity criteria. Thus the evidence of this study suggests that it is useful to think of creativity and intelligence as the outgrowths of distinct (although overlapping) sets of influences, even when this is not well indicated by discriminant‐convergent validation analyses carried out with respect to tests (in contrast to factors). Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84989746392"
"CARVER R.P.; DARBY C.A., JR.","CARVER, RONALD P. (7005570366); DARBY, CHARLES A. (57189407980)","7005570366; 57189407980","DEVELOPMENT AND EVALUATION OF A TEST OF INFORMATION STORAGE DURING READING","1971","Journal of Educational Measurement","8","1","","33","44","11","6","10.1111/j.1745-3984.1971.tb00904.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350286958&doi=10.1111%2fj.1745-3984.1971.tb00904.x&partnerID=40&md5=b8991c84e258105494f859627df1393a","Previous research has suggested potential advantages for a new type of item for measuring comprehension in reading and listening. The test items are called “chunked” and consist of groups of meaningfully related words in which certain groups have been changed in meaning from the original passage. A chunked type of test, designed to indicate information stored during reading, was developed and analyzed in two studies. The results of Study 1, indicated that the constructed test items were successful in differentiating between readers and nonreaders of the newly composed reading passages. “Using the results of Study I, test items were revised and two forms of a test were produced, complete with standardized instructions. The major purpose of Study 2 was to evaluate the extent to which the revised and standardization test could discriminate between a group of individuals who took the test in its standard form and another group which was given the same amount of time to work on the test items but was not given the benefit of reading the passages. The major result in Study 2 was that individuals who had not read the passages experienced a 75% decrement in their performance on Form A of the Chunked Reading Test as compared to individuals who had read the passages, and for Form B, nonreaders experienced a 78% decrement. From these re‐ sults, it was concluded that the Chunked Reading Test is a valid test of information storage during reading in terms of its utility in measuring the differences in information stored between readers and nonreaders of passages, and that it offers many advantages over the traditional standardized reading tests. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-70350286958"
"LORD F.M.","LORD, FREDERIC M. (16463899300)","16463899300","THE SELF‐SCORING FLEXILEVEL TEST","1971","Journal of Educational Measurement","8","3","","147","151","4","49","10.1111/j.1745-3984.1971.tb00918.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988026809&doi=10.1111%2fj.1745-3984.1971.tb00918.x&partnerID=40&md5=9b3105a62f5d73ab925a466cbfec6cf3","Modifications of administration and item arrangement of a conventional test can force a match between item difficulty levels and the ability level of the examinee. Although different examinees take different sets of items, the scoring method provides comparable scores for all. Furthermore, the test is self‐scoring. These advantages are obtained without some of the usual disadvantages of tailored testing. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988026809"
"QUERESHI M.Y.","QUERESHI, M.Y. (6603692585)","6603692585","NOTE ON THE PEARSON r AS A FUNCTION OF THE BIVARIATE DISTRIBUTIONAL CHARACTERISTICS","1971","Journal of Educational Measurement","8","3","","225","227","2","1","10.1111/j.1745-3984.1971.tb00931.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875240649&doi=10.1111%2fj.1745-3984.1971.tb00931.x&partnerID=40&md5=4ad54df2b9a86e7329965aedf29686f2","Methodological difficulties inherent in the estimation of bivariate relationships due to distortions caused by distributional irregularities were investigated empirically. The data represented the performance of 700 Ss between two and ten years of age on nine ITPA subtests and the Stanford‐Binet scale. The results indicated that scaling errors of one type or another caused considerable discrepancy in the measurement of underlying relations, but the effect of non‐normality was minimum. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84875240649"
"HARTNETT R.T.","HARTNETT, RODNEY T. (16486999100)","16486999100","A NOTE ON THE COMPARABILITY OF ALTERNATIVE SCORING METHODS FOR THE INSTITUTIONAL FUNCTIONING INVENTORY","1971","Journal of Educational Measurement","8","4","","311","315","4","0","10.1111/j.1745-3984.1971.tb00944.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024986507&doi=10.1111%2fj.1745-3984.1971.tb00944.x&partnerID=40&md5=b22bb814520784da094651113c90a0fa","Alternative methods of scoring the Institutional Functioning Inventory, a new measure of college environments, were compared. Institutional means obtained by the standard psychometric method–i.e., scoring each person's response to each item and then computing group means–were correlated with institutional means obtained via the “66+/33‐” method used for the College & University Environment Scales. The alternative scoring methods yield essentially the same information, including scale intercorrelations and validity. Reasons for preferring the traditional psychometric scoring technique are offered. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024986507"
"SHAVELSON R.J.; BLOCK J.H.; RAVITCH M.M.","SHAVELSON, RICHARD J. (35613093400); BLOCK, JAMES H. (25953851700); RAVITCH, MICHAEL M. (7101760869)","35613093400; 25953851700; 7101760869","CRITERION‐REFERENCED TESTING: COMMENTS ON RELIABILITY","1972","Journal of Educational Measurement","9","2","","133","137","4","13","10.1111/j.1745-3984.1972.tb00768.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915074740&doi=10.1111%2fj.1745-3984.1972.tb00768.x&partnerID=40&md5=03eccfbb99063a29db8bcc99a42277cc","Currently there is concern among some educators regarding the reliability of criterion‐referenced (CR) measures. In this comment, a recent attempt to develop a theory of reliability for CR measures is examined, and some considerations for determining the reliability of CR measures are discussed. Conventional reliability statistics (e.g., coefficient alpha, standard error of measurement) are found appropriate for CR measures satisfying the assumptions of the measurement model underlying classical test theory. For measures with underlying multidimensional traits, conventional reliability statistics may be used at the homogeneous subscale level. When the confidence interval about a student's “below criterion score” includes the criterion, additional evidence about the student should be obtained. Two‐stage sequential testing is suggested as one method for acquiring additional evidence. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84915074740"
"DARLINGTON R.B.","DARLINGTON, RICHARD B. (59025395800)","59025395800","ANOTHER LOOK AT “CULTURAL FAIRNESS”","1971","Journal of Educational Measurement","8","2","","71","82","11","115","10.1111/j.1745-3984.1971.tb00908.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993755560&doi=10.1111%2fj.1745-3984.1971.tb00908.x&partnerID=40&md5=f22908d23144d09e95ee723e0bf3a8c6","Four definitions of “cultural fairness” are examined and found to be not only mutually contradictory (for reasons which are explained), but all based on the false view that optimum treatment of cultural factors in test construction or test selection can be reduced to completely mechanical procedures. If a conflict arises between the two goals of maximizing a test's validity and minimizing the test's discrimination against certain cultural groups, then a subjective, policy‐level decision must be made concerning the relative importance of the two goals. The terms in which this judgment should be made are described, and methods are described for entering the result of this judgment into mechanical procedures for constructing a “culturally optimum” test. Such a test will not necessarily fit any of the four definitions of “cultural fairness.” Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84993755560"
"MERWIN J.C.","MERWIN, JACK C. (25952951500)","25952951500","EDUCATIONAL MEASUREMENT OF WHAT CHARACTERISTIC OF WHOM (OR WHAT) BY WHOM AND WHY","1973","Journal of Educational Measurement","10","1","","1","5","4","1","10.1111/j.1745-3984.1973.tb00774.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-33846900577&doi=10.1111%2fj.1745-3984.1973.tb00774.x&partnerID=40&md5=103a3e4d9c09fadc1f958675c9c1d686","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-33846900577"
"LIVINGSTON S.A.","LIVINGSTON, SAMUEL A. (35864363200)","35864363200","REPLY TO SHAVELSON, BLOCK, AND RAVITCH'S “CRITERION‐REFERENCED TESTING: COMMENTS ON RELIABILITY”","1972","Journal of Educational Measurement","9","2","","139","140","1","6","10.1111/j.1745-3984.1972.tb00769.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987200471&doi=10.1111%2fj.1745-3984.1972.tb00769.x&partnerID=40&md5=0da81441ec44ea6f283d62d7bd1c22ee","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987200471"
"MULLER D.; CALHOUN E.; ORLING R.","MULLER, DOUGLAS (7403361856); CALHOUN, EMORY (57195044164); ORLING, ROBERT (57195040145)","7403361856; 57195044164; 57195040145","TEST RELIABILITY AS A FUNCTION OF ANSWER SHEET MODE","1972","Journal of Educational Measurement","9","4","","321","324","3","4","10.1111/j.1745-3984.1972.tb00964.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013342959&doi=10.1111%2fj.1745-3984.1972.tb00964.x&partnerID=40&md5=ea17be611760a2e6885f427bc38b40e7","The purpose of this study was to examine the effect of using separate, machine scorable answer sheets on the number of marking errors made by third‐, fourth‐, and sixth‐grade students. Half of the Ss at each grade level answered in the test booklet (AIB), and half answered on separate answer sheets (SAS). The number of marking errors for the SAS group was approximately three times as great as for the AIB group at each grade level. This indicates that test standardization information must specify the answer sheet mode used to collect normative data. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85013342959"
"LIVINGSTON S.A.","LIVINGSTON, SAMUEL A. (35864363200)","35864363200","A REPLY TO HARRIS “AN INTERPRETATION OF LIVINGSTON'S RELIABILITY COEFFICIENT FOR CRITERION‐REFERENCED TESTS”","1972","Journal of Educational Measurement","9","1","","31","31","0","20","10.1111/j.1745-3984.1972.tb00758.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973770339&doi=10.1111%2fj.1745-3984.1972.tb00758.x&partnerID=40&md5=3378a3ff4234393f853552bb2835e862","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84973770339"
"McMORRIS R.F.","McMORRIS, ROBERT F. (6603270899)","6603270899","EVIDENCE ON THE QUALITY OF SEVERAL APPROXIMATIONS FOR COMMONLY USED MEASUREMENT STATISTICS","1972","Journal of Educational Measurement","9","2","","113","122","9","4","10.1111/j.1745-3984.1972.tb00766.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84972720694&doi=10.1111%2fj.1745-3984.1972.tb00766.x&partnerID=40&md5=6abf75ca1db96eed82ae54790ec23745","What is the extent of error likely with each of several approximations for the standard deviation, internal consistency reliability, and the standard error of measurement? To help answer this question, approximations were compared with exact statistics obtained on 85 different classroom tests constructed and administered by professors in a variety of fields; means and standard deviations of the resulting differences supported the use of approximations in practical situations. Results of this analysis (1) suggest a greater number of alternative formulas that might be employed, and (2) provide additional information concerning the accuracy of approximations with non‐normal distributions. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84972720694"
"RAMSEYER G.C.; CASHEN V.M.","RAMSEYER, GARY C. (6701707519); CASHEN, VALJEAN M. (6506395259)","6701707519; 6506395259","THE EFFECT OF PRACTICE SESSIONS ON THE USE OF SEPARATE ANSWER SHEETS BY FIRST AND SECOND GRADERS","1971","Journal of Educational Measurement","8","3","","177","181","4","8","10.1111/j.1745-3984.1971.tb00922.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84952185621&doi=10.1111%2fj.1745-3984.1971.tb00922.x&partnerID=40&md5=2fb2426abb7fed3a517f0ef4bddc1a71","The purpose of this study was to determine the effect of formal practice sessions on the ability of first and second graders to use separate answer sheets on the California Test of Mental Maturity. The Ss were all 79 pupils enrolled in these grades at one elementary school. Academically, these Ss were above average. Through the use of a counterbalanced design, the CTMM was administered twice to all Ss; once employing the usual answer marking format contained in the test booklet and once employing a separate answer sheet preceded by a formal practice session. Significant mean raw score differences between formats of 10.30 and 7.19 were obtained for Ss in grades one and two respectively in favor of the booklet format. Accuracy scores, which removed the effect of speed from raw score performances, were also analyzed and the results confirmed the superiority of the booklet format. It was concluded that even with prior practice sessions, above average pupils in grades one and two are unable to utilize separate answer sheets in an effective manner. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84952185621"
"McMORRIS R.F.; BROWN J.A.; SNYDER G.W.; PRUZEK R.M.","McMORRIS, ROBERT F. (6603270899); BROWN, JAMES A. (57195041924); SNYDER, GERALD W. (57195040427); PRUZEK, ROBERT M. (6603082283)","6603270899; 57195041924; 57195040427; 6603082283","EFFECTS OF VIOLATING ITEM CONSTRUCTION PRINCIPLES","1972","Journal of Educational Measurement","9","4","","287","295","8","22","10.1111/j.1745-3984.1972.tb00960.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994941249&doi=10.1111%2fj.1745-3984.1972.tb00960.x&partnerID=40&md5=152c8ca6c7c204a19164b5b409f16c76","Two forms of a social studies achievement test were constructed with half the items for each form containing a cue, grammar, or length fault. Faults were found to make the items easier, which was supported by confidence intervals for the differences. However, validity coefficients with achievement and intelligence criteria, as well as the reliability coefficients, were virtually unchanged. The results agreed with those of Dunn and Goldstein (1959), even though the methodology differed. A suggested measure of test‐wiseness for groups is presented. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84994941249"
"EBEL R.L.","EBEL, ROBERT L. (16050366400)","16050366400","EVALUATION AND EDUCATIONAL OBJECTIVES","1973","Journal of Educational Measurement","10","4","","273","279","6","7","10.1111/j.1745-3984.1973.tb00804.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973768062&doi=10.1111%2fj.1745-3984.1973.tb00804.x&partnerID=40&md5=06d72dc26115acfdcff964bf9bfc6e4e","The propositions advanced and defended in this article are: (1) that it is more urgent for educators to reach agreement on their general purposes and goals than to specify in detail the outcomes they seek; (2) that insistance on detailed statements of educational objectives is questionable; (3) that teachers should be more concerned with developing a pupil's cognitive resources than with changing his behavior; (4) that criterion‐referenced measures should supplement, not supplant norm‐referenced measures; and (5) that conventional test statistics are appropriate for criterion‐referenced tests if they are based on appropriate test responses. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973768062"
"STALLINGS W.M.; GILLMORE G.M.","STALLINGS, WILLIAM M. (16437347300); GILLMORE, GERALD M. (6701577870)","16437347300; 6701577870","A NOTE ON “ACCURACY” AND “PRECISION”","1971","Journal of Educational Measurement","8","2","","127","129","2","24","10.1111/j.1745-3984.1971.tb00916.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85008061578&doi=10.1111%2fj.1745-3984.1971.tb00916.x&partnerID=40&md5=b6788471258b2ff079f841e7379bef11","The terms accuracy and precision are consistently differentiated in the literature of engineering and the “hard” sciences. Precision shares a common core of meaning with reliability as used by behavioral scientists. Accuracy and validity have a similar semantic overlap. A review of the literature in educational and psychological measurement reveals an interchangeable usage of accuracy and precision in defining reliability, To help beginning students distinguish between validity and reliability, this paper advocates the use of precision, rather than accuracy, in describing reliability. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85008061578"
"FORSYTH R.A.","FORSYTH, ROBERT A. (57029929200)","57029929200","SOME EMPIRICAL RESULTS RELATED TO THE STABILITY OF PERFORMANCE INDICATORS IN DYER'S STUDENT CHANGE MODEL OF AN EDUCATIONAL SYSTEM","1973","Journal of Educational Measurement","10","1","","7","12","5","9","10.1111/j.1745-3984.1973.tb00775.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939441188&doi=10.1111%2fj.1745-3984.1973.tb00775.x&partnerID=40&md5=e513fdf8bf8e602348020464a877c8cc","Dyer, et al. (1967) have proposed a model for school system evaluation. The usefulness of the indices obtained from this model depend on the reliability or stability of the indices. This study presents evidence related to the stability of these indices when pupils and factors related to time are considered as sources of error. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84939441188"
"DIAMOND J.J.; EVANS W.J.","DIAMOND, JAMES J. (57018442400); EVANS, WILLIAM J. (35411671500)","57018442400; 35411671500","AN INVESTIGATION OF THE COGNITIVE CORRELATES OF TEST‐WISENESS","1972","Journal of Educational Measurement","9","2","","145","150","5","26","10.1111/j.1745-3984.1972.tb00771.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84950189126&doi=10.1111%2fj.1745-3984.1972.tb00771.x&partnerID=40&md5=c3b738d17fe72aa1cb612feebc1b1c1a","Gibb (1964) defined test‐wiseness (TW) as the ability to respond advantageously to multiple‐choice items containing extraneous clues and therefore to obtain credit without knowledge of the subject matter being tested. This study investigated TW in a sample of 6th grade pupils. A test instrument was developed utilizing fictitious material similar to the strategy employed by Slakter, Koehler & Hampton (1970). The study examines the cognitive correlates of TW through the interpretation of correlational matrices. The results lend support to the notion that TW is not a general trait, but rather is clue‐specific. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84950189126"
"MENNE J.W.; TOLSMA R.J.","MENNE, JOHN W. (24796104000); TOLSMA, ROBERT J. (57195042430)","24796104000; 57195042430","A DISCRIMINATION INDEX FOR ITEMS IN INSTRUMENTS USING GROUP RESPONSES","1971","Journal of Educational Measurement","8","1","","5","7","2","4","10.1111/j.1745-3984.1971.tb00899.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977051629&doi=10.1111%2fj.1745-3984.1971.tb00899.x&partnerID=40&md5=a8a816831b81616ba2a7ccd1e0372adc","Item discrimination for instruments used to measure characteristics by means of group responses is stressed. It is argued that a percentage of the total sum of squares which is due to groups can appropriately be used as an index of item discrimination. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84977051629"
"REILING E.; TAYLOR R.","REILING, ELDON (57190106190); TAYLOR, RYLAND (56987056800)","57190106190; 56987056800","A NEW APPROACH TO THE PROBLEM OF CHANGING INITIAL RESPONSES TO MULTIPLE CHOICE QUESTIONS","1972","Journal of Educational Measurement","9","1","","67","70","3","30","10.1111/j.1745-3984.1972.tb00762.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0039630553&doi=10.1111%2fj.1745-3984.1972.tb00762.x&partnerID=40&md5=2dc6a86147971a74c0662d85b85cc54b","The hypothesis that it is unwise to change answers to multiple choice questions was tested using the technique of multiple regression analysis. The net number of correct answers as a result of changing responses was regressed against final grade in the course, numeric score on the exam, percent of total answers changed for all questions and for analytical questions, sex of the student, and scope of the exam. The results show that there are gains to be made by changing responses. The variables which proved to be significant indicated that students who did well on the test changed a large percentage of answers, and that those who were taking a final exam tended to gain more. Final grades, sex of the student, and analytical questions had no significant impact on gains from changing responses. On the basis of the results gathered, the authors reject the hypothesis that changing responses is unwise. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0039630553"
"LIVINGSTON S.A.","LIVINGSTON, SAMUEL A. (35864363200)","35864363200","A NOTE ON THE INTERPRETATION OF THE CRITERION‐REFERENCED RELIABILITY COEFFICIENT","1973","Journal of Educational Measurement","10","4","","311","311","0","5","10.1111/j.1745-3984.1973.tb00809.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907155430&doi=10.1111%2fj.1745-3984.1973.tb00809.x&partnerID=40&md5=002648d8a7d7c56497e2b4afc32961ec","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84907155430"
"BARCIKOWSKI R.S.","BARCIKOWSKI, ROBERT S. (14038706500)","14038706500","A MONTE CARLO STUDY OF ITEM SAMPLING (VERSUS TRADITIONAL SAMPLING) FOR NORM CONSTRUCTION","1972","Journal of Educational Measurement","9","3","","209","214","5","6","10.1111/j.1745-3984.1972.tb00954.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973712375&doi=10.1111%2fj.1745-3984.1972.tb00954.x&partnerID=40&md5=27e565f1173297b12ff5cd2d2d6be267","Using a computer‐based model of an item trace line, a random sampling experiment concerned with comparing item sample estimates to traditional (examinee) sample estimates of the mean and variance of a distribution of test scores was conducted. The results indicated that the optimal method for estimating a test's parameters may depend on several conditions. As expected, item sampling proved superior to traditional sampling in estimating test means under all conditions. However, with certain test lengths, ranges of item difficulty, and discrimination, traditional sampling provided better estimates of test variance than did item sampling. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973712375"
"HUCK S.W.; BOWERS N.D.","HUCK, SCHUYLER W. (7006803001); BOWERS, NORMAN D. (56947279700)","7006803001; 56947279700","ITEM DIFFICULTY LEVEL AND SEQUENCE EFFECTS IN MULTIPLE‐CHOICE ACHIEVEMENT TESTS","1972","Journal of Educational Measurement","9","2","","105","111","6","25","10.1111/j.1745-3984.1972.tb00765.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970180715&doi=10.1111%2fj.1745-3984.1972.tb00765.x&partnerID=40&md5=f4914af3c3dd523aaa1c35a3ad3d6492","Certain testing authorities have implied that the proportion of examinees who answer an item correctly may be influenced by the difficulty of the immediately preceding item. If present, such a “sequence effect” would cause p (as an estimate of item difficulty level) to misrepresent an item's “true” level of difficulty. To investigate this hypothesis, a balanced Latin square design was used to rearrange examination items into various test forms. A unique analysis of variance procedure was used to analyze the resulting data. The alleged sequence effect was not found. Certain limitations preclude the generalization of this finding to all students or to all testing situations. However, the evidence provided by this investigation does suggest that comments relating to sequence effects should be qualified as compared with presently appearing statements. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970180715"
"SABERS D.L.; KLAUSMEIER R.D.","SABERS, DARRELL L. (6701710722); KLAUSMEIER, RICHARD D. (24580164400)","6701710722; 24580164400","ACCURACY OF SHORT‐CUT ESTIMATES FOR STANDARD DEVIATION","1971","Journal of Educational Measurement","8","4","","335","339","4","0","10.1111/j.1745-3984.1971.tb00948.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024977534&doi=10.1111%2fj.1745-3984.1971.tb00948.x&partnerID=40&md5=b3e1c569b0fed687727717d059a931d1","The accuracy of short‐cut estimates of standard deviation was investigated for distributions of raw scores on classroom tests and computer generated samples. Estimates proposed by Mason and Odeh, Jenkins, Diederich, Ebel, and Davenport were compared for relative accuracy in three studies. The loss in accuracy due to short‐cut methods versus the conventional statistic ranged from 0 to 7,8%. Based on the findings of these studies, it is recommended that a shortcut method for computing standard deviations he included in courses where the conventional formula is taught. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024977534"
"BOLEA A.S.; FELKER D.W.; BARNES M.D.","BOLEA, ANGELO S. (57195043006); FELKER, DONALD W. (6603450859); BARNES, MARGARET D. (57195041553)","57195043006; 6603450859; 57195041553","A PICTORIAL SELF‐CONCEPT SCALE FOR CHILDREN IN K‐4","1971","Journal of Educational Measurement","8","3","","223","224","1","11","10.1111/j.1745-3984.1971.tb00930.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009314972&doi=10.1111%2fj.1745-3984.1971.tb00930.x&partnerID=40&md5=46bad84a95678f7c38506101114df386","Described is a scale of self‐concept that does not require reading and can be group administered to children in K‐4. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85009314972"
"LINDSAY C.A.; PRICHARD M.A.","LINDSAY, CARL A. (16463709700); PRICHARD, MARK A. (57195044795)","16463709700; 57195044795","AN ANALYTICAL PROCEDURE FOR THE EQUIPERCENTILE METHOD OF EQUATING TESTS","1971","Journal of Educational Measurement","8","3","","203","207","4","3","10.1111/j.1745-3984.1971.tb00926.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965544650&doi=10.1111%2fj.1745-3984.1971.tb00926.x&partnerID=40&md5=2c2a13513f4462e575a06b34a069a773","Prior use of the equipercentile method of test equating was based on a graphic procedure which is tedious, subject to smoothing errors, and non‐analytical. Recognition of the equipercentile method as a curve‐fitting procedure for two cumulative percentage distributions leads to a proposed analytical solution to the problem through use of linear estimates for successive “missing” cumulative percentage points. A complete equipercentile procedure which uses the proposed method and provides linear and quadratic functions for goodness‐of‐fit and extrapolation is discussed and illustrated with data from a test equating project. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965544650"
"BIGGS J.B.; BRAUN P.H.","BIGGS, J.B. (7101919145); BRAUN, P.H. (57189655680)","7101919145; 57189655680","MODELS OF EVALUATION AND THEIR RELATION TO STUDENT CHARACTERISTICS","1972","Journal of Educational Measurement","9","4","","303","309","6","1","10.1111/j.1745-3984.1972.tb00962.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0009099615&doi=10.1111%2fj.1745-3984.1972.tb00962.x&partnerID=40&md5=79b2fb51523c4affbd763634446a62c1","The union and disjunction models for combining individual test marks to yield final grade distributions were outlined. It was expected that these models would differentially favor students according to their characteristic methods of learning and studying. The models were examined empirically in two educational psychology classes; five performance assessments were available, as well as eleven dimensions of study behavior and academic attitudes. While there was a substantial correlation between the distributions derived from the two models, they were found significantly to favor different student characteristics. The union model, relative to the disjunction model, favored students who were dependent, who interrelated different aspects of their course work, who scheduled their work and who rote‐learned material. These differences were interpreted in terms of the educational assumptions underlying the two models. Some implications of the study for grading practice were suggested. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0009099615"
"HENDRICKSON G.F.","HENDRICKSON, GERRY F. (57195042974)","57195042974","THE EFFECT OF DIFFERENTIAL OPTION WEIGHTING ON MULTIPLE‐CHOICE OBJECTIVE TESTS","1971","Journal of Educational Measurement","8","4","","291","296","5","17","10.1111/j.1745-3984.1971.tb00941.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965936392&doi=10.1111%2fj.1745-3984.1971.tb00941.x&partnerID=40&md5=512513b9dae41426aaea3edb43e80d40","The purpose of this study was to determine in what way Guttman weighting affected the internal consistency and intercorrelation of the suhtests of the Scholastic Aptitude Test. The tests were first scored with Guttman weights and then with conventional correction‐for‐guessing weights. The internal consistency of the tests increased markedly when Guttman weights were used. The correlation of the two verbal subtests increased somewhat when Guttman weights were used, but the correlation of the two mathematics subtests as well as the intercorrelation of all verbal and mathematics subtests decreased. Differences in the factor structure of the Guttman‐ and conventionally‐weighted subtests were used to explain the result. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965936392"
"PHILLIPS B.N.","PHILLIPS, BEEMAN N. (7401447546)","7401447546","SCHOOL STRESS AS A FACTOR IN CHILDREN'S RESPONSES TO TESTS AND TESTING","1971","Journal of Educational Measurement","8","1","","21","26","5","2","10.1111/j.1745-3984.1971.tb00902.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945767022&doi=10.1111%2fj.1745-3984.1971.tb00902.x&partnerID=40&md5=4fd4597e87403e8b570b8ec60a1c0da0","Response styles are conceptualized as stress reactions, and the stressful school experiences of acquiescent, negativistic, self‐enhancing, and self‐derogating children are studied. It was found that school interpersonal stress was lower among acquiescent than negativistic Ss, while school academic stress was higher among self‐enhancing than self‐derogating Ss. One of the major implications of the conceptual approach and empirical results is that tests might be generally improved by identifying the kinds of stressful experiences Ss have had, and relating these to the kinds of responses Ss make to tests and testing. In addition, while the importance of the reaction of Ss to the measuring process is generally accepted, much more needs to be done on the kinds of responses individuals make to the content, in comparison to the conditions, of testing. Finally, these observations are particularly pertinent to tests and testing in schools, especially when the teacher is involved in the process and makes tests and testing stressful. This will tend to increase the effects of response style tendencies and decrease the validity of tests. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84945767022"
"SOLOMON A.","SOLOMON, ALAN (57010775300)","57010775300","THE EFFECT OF ANSWER SHEET FORMAT ON TEST PERFORMANCE BY CULTURALLY DISADVANTAGED FOURTH GRADE ELEMENTARY SCHOOL PUPILS","1971","Journal of Educational Measurement","8","4","","289","290","1","3","10.1111/j.1745-3984.1971.tb00940.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973828685&doi=10.1111%2fj.1745-3984.1971.tb00940.x&partnerID=40&md5=65ed765c052dadb366797023eb180972","Answer sheet format was shown to have no effect on the test performance of culturally deprived fourth grade elementary school students. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973828685"
"LIVINGSTON S.A.","LIVINGSTON, SAMUEL A. (35864363200)","35864363200","CRITERION‐REFERENCED APPLICATIONS OF CLASSICAL TEST THEORY","1972","Journal of Educational Measurement","9","1","","13","26","13","102","10.1111/j.1745-3984.1972.tb00756.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0002119909&doi=10.1111%2fj.1745-3984.1972.tb00756.x&partnerID=40&md5=b69e762d49a02590d7e627a5cebe7331","A reliability coefficient for criterion‐referenced tests is developed from the assumptions of classical test theory. This coefficient is based on deviations of scores from the criterion score, rather than from the mean. The coefficient is shown to have several of the important properties of the conventional normreferenced reliability coefficient, including its interpretation as a ratio of variances and as a correlation between parallel forms, its relationship to test length, its estimation from a single form of a test, and its use in correcting for attenuation due to measurement error. Norm‐referenced measurement is considered as a special case of criterion‐referenced measurement. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0002119909"
"WOLFE J.M.","WOLFE, JACK M. (56931522000)","56931522000","A SIMPLE METHOD OF CALCULATING THE COEFFICIENT OF CORRELATION","1971","Journal of Educational Measurement","8","3","","221","222","1","0","10.1111/j.1745-3984.1971.tb00929.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024971170&doi=10.1111%2fj.1745-3984.1971.tb00929.x&partnerID=40&md5=0812e0a8d7a666a8af698504c7db4596","Where two sets of measurements can each be grouped into below average, average and above average classifications with an equal number assigned to each of the below average and above average classifications, a 3 by 3 table can then be tabulated with frequency counts. The exact value of the product moment coefficient of correlation can then be calculated very simply by means of the formula, r= (DIFF)/2m, where DIFF is the difference between the sum of the corner numbers on the positive diagonal and the sum of the corner numbers on the negative diagonal, and m equals the number in each of the below average and above average classifications for each variable. The formula for r is applicable to negative as well as positive correlation. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024971170"
"COLE N.S.","COLE, NANCY S. (38961260400)","38961260400","BIAS IN SELECTION","1973","Journal of Educational Measurement","10","4","","237","255","18","88","10.1111/j.1745-3984.1973.tb00802.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84909039525&doi=10.1111%2fj.1745-3984.1973.tb00802.x&partnerID=40&md5=6671ca129209361c6ceb863af9a6e5d7","Possible bias in selection procedures used for employment and college admissions is of crucial social and educational importance. However, there are many different definitions of what constitutes bias with each definition based on different values and with different implications for how selection should be accomplished. A number of these definitions of bias and their implications are examined, and a new conditional probability model of fairness based on equal opportunity for potentially successful applicants is presented. This conditional probability model is proposed as an intuitively appealing and socially desirable model for use in many selection situations in employment and college admissions. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84909039525"
"BREWER J.K.; OWEN P.W.","BREWER, JAMES K. (7201421310); OWEN, PATRICIA W. (57195042009)","7201421310; 57195042009","A NOTE ON THE POWER OF STATISTICAL TESTS IN THE JOURNAL OF EDUCATIONAL MEASUREMENT","1973","Journal of Educational Measurement","10","1","","71","73","2","13","10.1111/j.1745-3984.1973.tb00784.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-73949125104&doi=10.1111%2fj.1745-3984.1973.tb00784.x&partnerID=40&md5=34d349ab3fd778c3e11b3a6376ef3fe7","The power of statistical tests recently appearing in the JEM was determined using the power calculation guidelines proposed by Cohen (1969). All the articles containing tests of significance were surveyed. The results indicated that power was generally below .50 for small effect sizes and above .50 for medium and large effect sizes. A suggestion for reporting statistical results to include power of the tests was made. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-73949125104"
"SLOTNICK H.B.","SLOTNICK, HENRY B. (7003793285)","7003793285","TOWARD A THEORY OF COMPUTER ESSAY GRADING","1972","Journal of Educational Measurement","9","4","","253","263","10","15","10.1111/j.1745-3984.1972.tb00958.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013676963&doi=10.1111%2fj.1745-3984.1972.tb00958.x&partnerID=40&md5=8b61ade70b04119ea743b37372ac6c8d","A principal components analysis was conducted to determine whether the measures of essays made by the computer could be grouped into factors. Six factors (fluency, spelling, diction, sentence structure, punctuation, and paragraphing) were identified. Factor scores were computed for the original essays, and two sets of papers were identified for each factor: papers with high scores and papers with low scores. The selected papers had average scores for all other factors. The high and low papers were then compared to determine what attributes of interest to humans were being reflected by the factors. The attributes found were: quantity of thought, spelling, range of vocabulary and word choice, structure of sentences, emphasis through subordination, and paragraph organization. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85013676963"
"SHOEMAKER D.M.","SHOEMAKER, DAVID M. (57029927000)","57029927000","FURTHER RESULTS ON THE STANDARD ERRORS OF ESTIMATE ASSOCIATED WITH ITEM‐EXAMINEE SAMPLING PROCEDURES","1971","Journal of Educational Measurement","8","3","","215","220","5","7","10.1111/j.1745-3984.1971.tb00928.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973712373&doi=10.1111%2fj.1745-3984.1971.tb00928.x&partnerID=40&md5=ecdf2ce58d4b58c030318c097b87986d","Defining one observation as the score received by one examinee on one item, the results of this investigation suggest that, for a given test length, item‐examinee sampling procedures having the same number of observation have, for all practical purposes, the same standard error in estimating μ but different standard errors in estimating σ. Additionally, the variance of the item difficulty indices (proportion answering the item correctly) was found to be a significant factor in accounting for differences in standard errors of estimating μ between normative distributions differing primarily in degree of skewness. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973712373"
"JUDY C.J.","JUDY, CHESTER J. (6601944257)","6601944257","A PROPOSED TECHNIQUE FOR IMPROVING PREDICTION OF COLLEGE GRADES USING MORE INFORMATION FROM THE HIGH SCHOOL RECORD","1971","Journal of Educational Measurement","8","3","","183","188","5","0","10.1111/j.1745-3984.1971.tb00923.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024942945&doi=10.1111%2fj.1745-3984.1971.tb00923.x&partnerID=40&md5=998ecb0f4bdacb31053db776a1b2fa41","An attempt is made to cite some of the literature and experience which has led the author to the conclusion that there may be major payoff in a new look at the high school record as a source of information for improving the prediction of college “'success.” A brief expository description of a suggested method for handling the available information is then given. The method entails an empirical keying of selected elements of information contained on high school transcripts against a criterion of first year grade point averages in college. Increased accuracy in prediction through the use of the kind of “education index” derived should, the author believes, permit college admissions officers to identify better, potential students for whom alternative training programs should be recommended or devised. Increased accuracy should allow better decisions with respect to the appropriateness of alternative curriculums within the college or university. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024942945"
"HARRIS W.S.","HARRIS, WILBUR S. (56962615300)","56962615300","AGREEMENT AMONG NCME MEMBERS ON SELECTED ISSUES IN EDUCATIONAL MEASUREMENT","1973","Journal of Educational Measurement","10","1","","63","70","7","2","10.1111/j.1745-3984.1973.tb00783.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84912909160&doi=10.1111%2fj.1745-3984.1973.tb00783.x&partnerID=40&md5=34028b4b04d143f48b6544d12ed9da82","This study surveyed 145 NCME members to determine the extent of their agreement on 40 controversial issues in educational measurement. Two types of agreement were obtained for each issue. First, the degree of agreement with the issues as presented. Second, the degree of agreement among the group of respondents. The percent of respondents choosing each of three responses to each issue, and a mean, variance, and “consensus” score for each issue were computed. The mean scores indicated the degree to which the respondents agreed with the issues. They varied from + .91 to ‐ .71, when + 1 would indicate maximum agreement with an issue, and ‐ 1 maximum disagreement. The “consensus” scores varied from .90 to .15, and had a mean of .40 where 1 would indicate maximum agreement among the group, and 0 maximum disagreement. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84912909160"
"MITCHELL J.V., JR.","MITCHELL, JAMES V. (57213406612)","57213406612","THE INFLUENCE OF A DESIRABILITY HALO EFFECT ON RATINGS OF INSTITUTIONAL ENVIRONMENT","1973","Journal of Educational Measurement","10","3","","195","202","7","3","10.1111/j.1745-3984.1973.tb00797.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84934598994&doi=10.1111%2fj.1745-3984.1973.tb00797.x&partnerID=40&md5=6618555263a70f17a3cbee9c55783e15","A rationale is provided for hypothesizing that a counterpart of the social desirability variable influences environmental ratings based on student perceptions, and a test is made of the hypothesis. The High School Characteristics Index was administered to 2819 high school seniors from 11 high schools. Social desirability scale values for the 300 items and 30 scale scores of the HSCI were obtained from 85 students in Education, and these values were correlated with the endorsement percentages and average scale scores for the students in each of the 11 high schools. Results indicated an appreciable “desirability halo” effect for some student bodies, with wide differences among student bodies with respect to the strength and direction of that effect. The results are interpreted as a serious challenge to the validity and discriminative capability of environmental assessment techniques based on student perceptions. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84934598994"
"HOGAN T.P.","HOGAN, THOMAS P. (57203054607)","57203054607","PREDICTION OF WITHIN‐SCHOOL SYSTEM VARIANCE IN TEST SCORES FROM WITHIN‐COMMUNITY VARIANCE IN SOCIOECONOMIC STATUS","1972","Journal of Educational Measurement","9","2","","155","158","3","2","10.1111/j.1745-3984.1972.tb00773.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861754353&doi=10.1111%2fj.1745-3984.1972.tb00773.x&partnerID=40&md5=2cb92530a6b9b71708c6943d8daec70d","Prediction of school systems' scores on cognitive tests from average socioeconomic indices for communities has proved very helpful for several applications. It would also be useful to be able to predict within‐school system variance in test scores from within‐community variance in socioeconomic status. The present study examined correlations between standard deviations of test scores and an index of within‐community variability in income. These correlations were of borderline significance. It was noted that correlations among test standard deviations themselves were quite low, suggesting that within‐school system variance is a characteristic of less generality than school systems' median performance in different test areas. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84861754353"
"LEWY A.","LEWY, ARIEH (56968378400)","56968378400","DISCRIMINATION AMONG INDIVIDUALS V. DISCRIMINATION AMONG GROUPS","1973","Journal of Educational Measurement","10","1","","19","24","5","5","10.1111/j.1745-3984.1973.tb00777.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911550751&doi=10.1111%2fj.1745-3984.1973.tb00777.x&partnerID=40&md5=db5f570a0551c9aa0e06981c6aa49718","Achievement tests are used for discrimination both among individuals and among classes. Item selection procedures which are recommended for constructing tests for individual differentiation may not be adequate for tests for discrimination among classes. It is suggested that the item intraclass correlation should be used as an index for item selection in tests designed for the measurement of class performance. An example is presented which shows that using the intraclass correlation for item selection yields different results than using item‐test correlation coefficients. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84911550751"
"NIEDERMEYER F.C.; SULLIVAN H.J.","NIEDERMEYER, FRED C. (6507815708); SULLIVAN, HOWARD J. (7101994394)","6507815708; 7101994394","DIFFERENTIAL EFFECTS OF INDIVIDUAL AND GROUP TESTING STRATEGIES IN AN OBJECTIVES‐BASED INSTRUCTIONAL PROGRAM","1972","Journal of Educational Measurement","9","3","","199","204","5","3","10.1111/j.1745-3984.1972.tb00952.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84973808743&doi=10.1111%2fj.1745-3984.1972.tb00952.x&partnerID=40&md5=f234646ba8a5be6cf914fd4feaa8843e","A total of ten first‐grade teachers in an objectives‐based reading program utilized on a biweekly basis three types of criterion tests: (1) individually‐administered, constructed‐response tests; (2) group‐administered, selected‐response tests with three choices per item; and (3) group‐administered, selected‐response tests with four choices per item. Scores on these tests and scores on an end‐of‐year, constructued‐response posttest were collected on a sample of 40 Ss for each type of test. Both the individually‐administered, constructed‐response tests and the 4‐choice, selected‐response tests provided scores that accurately predicted end‐of‐year performance. The 3‐choice tests did not. The use of 3‐choice, selected‐response tests in similar type instructional programs is not recommended. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84973808743"
"WIERSMA W.","WIERSMA, WILLIAM (25957475000)","25957475000","A CROSS‐NATIONAL COMPARISON OF ACADEMIC AND AFFECTIVE CHARACTERISTICS OF PROSPECTIVE SECONDARY SCHOOL TEACHERS","1972","Journal of Educational Measurement","9","1","","57","66","9","0","10.1111/j.1745-3984.1972.tb00761.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024958722&doi=10.1111%2fj.1745-3984.1972.tb00761.x&partnerID=40&md5=2557a33785d0db1a8e41c776fd84689b","This research report deals with the measurement of nine groups of prospective secondary teachers; five from the British Isles and four from the United States. The sample of 839 final year, teacher education students was measured on academic achievement, professional education achievement, and affective measures. A multivariate analysis of variance was used to analyze differences between the groups. The analysis resulted in six statistically significant canonical variates. There was a clear country separation on only the first canonical variate, which indicated the British groups high on achievement in English composition and fine arts, and United States groups high on achievement in guidance and measurement. The canonical variates are described in the context of the real variables, as well as the separation of the groups on the canonical variates. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024958722"
"AYRER J.E.; McNAMARA T.C.","AYRER, JAMES E. (57195042854); McNAMARA, THOMAS C. (24543521100)","57195042854; 24543521100","SURVEY TESTING ON AN OUT‐OF‐LEVEL BASIS","1973","Journal of Educational Measurement","10","2","","79","83","4","9","10.1111/j.1745-3984.1973.tb00785.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84916007231&doi=10.1111%2fj.1745-3984.1973.tb00785.x&partnerID=40&md5=c869df8660f0272e62c3756b9275c586","“Out‐of‐level” testing, assigning pupils to levels of a standardized test on the basis of previous (close to chance level) test scores rather than their present grade assignment, has been used in Philadelphia since 1968. An extensive number of pupils were tested in this way in 1970, in contrast to the two previous years, and overall performance indices seemed depressed as a result. The test results of 1500 children tested out‐of‐level in 1970 were reviewed to see if their performance supported the rationale behind the practice. More reliable performance definitely resulted from the procedure for this sample, but there is considerable question about the publisher's assurance regarding comparability of in‐level and out‐of‐level scores. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84916007231"
"SONTAG M.; PEDHAZUR E.","SONTAG, MARVIN (56947247800); PEDHAZUR, ELAZAR (6507516663)","56947247800; 6507516663","DIMENSIONS OF EDUCATIONAL ATTITUDES: FACTORIAL CONGRUENCE OF TWO SCALES","1972","Journal of Educational Measurement","9","3","","189","198","9","7","10.1111/j.1745-3984.1972.tb00951.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977012711&doi=10.1111%2fj.1745-3984.1972.tb00951.x&partnerID=40&md5=7e8dc76e14088f59060589a8364db543","A second‐order factor analysis of responses to Kerlinger's ES‐VII and Oliver and Butcher's Survey of Opinions about Education was performed. Both scales were designed to measure “Attitudes toward Education”. Seven first‐order factors emerged, as follows: (1) Career Training; (2) Moral vs. Religious Training; (3) Corporal Punishment; (4) Individualized Instruction; (5) Subject Matter and Knowledge; (6) Expansion of Education; and (7) School as a Social Force. Two second‐order factors emerged. The first was a bipolar factor involving Kerlinger's concept of “Traditionalism” and Oliver and Butcher's “Tendermindedness”. The second combined Kerlinger's “Progressivism” with Oliver and Butcher's “Radicalism”. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84977012711"
"GILMAN D.A.; FERRY P.","GILMAN, DAVID ALAN (7003990758); FERRY, PAULA (57195040259)","7003990758; 57195040259","INCREASING TEST RELIABILITY THROUGH SELF‐SCORING PROCEDURES","1972","Journal of Educational Measurement","9","3","","205","207","2","20","10.1111/j.1745-3984.1972.tb00953.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84993747908&doi=10.1111%2fj.1745-3984.1972.tb00953.x&partnerID=40&md5=01a207c7ef4e83668cb90be57d7ef0f3","Fifty‐four graduate students were administered a 66 item four‐response multiple choice test on self‐scoring tests forms. Each test was scored by the traditional right‐wrong method of scoring tests and was also scored by the self‐scoring method of counting the number of responses necessary to respond to all items correctly. Results indicate that scoring tests by the self‐scoring method can result in a higher split half reliability than tests scored by the traditional right‐wrong method. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84993747908"
"O'REILLY R.P.; WlGHTMAN L.E.","O'REILLY, ROBERT P. (57195045110); WlGHTMAN, LAWRENCE E. (57195040208)","57195045110; 57195040208","IMPROVING THE IDENTIFICATION OF ANXIOUS ELEMENTARY SCHOOL CHILDREN THROUGH THE USE OF AN ADJUSTED ANXIETY SCALE","1971","Journal of Educational Measurement","8","2","","107","112","5","2","10.1111/j.1745-3984.1971.tb00913.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-23744432678&doi=10.1111%2fj.1745-3984.1971.tb00913.x&partnerID=40&md5=b8644eb44ece66d2894e4d18a5d282e9","Anxiety scores (Test Anxiety Scale for Children) from 165 sixth graders were adjusted for defensiveness (Lie Scale for Children) by an equally weighted summation of the two scores. Construct validity of the adjusted anxiety score was markedly superior to that of the uncorrected score, as indicated by an increase in correlation with achievement on a programmed instruction unit of(in one case) ‐.33 to ‐.52. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-23744432678"
"SCHUTZ R.E.","SCHUTZ, RICHARD E. (56952219800)","56952219800","THE ROLE OF MEASUREMENT IN EDUCATION: SERVANT, SOULMATE, STOOLPIGEON, STATESMAN, SCAPEGOAT, ALL OF THE ABOVE, AND/OR NONE OF THE ABOVE","1971","Journal of Educational Measurement","8","3","","141","146","5","0","10.1111/j.1745-3984.1971.tb00917.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024997695&doi=10.1111%2fj.1745-3984.1971.tb00917.x&partnerID=40&md5=8f442dd80d2ef4a0ba335a476fe2ad30","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-85024997695"
"COCKRIEL I.W.","COCKRIEL, IRVIN W. (16439503900)","16439503900","SOCIOMETRIC STATUS SCORES: A COMPARISON OF JAMRICH VALUES WITH CONVENTIONAL SCALES","1972","Journal of Educational Measurement","9","1","","71","73","2","0","10.1111/j.1745-3984.1972.tb00763.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024994693&doi=10.1111%2fj.1745-3984.1972.tb00763.x&partnerID=40&md5=d2bb1fed1f65aaa28570a1119f9e7e6c","Sociometric ranking of ten classrooms was analyzed to determine if Jamrich's procedure was significantly different from conventional indexes. Spearman Rank correlations and Kendall's coefficient of concordance were used to determine degree of correlation, Jamrich's ranked values were not found to be significantly different from conventional scales. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024994693"
"EVANS F.R.; REILLY R.R.","EVANS, FRANKLIN R. (7103220085); REILLY, RICHARD R. (7102935742)","7103220085; 7102935742","A STUDY OF SPEEDEDNESS AS A SOURCE OF TEST BIAS","1972","Journal of Educational Measurement","9","2","","123","131","8","46","10.1111/j.1745-3984.1972.tb00767.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953144740&doi=10.1111%2fj.1745-3984.1972.tb00767.x&partnerID=40&md5=b1bf4144d34ee1b411542512aee14c5b","Specially constructed “speeded” and “unspeeded” forms of a Reading Comprehension test were administered to both regular center and fee‐free center LSAT candidates in an effort to determine: (1) if the test was more speeded for fee‐free candidates, and (2) if reducing the amount of speededness was more beneficial to fee‐free candidates. Results of the analyses show: (1) the test is somewhat more speeded for fee‐free candidates than for regular candidates, (2) reducing the amount of speededness produces higher scores for both regular and fee‐free center candidates, and (3) reducing speededness is not significantly more beneficial (in terms of increasing the number of items answered correctly) to fee‐free than to regular center candidates. Lower KR‐20 reliability was observed under speeded conditions in the fee‐free sample. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84953144740"
"Tuinman J.J.; Farr R.; Blanton B.E.","Tuinman, J. Jaap (57013032800); Farr, Roger (24786322400); Blanton, B. Elgit (57167972000)","57013032800; 24786322400; 57167972000","INCREASES IN TEST SCORES AS A FUNCTION OF MATERIAL REWARDS","1972","Journal of Educational Measurement","9","3","","215","223","8","6","10.1111/j.1745-3984.1972.tb00955.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85005405095&doi=10.1111%2fj.1745-3984.1972.tb00955.x&partnerID=40&md5=df80e1ec42504f9207e850bd12e8e45a","In this study 81 experimental and 79 control subjects (randomly assigned to treatments) took Form A of the Nelson Reading Test, twice, with a four week interval between test administrations. Instructions for the retest varied for the E and C groups. The latter group was told that the test was readministered for purposes of assessing improvement. The E subjects were informed that by improving their previous score they would be eligible for winning a prize (candy bars, university sweaters, radios). Analysis of covariance indicated that the effect of the awards was significant (p < .01) in terms of number of items attempted and in terms of items correct. The adjusted mean increase for the E subjects was three months. The authors concluded that, if the terms of an actual performance contract would be applied to their results, they were to realize approximately $3,000 profit on a $75 investment. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85005405095"
"PREDIGER D.J.","PREDIGER, DALE J. (6602111339)","6602111339","CONVERTING TEST DATA TO COUNSELING INFORMATION: SYSTEM TRIAL‐WITH FEEDBACK","1971","Journal of Educational Measurement","8","3","","161","169","8","1","10.1111/j.1745-3984.1971.tb00920.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990419942&doi=10.1111%2fj.1745-3984.1971.tb00920.x&partnerID=40&md5=d394e050626540be613f7d84051f2ff8","A computer‐based system for converting test data into locally‐validated counseling information was developed and field tested with potential vocational school students. Two data‐information conversion procedures were used: similarity (centour) scores based on discriminant analyses and success estimates based on experience tables. Longitudinal validation analyses involving over 1500 students and 20 interest and aptitude measures provided the empirical base for the data‐information conversion procedures. Similarity scores and success estimates were developed for each of the 12 vocational program areas in which the students enrolled. These reporting procedures were field tested with 1000 students enrolled in 12 high schools, Illustrations of the similarity score reporting procedures are provided along with summaries of student reactions to these procedures. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84990419942"
"STAFFORD R.E.","STAFFORD, RICHARD E. (7102379641)","7102379641","THE SPEEDEDNESS QUOTIENT: A NEW DESCRIPTIVE STATISTIC FOR TESTS","1971","Journal of Educational Measurement","8","4","","275","277","2","18","10.1111/j.1745-3984.1971.tb00937.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013501989&doi=10.1111%2fj.1745-3984.1971.tb00937.x&partnerID=40&md5=299a1a53380c70833dbb840a73aa6399","It is proposed to describe the speededness of a test by a new statistic, the Speededness Quotient (SQ). The SQ is derived by dividing the total number of unattempted items by the total number of errors. It is suggested that test publishers should report the SQ of a test especially when reporting the reliability as an odd‐even correlation coefficient. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85013501989"
"BAKER E.L.","BAKER, EVA L. (7401660666)","7401660666","THE EFFECTS OF MANIPULATED ITEM WRITING CONSTRAINTS ON THE HOMOGENEITY OF TEST ITEMS","1971","Journal of Educational Measurement","8","4","","305","309","4","2","10.1111/j.1745-3984.1971.tb00943.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84954675651&doi=10.1111%2fj.1745-3984.1971.tb00943.x&partnerID=40&md5=9ee0c566c6e23484c5d532de68c271d5","Described are the effects of four sets of instructions on the observed item inter‐ correlations of current events and subtraction items. The four conditions were: (a) general objective, (b) behavioral objective, (c) behavioral objective plus test item, and (d) behavioral objective plus item‐form. Two tests, one in each subject matter, constructed by selecting four items generated from each of the experimental conditions, were administered to 51 seventh grade children. Not found were the expected tendencies toward greater homogeneity among items produced under the three conditions employing behavioral objectives. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84954675651"
"ANGOFF W.H.; FORD S.F.","ANGOFF, WILLIAM H. (16648034100); FORD, SUSAN F. (7201423034)","16648034100; 7201423034","ITEM‐RACE INTERACTION ON A TEST OF SCHOLASTIC APTITUDE","1973","Journal of Educational Measurement","10","2","","95","105","10","119","10.1111/j.1745-3984.1973.tb00787.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948884958&doi=10.1111%2fj.1745-3984.1973.tb00787.x&partnerID=40&md5=cb746c5ec66c5a00407f3319d1198ade","Several samples of black and white students were drawn from the 1970 PSAT administration in Georgia and studied for item x race interaction on both the verbal and mathematical sections of the test. When subsamples of candidates were drawn from their respective racial groups, matched on mathematical for the study of verbal items and matched on verbal for the study of mathematical items, there was an observable decrease in the size of the item x race interaction, suggesting that one factor contributing to that interaction was simply the difference in performance levels on the test shown by the two races. Further analyses demonstrated a moderate item x group interaction for blacks native to different cities and a moderate item x group interaction for blacks native to areas of different population density. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84948884958"
"PACK E.C.","PACK, ELBERT C. (57195041144)","57195041144","THE EFFECTS OF TESTING UPON ATTITUDE TOWARDS THE METHOD AND CONTENT OF INSTRUCTION","1972","Journal of Educational Measurement","9","2","","141","144","3","1","10.1111/j.1745-3984.1972.tb00770.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84911557824&doi=10.1111%2fj.1745-3984.1972.tb00770.x&partnerID=40&md5=e722ca738c510d1afa0e6fd1d9a79a81","Senior high school mathematics students were taught computer arithmetic via self‐instructional materials. Following instruction they were randomly assigned to one of two groups. One group was tested with a norm‐referenced measure made up of items having moderate difficulty and high correlations with each other; the other group was tested with a criterion‐referenced measure designed to assess attainment of specific behavioral objectives. Student attitude toward the content of instruction and toward the mode of instruction was assessed immediately following. Significantly more positive attitude toward the subject matter of instruction was associated with the use of the criterion‐referenced measure. Differences in attitude toward mode of instruction were not significant. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84911557824"
"SCHUSTER D.H.","SCHUSTER, D.H. (7102831114)","7102831114","AN ANALYSIS OF FLUNKED‐OUT AND READMITTED STUDENTS","1971","Journal of Educational Measurement","8","3","","171","175","4","2","10.1111/j.1745-3984.1971.tb00921.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970190600&doi=10.1111%2fj.1745-3984.1971.tb00921.x&partnerID=40&md5=712da2faf8e052398802cfa4643b82c3","This study utilized multiple regression analysis to develop equations to predict a committee's decision on whether to readmit flunked‐out college students and to develop a second equation to predict grade point average the first quarter after readmitting such students. Data for similar students for a second academic year provided a hold‐out group to cross‐validate the regression equations. The committee's decision to readmit students could be predicted fairly well (cross‐validity = .61) from the variables of setting realistic goals, math test score, number of quality points short of a passing average, and a self‐analysis of failure. The attempt to predict the grade point average the first quarter after readmission was much less successful (cross‐validity = .32). A different set of student factors seemed to be influential in accounting for a committee's decision to readmit a student and for the student's subsequent grade performance if admitted Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970190600"
"ECHTERNACHT G.J.; BOLDT R.F.; SELLMAN W.S.","ECHTERNACHT, G.J. (6506072437); BOLDT, R.F. (57189161790); SELLMAN, W.S. (57030439100)","6506072437; 57189161790; 57030439100","PERSONALITY INFLUENCES ON CONFIDENCE TEST SCORES","1972","Journal of Educational Measurement","9","3","","235","241","6","8","10.1111/j.1745-3984.1972.tb00957.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977031908&doi=10.1111%2fj.1745-3984.1972.tb00957.x&partnerID=40&md5=ae063bbbf49642b924d9fc649563ebca","From the earliest years in the development of confidence testing, several authors have expressed the concern that confidence test scores were influenced, to a measurable degree, by personality variables. Advocates of confidence testing have claimed that the effects of personality variables can be reduced with practice. This study attempts to evaluate the association of personality variables with confidence test scores in light of practice. It was concluded that although significant correlations between personality variables and confidence testing scores could be obtained, these correlations did not hold up with replication. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84977031908"
"GOLDMAN R.D.; WARREN R.","GOLDMAN, ROY D. (7402001118); WARREN, REBECCA (57195040437)","7402001118; 57195040437","DISCRIMINANT ANALYSIS OF STUDY STRATEGIES CONNECTED WITH COLLEGE GRADE SUCCESS IN DIFFERENT MAJOR FIELDS","1973","Journal of Educational Measurement","10","1","","39","47","8","25","10.1111/j.1745-3984.1973.tb00780.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970339984&doi=10.1111%2fj.1745-3984.1973.tb00780.x&partnerID=40&md5=284be1d3b693fa1af48d10a7d4ba949d","A study techniques questionnaire was administered to 538 students enrolled in upper division college classes. Multivariate analysis of variance was employed to compare the centroids of questionnaire responses of students in four major fields who had above and below average grades. There were significant differences in group centroids for the comparison between major fields and between grade levels. There was no significant interaction. The major differences between students with above and below average grades appeared to be reflected in “clerical diligence” and cognitive “activity.” Successful students were not only more diligent in their study habits, but also more likely to transform actively scholastic information. For the comparison of major field groups, two discriminant functions were significant. One function seemed to reflect mathematical‐logical thinking while the other reflected “applied‐subjective” thinking. The major field groups formed a science‐nonscience continuum on the first function but not on the second. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970339984"
"SHOEMAKER D.M.","SHOEMAKER, DAVID M. (57029927000)","57029927000","A NOTE ON ALLOCATING ITEMS TO SUBTESTS IN MULTIPLE MATRIX SAMPLING AND APPROXIMATING STANDARD ERRORS OF ESTIMATE WITH THE JACKKNIFE","1973","Journal of Educational Measurement","10","3","","211","219","8","3","10.1111/j.1745-3984.1973.tb00799.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965897721&doi=10.1111%2fj.1745-3984.1973.tb00799.x&partnerID=40&md5=bc57adee3d16727d06d5302df10009ac","Investigated empirically through post mortem item‐examinee sampling were the relative merits of two alternative procedures for allocating items to subtests in multiple matrix sampling and the feasibility of using the jackknife in approximating standard errors of estimate. The results indicate clearly that a partially balanced incomplete block design is preferable to random sampling in allocating items to subtests. The jackknife was found to better approximate standard errors of estimate in the latter item allocation procedure than in the former. Copyright © 1973, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965897721"
"EMRICK J.A.","EMRICK, JOHN A. (57195044821)","57195044821","AN EVALUATION MODEL FOR MASTERY TESTING","1971","Journal of Educational Measurement","8","4","","321","326","5","33","10.1111/j.1745-3984.1971.tb00946.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987177937&doi=10.1111%2fj.1745-3984.1971.tb00946.x&partnerID=40&md5=7ec00bc4ecb0365b2e4ef960d2a305d0","Noting the desirability of the current shift toward mastery testing and criterion‐referenced test procedures, an evaluation model is presented which should be useful and practical for such purposes. This model is based on the assumptions that the learning of fundamental skills can be considered all or none, that each item response on a single skill test represents an unbiased sample of the examinee's true mastery status, that measurement error occurring on the test (as estimated from the average interitem correlation) can be of only one type (α or β) for each examinee, and that through practical and theoretical considerations of evaluation error costs and item error characteristics, an optimal mastery criterion can be calculated. Each of these assumptions is discussed and the resultant mastery criteria algorithm is described along with an example from the IPI math program. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987177937"
"CHASE C.I.; PUGH R.C.","CHASE, CLINTON I. (7102500238); PUGH, RICHARD C. (24427968300)","7102500238; 24427968300","SOCIAL CLASS AND PERFORMANCE ON AN INTELLIGENCE TEST","1971","Journal of Educational Measurement","8","3","","197","202","5","0","10.1111/j.1745-3984.1971.tb00925.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024944396&doi=10.1111%2fj.1745-3984.1971.tb00925.x&partnerID=40&md5=6841b673d02ef242635739af2645ec91","Noting the wide differences in verbal abilities of middle and lower class children, the investigators proposed that two groups of children, one from the lower class, one from the middle class, who achieve comparable total scores on a group intelligence test, would get their scores by successfully completing different sets of items. In the first study children were placed in social classes based on their fathers’ occupations, following guidelines from the Warner scale. Middle class children were matched with lower class children on total Otis scores. No item‐social class interaction was found. The study was repeated using the occupational categories of the Dictionary of Occupational Titles as a guide to social class standing. Again no item‐social class interaction appeared. If two social class groups are equated on total intelligence scores, one social class sample appears to succeed on essentially the same test items as does the other social class sample. A given score on an intelligence test appears to represent the same skills for one social class as it does for another social class. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024944396"
"PRICE J.‐A.","PRICE, JO‐ANN (57195040471)","57195040471","AN INSTRUMENT FOR MEASURING STUDENT TEACHER MORALE","1971","Journal of Educational Measurement","8","1","","47","48","1","0","10.1111/j.1745-3984.1971.tb00906.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024996587&doi=10.1111%2fj.1745-3984.1971.tb00906.x&partnerID=40&md5=59aa6e4ed5ae2e0140c6aaab95c6ff66","Described in the article is an instrument designed to measure 12 dimensions of student teacher morale. The factors are based on 57 items taken from the Purdue Teacher Opinionaireand 43 items written specifically for the experimental instrument. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024996587"
"HARRIS C.W.","HARRIS, CHESTER W. (16535830400)","16535830400","AN INTERPRETATION OF LIVINGSTON'S RELIABILITY COEFFICIENT FOR CRITERION‐REFERENCED TESTS","1972","Journal of Educational Measurement","9","1","","27","29","2","9","10.1111/j.1745-3984.1972.tb00757.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024988050&doi=10.1111%2fj.1745-3984.1972.tb00757.x&partnerID=40&md5=a5a2094cd42b10ed474e55b877823fbe","An alternative interpretation of Livingston's reliability coefficient is based on the notion of the relation of the size of the reliability coefficient to the range of talent. It is shown that the (generally) larger Livingston coefficient does not imply a smaller standard error of measurement and consequently does not imply a more dependable determination of whether or not a true score falls below (or exceeds) a given criterion value. Copyright © 1972, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024988050"
"BAKAN R.","BAKAN, RITA (56947414800)","56947414800","ACADEMIC PERFORMANCE AND SELF‐CONCEPT AS A FUNCTION OF ACHIEVEMENT‐VARIABILITY","1971","Journal of Educational Measurement","8","4","","317","319","2","5","10.1111/j.1745-3984.1971.tb00945.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84953092650&doi=10.1111%2fj.1745-3984.1971.tb00945.x&partnerID=40&md5=1715f21aa9bb2cec66a9139191426ec9","The relationship of achievement‐variability (standard deviation of grades) to changes over time in academic achievement and self‐concept of academic ability was investigated. Compared were 112 students having near average grade point averages (GPAs) but very high or very low achievement variability (AV) indices. The high AV group showed a significantly greater drop (17 less than .05) in both GPA and self‐concept of academic ability over the 5‐year period. There were no significant differences between the groups in intelligence scores or socio‐economic status ratings. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84953092650"
"SLAKTER M.J.; KOEHLER R.A.; HAMPTON S.H.","SLAKTER, MALCOLM J. (6603541799); KOEHLER, ROGER A. (57029863300); HAMPTON, SANDRA H. (57029969800)","6603541799; 57029863300; 57029969800","LEARNING TEST‐WISENESS BY PROGRAMMED TEXTS","1970","Journal of Educational Measurement","7","4","","247","254","7","14","10.1111/j.1745-3984.1970.tb00725.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84970295235&doi=10.1111%2fj.1745-3984.1970.tb00725.x&partnerID=40&md5=4e195cd849b59db6b1151feeaef60b4e","High school seniors (84 males, 77 females) were randomly assigned to one of two treatment groups. One group received a programmed text designed to teach Ss to answer every item on an examination, whether or not the directions included a penalty for incorrect answers. The other group was administered a programmed text to teach certain selected aspects of test‐wiseness. Each group served as the control group for the other. The following day all Ss were administered a measure of willingness to guess and a measure of test‐wiseness. Two weeks later, all Ss received additional measures of willingness to guess and test‐wiseness. Analysis of the data indicated the group that received the guessing program answered significantly more items than its control group (on both the immediate and delayed tests), even though there was a penalty for incorrect answers. In similar fashion, the group exposed to the test‐wiseness program achieved significantly higher mean test‐wiseness scores than its control group. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84970295235"
"HILTON T.L.; PATRICK C.","HILTON, THOMAS L. (25952469500); PATRICK, CATHLEEN (57189649528)","25952469500; 57189649528","CROSS‐SECTIONAL VERSUS LONGITUDINAL DATA: AN EMPIRICAL COMPARISON OF MEAN DIFFERENCES IN ACADEMIC GROWTH","1970","Journal of Educational Measurement","7","1","","15","24","9","20","10.1111/j.1745-3984.1970.tb00689.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987335959&doi=10.1111%2fj.1745-3984.1970.tb00689.x&partnerID=40&md5=e1d4f4fb09070efc6f041c82f79b4d01","Three sources of data for studies of growth (matched longitudinal, unmatched longitudinal, and cross‐sectional) were compared using mean achievement test scores collected from 32,000 students tested repeatedly from 1961 to 1967. The principal results were that matched longitudinal data yielded significantly higher means than unmatched longitudinal data, and that a school's dropout rate was highly related to the discrepancy between cross‐sectional and matched longitudinal data (r= .85). Seven sources of differences among the three types of data were considered: age differences, cohort differences, time changes, equating errors, retest effects, cohort change effects, and selection effects. Methodological guidelines for future research in studies of growth and change are presented. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987335959"
"COX R.C.; STERRETT B.G.","COX, RICHARD C. (57188898018); STERRETT, BARBARA G. (57191122653)","57188898018; 57191122653","A MODEL FOR INCREASING THE MEANING OF STANDARDIZED TEST SCORES","1970","Journal of Educational Measurement","7","4","","227","228","1","2","10.1111/j.1745-3984.1970.tb00721.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987332228&doi=10.1111%2fj.1745-3984.1970.tb00721.x&partnerID=40&md5=357dae8f73ae857c841f6cb544e806c4","The model which is proposed to increase the meaningfulness of standardized test scores includes the following steps: (a) a precise description of curriculum objectives and a specification of pupil achievement in reference to these objectives; (b) the coding of each item on a standardized test with reference to the curriculum, and (c) the assignment of two scores to each pupil, one reflecting his achievement on items that test content to which he has been exposed; the other his achievement on items that test content beyond his present status in the curriculum or not represented in the curriculum at all. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987332228"
"KNAPP T.R.","KNAPP, THOMAS R. (24366321400)","24366321400","A NOTE CONCERNING CARVER'S “A MODEL FOR USING THE FINAL EXAMINATION AS A MEASURE OF THE AMOUNT LEARNED IN CLASSROOM LEARNING”","1970","Journal of Educational Measurement","7","1","","51","51","0","1","10.1111/j.1745-3984.1970.tb00695.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987306755&doi=10.1111%2fj.1745-3984.1970.tb00695.x&partnerID=40&md5=16614d48181636415b11fb51da201c74","[No abstract available]","","","Article","Final","","Scopus","2-s2.0-84987306755"
"MANN L.; TAYLOR R.G., JR.; PROGER B.B.; DUNGAN R.H.; TIDEY W.J.","MANN, LESTER (36723537500); TAYLOR, RAYMOND G. (55479086300); PROGER, BARTON B. (7801351689); DUNGAN, ROY H. (57191123837); TIDEY, WILLIAM J. (57191126127)","36723537500; 55479086300; 7801351689; 57191123837; 57191126127","THE EFFECT OF SERIAL RETESTING ON THE RELATIVE PERFORMANCE OF HIGH‐ AND LOW‐TEST ANXIOUS SEVENTH GRADE STUDENTS","1970","Journal of Educational Measurement","7","2","","97","104","7","3","10.1111/j.1745-3984.1970.tb00702.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987263300&doi=10.1111%2fj.1745-3984.1970.tb00702.x&partnerID=40&md5=8a641769a0a0654ddc16d79d767a5559","Serial retesting was investigated as a means of improving the test performance of high‐anxious students relative to that of their low‐anxious peers. The Test Anxiety Scale for Children was given to about 300 seventh grade students in a suburban school; the middle 50% were eliminated to maximize experimental variance. Six groups were established for high and low anxiety levels and for three ability levels. The Academic Promise Tests (except for the Abstract Reasoning Test) were then given four times at 1‐week intervals in the fall of the school year. All groups continued to improve significantly in a monotonic, linear fashion, with the greatest improvement occurring on the Numerical Test. Contrary to expectation, there were no significant interactions among previous achievement levels, predispositional test anxiety levels, and test trials. The greatest change on the Numerical Test occurred between the first test trial and the second test trial. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987263300"
"SCOTT N.C., JR.","SCOTT, NORVAL C. (57213225880)","57213225880","ZIP TEST: A QUICK LOCATOR TEST FOR MIGRANT CHILDREN","1970","Journal of Educational Measurement","7","1","","49","50","1","0","10.1111/j.1745-3984.1970.tb00694.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987305223&doi=10.1111%2fj.1745-3984.1970.tb00694.x&partnerID=40&md5=8dd2f44e2370de3a3b76d4e71268722d","A short test to measure proficiency in English, reading and mathematics of migrant children of elementary school age is described. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987305223"
"LOHNES P.R.; GRIBBONS W.D.","LOHNES, PAUL R. (25952686600); GRIBBONS, WARREN D. (25952498900)","25952686600; 25952498900","THE MARKOV CHAIN AS NULL HYPOTHESIS IN A DEVELOPMENT SURVEY","1970","Journal of Educational Measurement","7","1","","25","32","7","3","10.1111/j.1745-3984.1970.tb00690.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84948877514&doi=10.1111%2fj.1745-3984.1970.tb00690.x&partnerID=40&md5=c65421bb84e118b54b9abc64ec7ead0e","Development criteria observed as time series on nominal variables pose a problem for research design. Markov chains are attractive in the first instance because they can handle such multivariate multinomial data sets, with results that are described and demonstrated on Career Development Study data. The power of the formal probability model is purchased at the expense of assumptions that may be unrealistic. It is argued and demonstrated that where the Markov chain theory for the data breaks down is precisely where the most interesting part of the message contained in the data resides. The Markov chain is shown to be a better null hypothesis against which to array the psychometric or other prediction model than is the usually employed random walk. A new prediction system that combines information from the Markov chain with the psychometric predictors is described and operated. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84948877514"
"CLARK P.M.; MIRELS H.L.","CLARK, PHILIP M. (57010670000); MIRELS, HERBERT L. (7004279909)","57010670000; 7004279909","FLUENCY AS A PERVASIVE ELEMENT IN THE MEASUREMENT OF CREATIVITY","1970","Journal of Educational Measurement","7","2","","83","86","3","71","10.1111/j.1745-3984.1970.tb00699.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987349229&doi=10.1111%2fj.1745-3984.1970.tb00699.x&partnerID=40&md5=4409a37845e15c0cf2b207ecb6e1d092","It was suggested that fluency, defined as number of responses, may misleadingly influence both high Intercorrelations sometimes reported among measures of creativity and low correlations sometimes reported between measures of creativity and intelligence. Subjects were 93 Saturday art school students between the ages of 9 and 15 years. Intercorrelations among five “creativity” scores derived from a slightly modified version of Torrance's Figure Completion Test and between these scores and Henmon‐Nelson Intelligence were compared using both raw creativity scores and creativity scores corrected for the effect of fluency. Uncorrected creativity scores intercorrelated high among themselves (mean r= .45) and low with intelligence (mean r= .09), while corrected creativity scores showed low intercorrelations among themselves (mean r= .08) and with intelligence (mean r= .13). These findings are interpreted as confirming the influence of fluency upon high intercorrelations among so‐called measures of creativity and as failing to support the suggestion that fluency may also influence low correlations among creativity and intelligence measures. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987349229"
"PFEIFER C.M., JR.; SEDLACEK W.E.","PFEIFER, C. MICHAEL (57532767000); SEDLACEK, WILLIAM E. (7004179297)","57532767000; 7004179297","THE VALIDITY OF ACADEMIC PREDICTORS FOR BLACK AND WHITE STUDENTS AT A PREDOMINANTLY WHITE UNIVERSITY","1971","Journal of Educational Measurement","8","4","","253","261","8","24","10.1111/j.1745-3984.1971.tb00934.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0010190112&doi=10.1111%2fj.1745-3984.1971.tb00934.x&partnerID=40&md5=ef58e0e174a3a8f0a871734ac293479f","High school grades and both the verbal and mathematical scales of the Scholastic Aptitude Test (SAT‐V and SAT‐M, respectively) were examined as predictors of college grade point average in groups divided by race and sex. Results indicated that high school grades were not correlated as highly with college grades for black males as for the other three groups, although there were no significant differences in the correlation of either SAT‐V or SAT‐M with college grades. Moreover, the multiple regression equation for the black male group differed from the equations for the other groups in that SAT‐V is the predictor of primary importance rather than high school grades. Weights derived on a random sample of the student body caused substantial shrinkage of the multiple R only in the black male sample. Both black males and black females were significantly overpredicted by such weights. The importance of separate prediction equations for race‐sex groupings was emphasized. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0010190112"
"CARVER R.P.","CARVER, RONALD P. (7005570366)","7005570366","ANALYSIS OF “CHUNKED” TEST ITEMS AS MEASURES OF READING AND LISTENING COMPREHENSION","1970","Journal of Educational Measurement","7","3","","141","150","9","11","10.1111/j.1745-3984.1970.tb00708.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987278636&doi=10.1111%2fj.1745-3984.1970.tb00708.x&partnerID=40&md5=47c84f8441c4d944fc2730d7941cc699","A new type of test item was developed which required Ss to recognize groups of words, i.e., chunks, whose meaning had been changed from that in the original reading or listening passage. In one study involving 52 Ss and 20 test variables, individual differences on the chunked reading test were found to correlate .68 with a multiple‐choice alternate form. In another study, the decrease in listening comprehension due to increased speech rate as measured by the chunked items was roughly parallel to the decrease as measured by the multiple‐choice questions. These data were interpreted as providing evidence for the validity of the chunked items as measures of comprehension. However, other results suggested that the chunked items may be less dependent upon grammatical and vocabulary knowledge and more sensitive to within individual changes in comprehension as compared to the traditional multiple‐choice question. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987278636"
"MEURIS G.","MEURIS, GEORGES (57190479273)","57190479273","THE STRUCTURE OF PRIMARY MENTAL ABILITIES OF BELGIAN SECONDARY SCHOOL STUDENTS","1970","Journal of Educational Measurement","7","3","","191","197","6","0","10.1111/j.1745-3984.1970.tb00716.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987263060&doi=10.1111%2fj.1745-3984.1970.tb00716.x&partnerID=40&md5=0c4cd73aeb2a6abbb4894580735451c8","A factor analysis was conducted of a test battery designed for use with Belgian secondary school students and based on Thurstone's earlier work on the primary mental abilities. The analysis provided construct validity evidence for the existence of verbal, numerical, spatial, and reasoning abilities in the Belgian sample and thus confirmed the theoretical conceptions guiding the development of the test battery. An examination of the factorial organization of these mental abilities for different age groups revealed a progressive differentiation of abilities with age. There was also evidence that intensive academic specialization improves performance in the abilities required by these specializations. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987263060"
"HALINSKI R.S.; FELDT L.S.","HALINSKI, RONALD S. (6506528423); FELDT, LEONARD S. (7003911114)","6506528423; 7003911114","THE SELECTION OF VARIABLES IN MULTIPLE REGRESSION ANALYSIS","1970","Journal of Educational Measurement","7","3","","151","157","6","70","10.1111/j.1745-3984.1970.tb00709.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987340430&doi=10.1111%2fj.1745-3984.1970.tb00709.x&partnerID=40&md5=8d4eb98efc82ed78ff4fcc20529d7f03","4 different procedures are commonly employed with sample data to reduce a set of predictor variables. In the present study these procedures were repeatedly applied to computer‐simulated samples to provide comparative data pertaining to two questions: (a) Which procedure can be expected to produce an equation that yields the most accurate predictions for the population? (b) Which procedure is most likely to identify the optimal set of independent variables? The samples were drawn from 12, mathematically defined, multivariate normal populations. Each population consisted of 1 criterion and 10 predictor variables. Five or fewer independent variables constituted the optimal set in each case. With respect to both questions small differences among the procedures were observed. However, the forward selection and stepwise procedures consistently produced more favorable results than the 2 backward elimination procedures. The question of the number of sampling units to use is discussed. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987340430"
"DARLINGTON R.B.","DARLINGTON, RICHARD B. (59025395800)","59025395800","SOME TECHNIQUES FOR MAXIMIZING A TEST'S VALIDITY WHEN THE CRITERION VARIABLE IS UNOBSERVED","1970","Journal of Educational Measurement","7","1","","1","14","13","6","10.1111/j.1745-3984.1970.tb00688.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987305242&doi=10.1111%2fj.1745-3984.1970.tb00688.x&partnerID=40&md5=8fce09473d50474e8074d71c25ce25df","A set of techniques is presented for constructing a test or test battery which can be inferred to correlate as highly as possible with a hypothetical construct which is named but not measured directly. Use of the techniques requires the test constructor to describe first the nature of the construct indirectly, by estimating the relative sizes of the construct's correlations with several observable variables which the test constructor has selected. Techniques are also described for estimating the validity of a test constructed by these methods. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987305242"
"SIROTNIK K.","SIROTNIK, KEN (56360886700)","56360886700","AN INVESTIGATION OF THE CONTEXT EFFECT IN MATRIX SAMPLING","1970","Journal of Educational Measurement","7","3","","199","207","8","16","10.1111/j.1745-3984.1970.tb00717.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987341346&doi=10.1111%2fj.1745-3984.1970.tb00717.x&partnerID=40&md5=b2fd354f80facb6eca77137ecf429bea","Practical use of the matrix sampling (i.e. item sampling) technique requires the assumption that an examinee's response to an item is independent of the context in which the item occurs. This assumption was tested experimentally by comparing the responses of examinees to a population of items with the responses of examinees to item samples. Matrix sampling mean and variance estimates for verbal, quantitative, and attitude tests were used as dependent variables to test for differences between the “context” and “out‐of‐context” groups. The estimates obtained from both treatment groups were also compared with actual population values. No significant differences were found between treatments on matrix sample parameter estimates for any of the three types of tests. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987341346"
"JENSEN J.A.; SCHMITT J.A.","JENSEN, JOHN A. (57195042360); SCHMITT, JOHN A. (16527171500)","57195042360; 16527171500","THE INFLUENCE OF TEST TITLE ON TEST RESPONSE","1970","Journal of Educational Measurement","7","4","","241","245","4","0","10.1111/j.1745-3984.1970.tb00724.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024971972&doi=10.1111%2fj.1745-3984.1970.tb00724.x&partnerID=40&md5=cb0002d1da859a9782521f8d3c88f0d9","This study was designed to determine the extent to which responses to test items of the type frequently found in personality inventories would be influenced by the title associated with the test. The basic hypothesis was that subjects respond to the test title by developing a particular response set which will be reflected in the individual responses. An instrument was constructed and administered to eight treatment groups. Each administration differed primarily in the title each group's tests bore. The dependent variables were measures of the tendency to lie, respond defensively, answer carefully, and complete questions. Subjects tended to lie and respond more defensively to titled tests than to a test having no title and administered under nonthreatening conditions. All other comparisons were not statistically significant. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024971972"
"GOLDSTEIN L.S.; COLLER A.R.; DILL J.; TILIS H.S.","GOLDSTEIN, LEO S. (24782356800); COLLER, ALAN R. (57191127407); DILL, JOHN (57191128424); TILIS, HOWARD S. (57191124751)","24782356800; 57191127407; 57191128424; 57191124751","THE EFFECT OF A SPECIAL CURRICULUM FOR DISADVANTAGED CHILDREN ON TEST‐RETEST RELIABILITIES OF THREE STANDARDIZED INSTRUMENTS","1970","Journal of Educational Measurement","7","3","","171","174","3","5","10.1111/j.1745-3984.1970.tb00713.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987313865&doi=10.1111%2fj.1745-3984.1970.tb00713.x&partnerID=40&md5=7f0ccf6ef2f31624aff42c3d52d926d9","Test‐retest (stability) reliability coefficients are, by their nature, affected by what has happened to the tested subjects during the period between testings. Similarly, changes in subjects' mean performance will reflect what happened to them in the interim period. In this regard, the relative values of stability coefficients for experimental and control groups are indicative of the relative degree to which an experimental program is able to change the rankings of the students on criteria measures at pre‐ and posttreatment times. Changes in students' rankings however do not necessarily affect the level of the group's average performance. This study examines the stability reliabilities of three standardized testing instruments used in the evaluation of a special (enriched) curriculum for young disadvantaged children and the changes in their average performance over a 2‐year period. Magnitudes in test‐retest reliability differences between treatment groups seem to parallel differences in mean scores. Using the stability reliability coefficients as indices, the program discussed in this report seemed to be most effective in producing change in the skills measured by the Peabody Picture Vocabulary Test. However, significant differences in mean performance between the treatment groups indicates the effectiveness of the program not only in the skills measured by the PPVT but also in those areas measured by the Stanford Binet and the Columbia Mental Maturity Test. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987313865"
"QUERESHI M.Y.; MILLER J.M.","QUERESHI, M.Y. (6603692585); MILLER, JEFFREY M. (57191125696)","6603692585; 57191125696","THE COMPARABILITY OF THE WAIS, WISC, AND WBII","1970","Journal of Educational Measurement","7","2","","105","111","6","8","10.1111/j.1745-3984.1970.tb00703.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987260718&doi=10.1111%2fj.1745-3984.1970.tb00703.x&partnerID=40&md5=235ca8dc467ddb02c40da9e55149e140","Three Wechsler scales (the Wechsler Adult Intelligence Scale, Wechsler Intelligence Scale for Children, and Wechsler‐Bellevue II) were administered in a counterbalanced design to 72 randomly selected 17 year‐old high school Ss in order to investigate their comparability by testing the equality of (a) means, (b) variances, (c) reliability coefficients, and (d) validity coefficients based on scaled scores and IQs. Results indicated that the subtest scores and IQs for the given three scales were not equivalent. The present findings conform with most of the previous results regarding the comparability of Wechsler scales. Although the three scales investigated all evidence high similarity of item content and format, they clearly fail to meet the statistical criteria of equivalence for 17 year‐old subjects. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987260718"
"OWENS R.E.; HANNA G.S.; COPPEDGE F.L.","OWENS, RICHARD E. (57191124176); HANNA, GERALD S. (24325536600); COPPEDGE, FLOYD L. (56947517700)","57191124176; 24325536600; 56947517700","COMPARISON OF MULTIPLE‐CHOICE TESTS USING DIFFERENT TYPES OF DISTRACTOR SELECTION TECHNIQUES","1970","Journal of Educational Measurement","7","2","","87","90","3","6","10.1111/j.1745-3984.1970.tb00700.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945202449&doi=10.1111%2fj.1745-3984.1970.tb00700.x&partnerID=40&md5=9fdb9a940d496693f53e84101a90d835","3 multiple‐choice tests were developed from judgmental, frequency, and discrimination procedures of selecting item distractors. Scores on each of these tests were correlated with scores on a completion test of parallel numeric and algebraic content. Matched triads, with 558 students in each group, were used. No significant differences in validity were found among the tests. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84945202449"
"BOWERS J.","BOWERS, JOHN (56951937400)","56951937400","THE COMPARISON OF GPA REGRESSION EQUATIONS FOR REGULARLY ADMITTED AND DISADVANTAGED FRESHMEN AT THE UNIVERSITY OF ILLINOIS","1970","Journal of Educational Measurement","7","4","","219","225","6","13","10.1111/j.1745-3984.1970.tb00720.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987349491&doi=10.1111%2fj.1745-3984.1970.tb00720.x&partnerID=40&md5=71d87c66216b7a5342f52c95536a325d","The regression equations of first semester grade point average (GPA) on high school percentile rank (HSPR) and verbal and quantitative score on the Cooperative School and College Ability Tests (SCAT) were significantly different for men and women regularly admitted freshmen and men and women freshmen admitted to the Special Educational Opportunities Program (SEOP) at the University of Illinois. HSPR and SCAT verbal scores were useful predictors of GPA for all groups. However, separate regression equations for the prediction of GPA were indicated, since there were significant differences in the regression coefficients of all of the independent variables among the four groups. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987349491"
"RIPPEY R.M.","RIPPEY, ROBERT M. (6603819473)","6603819473","A COMPARISON OF FIVE DIFFERENT SCORING FUNCTIONS FOR CONFIDENCE TESTS","1970","Journal of Educational Measurement","7","3","","165","170","5","24","10.1111/j.1745-3984.1970.tb00712.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987310050&doi=10.1111%2fj.1745-3984.1970.tb00712.x&partnerID=40&md5=e7417625cd95742de597031533ec9383","Several parts of the STEP Writing Test, Level 1, were administered to 14 different groups of from 19 to 52 high school students. In the testing situations, scores were computed using the following scoring functions: (a) probability assigned to the correct answer, (b) the logarithmic function, (c) the spherical function, (d) the Euclidean function, and (e) inferred choice. Reliabilities of the scores obtained by means of each scoring function were computed. Comparisons between the reliabilities showed that the simplest and most intuitive function, the probability assigned to the correct answer, produced the highest reliability in comparison with any of the other functions. The data suggest that in the absence of information about the scoring system, subjects assign their confidence in multiple‐choice responses on the basis of the intuitively simplest payoff model, and that reliability decreases as scoring functions generate item scores which are progressively discrepant from scores generated by the simplest model. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987310050"
"SHOEMAKER D.M.","SHOEMAKER, DAVID M. (57029927000)","57029927000","ITEM‐EXAMINEE SAMPLING PROCEDURES AND ASSOCIATED STANDARD ERRORS IN ESTIMATING TEST PARAMETERS","1970","Journal of Educational Measurement","7","4","","255","262","7","11","10.1111/j.1745-3984.1970.tb00726.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84988134642&doi=10.1111%2fj.1745-3984.1970.tb00726.x&partnerID=40&md5=1c8d62db083c1b06a2a4ff26c9da80a2","Selected parameters for a negatively skewed and a normally distributed normative distribution were estimated in a post mortem item‐examinee sampling investigation. Manipulated systematically were number of subtests, number of items per subtest, and number of examinees responding to each sub‐test. Each item‐examinee sampling procedure was replicated five times. Defining one observation as the score received by one examinee on one item, the results of this investigation support the conclusion that, in estimating parameters by item‐examinee sampling, the variable of importance is not the item‐examinee sampling procedure but is instead the number of observations obtained by that procedure. Degree of skewness in the normative distribution and failure to distribute all items among subtests were found to be relatively unimportant variables. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84988134642"
"DIEDERICH P.B.","DIEDERICH, PAUL B. (57121855300)","57121855300","SHORTCUT ITEM‐TEST CORRELATIONS FOR TEACHER‐MADE TESTS","1970","Journal of Educational Measurement","7","1","","43","44","1","1","10.1111/j.1745-3984.1970.tb00692.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987378228&doi=10.1111%2fj.1745-3984.1970.tb00692.x&partnerID=40&md5=5171449907eab668ca0282d4a649aff2","The item‐test correlation is approximately equal to the difference between per‐cents correct in high and low groups, each including 27% of the students tested. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987378228"
"REA R.E.; REYS R.E.","REA, ROBERT E. (57191128648); REYS, ROBERT E. (6506874971)","57191128648; 6506874971","THE COMPREHENSIVE MATHEMATICS INVENTORY: AN EXPERIMENTAL INSTRUMENT FOR ASSESSING YOUNGSTERS ENTERING SCHOOL","1970","Journal of Educational Measurement","7","1","","45","47","2","0","10.1111/j.1745-3984.1970.tb00693.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987260677&doi=10.1111%2fj.1745-3984.1970.tb00693.x&partnerID=40&md5=16fa67dfd0610f191c357025e11992e7","Described is an instrument designed to measure quantitative ideas of young children in the areas of money, vocabulary, number, geometry, pattern identification, measurement, and recall. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987260677"
"BROWN S.R.","BROWN, STEVEN R. (55712917800)","55712917800","THE FORCED‐FREE DISTINCTION IN Q TECHNIQUE","1971","Journal of Educational Measurement","8","4","","283","287","4","45","10.1111/j.1745-3984.1971.tb00939.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0001298663&doi=10.1111%2fj.1745-3984.1971.tb00939.x&partnerID=40&md5=fccc8199ef8dc629bd4f9ccb0ecda0ce","Arguments favoring free‐ over forced‐distribution Q sorts have assumed that forcing leads to loss of important statistical information and interferes with interval properties, rendering Pearson's r inappropriate for analysis. Q sorts with identical item orderings but with varied distributions are shown to provide essentially the same correlations and factor structures when coefficients are computed using Spearman's rs, Kendall's τ, and Pearson's r, leading to the conclusion that the same results are obtained, despite distribution and whether interval or ordinal statistics are used. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0001298663"
"LUNNEY G.H.","LUNNEY, GERALD H. (7801432533)","7801432533","USING ANALYSIS OF VARIANCE WITH A DICHOTOMOUS DEPENDENT VARIABLE: AN EMPIRICAL STUDY","1970","Journal of Educational Measurement","7","4","","263","269","6","431","10.1111/j.1745-3984.1970.tb00727.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024987775&doi=10.1111%2fj.1745-3984.1970.tb00727.x&partnerID=40&md5=27d2191e3d687ff3b91a6e4f71a8a685","A study was conducted to determine if analysis of variance techniques are appropriate when the dependent variable has a dichotomous (zero‐one) distribution. Several 1‐, 2‐, and 3‐way analysis of variance configurations were investigated with regard to both the size of the Type I error and the Power. The findings show the analysis of variance to be an appropriate statistical technique for analyzing dichotomous data in fixed effects models where cell frequencies are equal under the following conditions: (a) the proportion of responses in the smaller response category is equal to or greater than .2 and there are at least 20 degrees of freedom for error, or (b) the proportion of responses in the smaller response category is less than .2 and there are at least 40 degrees of freedom for error. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024987775"
"SLAKTER M.J.; KOEHLER R.A.; HAMPTON S.H.","SLAKTER, MALCOLM J. (6603541799); KOEHLER, ROGER A. (57029863300); HAMPTON, SANDRA H. (57029969800)","6603541799; 57029863300; 57029969800","GRADE LEVEL, SEX, AND SELECTED ASPECTS OF TEST‐WISENESS","1970","Journal of Educational Measurement","7","2","","119","122","3","28","10.1111/j.1745-3984.1970.tb00705.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987349530&doi=10.1111%2fj.1745-3984.1970.tb00705.x&partnerID=40&md5=d2d977c9288767492a83ec010846ec03","Measures of four selected aspects of test‐wiseness (TW) were constructed for use in grades 5 through 11, and administered to students in two school systems. In each case the grade effects were significant at the .05 level, with a linear trend indicated. There was no evidence of sex, or sex by grade interaction effects. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987349530"
"JORGENSON D.O.","JORGENSON, DALE O. (7005755570)","7005755570","PREDICTION OF PREDICTABILITY IN THE MULTIVARIATE CASE","1970","Journal of Educational Measurement","7","3","","175","185","10","2","10.1111/j.1745-3984.1970.tb00714.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987344383&doi=10.1111%2fj.1745-3984.1970.tb00714.x&partnerID=40&md5=1a71cd47036f431f14e870267f56b1c1","110 Ss who completed Dunnette's Adjective Check List were randomly divided into a developmental sample (N = 58) and a cross‐validation sample (N = 52). Ss in the developmental sample were divided into two subgroups by means of Ghiselli's d score technique (difference between standard predictor and criterion scores). Three separate item analyses of the responses of Ss in three separate sets of high d score and low d score subgroups yielded three scales: (a) a univariate predictability scale for assessing predictive accuracy from one variable; (b) a moderator scale for determining which of two predictors would be more accurate for an S; (c) a multivariate predictability scale for assessing predictive accuracy from two predictor variables. The results seem to support the general hypothesis that it is possible to use a performance on a moderator or predictability scale to select a subgroup of Ss for whom correspondence between the predictor(s) and criterion is much greater than that of a subgroup whose scores on the moderator indicate a lesser degree of correspondence. All three scales held up in cross‐validation. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987344383"
"ROSENGARTEN W.","ROSENGARTEN, WILLIAM (57191126848)","57191126848","MEASURING FACULTY REACTION TO HOMOGENEOUS GROUPING","1970","Journal of Educational Measurement","7","2","","129","130","1","0","10.1111/j.1745-3984.1970.tb00707.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987325886&doi=10.1111%2fj.1745-3984.1970.tb00707.x&partnerID=40&md5=403fee69a1c45992b8ddc4bb3b0a77ce","A 6‐item instrument to estimate teacher reaction to homogeneous grouping is described. With slight changes in wording, its format can be adapted to evaluate opinion toward other educational practices. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987325886"
"WILBUR P.H.","WILBUR, PAUL H. (57189407794)","57189407794","POSITIONAL RESPONSE SET AMONG HIGH SCHOOL STUDENTS ON MULTIPLE‐CHOICE TESTS","1970","Journal of Educational Measurement","7","3","","161","163","2","4","10.1111/j.1745-3984.1970.tb00711.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987300044&doi=10.1111%2fj.1745-3984.1970.tb00711.x&partnerID=40&md5=52f36092d42b6359abf5aa759e54a35e","Investigations of positional response set in examinees of multiple‐choice items have shown conflicting results. This study attempted to clarify this controversy. Over 1000 subjects were assigned at random to one of nine forms of a specially prepared vocabulary test. The difference among forms related to the position of the correct answers and the most popular distractor as determined by prior administrations of the test. The forms of the test were constructed so that if a universal positional response set existed, it would manifest itself as a difference of means of scores obtained on selected items dispersed throughout each of the different forms. The results of the analysis of variance showed no significant evidence of interindividual positional response set. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987300044"
"TEMP G.","TEMP, GEORGE (57188914845)","57188914845","VALIDITY OF THE SAT FOR BLACKS AND WHITES IN THIRTEEN INTEGRATED INSTITUTIONS","1971","Journal of Educational Measurement","8","4","","245","251","6","29","10.1111/j.1745-3984.1971.tb00933.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-0000713520&doi=10.1111%2fj.1745-3984.1971.tb00933.x&partnerID=40&md5=25b8be918384513dfbb7ac0a491edf8e","Differential prediction for black and white students was empirically investigated at 13 institutions by comparison of regression planes. Particular attention was given to the possibility that prediction procedures that are appropriate for white (majority) students would underpredict the performance of black (minority) students. The data tend to support, among others, the following generalizations: (a) a single regression plane cannot be used to predict freshman GPA for both blacks and whites in 10 of the 13 institutions studied; nevertheless, (b) if prediction of GPA from SAT scores is based upon prediction equations suitable for majority students, then black students, as a group, are predicted to do about as well as (or better than) they actually do; but (c) the multiple regression (SAT‐V, M) prediction for blacks in 12 of the 13 institutions was lower in magnitude than for whites and was nonsignificant in 6 of the situations studied. Copyright © 1971, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-0000713520"
"POLLOCK M.B.","POLLOCK, MARION B. (7103186943)","7103186943","MOOD‐ALTERING SUBSTANCES: A BEHAVIOR INVENTORY","1970","Journal of Educational Measurement","7","3","","211","212","1","0","10.1111/j.1745-3984.1970.tb00719.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987350907&doi=10.1111%2fj.1745-3984.1970.tb00719.x&partnerID=40&md5=ea83b81433bcf7d193af701e223e7a9a","Described is a test designed to appraise the knowledge and actual practice of high school graduates concerning the use of mood‐altering substances. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987350907"
"GARDNER P.L.","GARDNER, P.L. (7201658481)","7201658481","TEST LENGTH AND THE STANDARD ERROR OF MEASUREMENT","1970","Journal of Educational Measurement","7","4","","271","273","2","6","10.1111/j.1745-3984.1970.tb00728.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-56649118590&doi=10.1111%2fj.1745-3984.1970.tb00728.x&partnerID=40&md5=cc4b5f97193fdba2a158909aa3f4dc04","Lord (1959) has shown that the standard error of measurement of a test is, for all practical purposes, directly proportional to the square root of the number of items on the test. More specifically, Lord found empirically that the standard error of a test was equal to . if the reliability of the test was computed by the Kuder‐Richardson (KR) 20 formula. If the KR‐21 formula was used, the standard error was equal to .. The present paper sets out to show how these relationships may be derived from the defining formulas of reliability and standard error of measurement, if certain simple assumptions about values of test statistics are made. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-56649118590"
"SMITH R.B.","SMITH, RICHARD B. (57190712777)","57190712777","AN EMPIRICAL INVESTIGATION OF COMPLEXITY AND PROCESS IN MULTIPLE‐CHOICE ITEMS","1970","Journal of Educational Measurement","7","1","","33","41","8","6","10.1111/j.1745-3984.1970.tb00691.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987263070&doi=10.1111%2fj.1745-3984.1970.tb00691.x&partnerID=40&md5=0b6d12b339636821888f24378dd9d04d","In this study hierarchical syndrome analysis was used to investigate empirically the clustering of tests each of which consisted of items based upon the rationale of a particular category of the Bloom Taxonomy (i.e., an “application” test, an “analysis” test, etc.). Each test included items related to eight physical science principles. Thus an attempt was made to hold the content as constant as possible and systematically vary process in the formation of the tests. The data indicate possible ways of combining Taxonomy item types based on the psychological distance between the categories. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987263070"
"BAIRD L.L.","BAIRD, LEONARD L. (16427085000)","16427085000","THE RELATION OF VOCATIONAL INTERESTS TO LIFE GOALS, SELF‐RATINGS OF ABILITY AND PERSONALITY TRAITS, AND POTENTIAL FOR ACHIEVEMENT","1970","Journal of Educational Measurement","7","4","","233","239","6","7","10.1111/j.1745-3984.1970.tb00723.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84965658008&doi=10.1111%2fj.1745-3984.1970.tb00723.x&partnerID=40&md5=985d15c19cf7c7a71e0a729e5cce23bb","In three analyses using canonical correlation, interests as measured by Holland's Vocational Preference Inventory, were related to (a) 35 life goals, (b) 31 self‐ratings of ability and personality traits, and (c) 22 scales measuring potentials for achievement. The sample consisted of 20,369 college freshmen in 37 institutions. Results are shown separately for males and females for five factors for each analysis. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84965658008"
"LEVINE H.G.; McGUIRE C.H.","LEVINE, HAROLD G. (7201737735); McGUIRE, CHRISTINE H. (7006340576)","7201737735; 7006340576","THE VALIDITY AND RELIABILITY OF ORAL EXAMINATIONS IN ASSESSING COGNITIVE SKILLS IN MEDICINE","1970","Journal of Educational Measurement","7","2","","63","74","11","37","10.1111/j.1745-3984.1970.tb00697.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987344300&doi=10.1111%2fj.1745-3984.1970.tb00697.x&partnerID=40&md5=cea6b2ecec082d5d5a7fc1954bf78ef8","In order to attempt to assess aspects of clinical competence, not adequately assessed by other means, the Center for the Study of Medical Education, University of Illinois College of Medicine together with the American Board of Orthopaedic Surgery developed oral examinations in formats specifically designed to yield information on high level cognitive functioning. The examinations were administered to 784 candidates for certification in January 1968. Reliability of the oral problem‐solving component score pooled from four examiners was approximately .50. Assessment of content, construct, and concurrent validity made by questionnaire and factor analytic studies indicated that the oral tests identified factors not measured by multiple‐choice tests and, therefore, significantly improved the relationship between supervisory evaluations and test scores. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987344300"
"HOGAN T.P.","HOGAN, THOMAS P. (57203054607)","57203054607","USING OLD SOCIOECONOMIC DATA FOR DEFINING NORM GROUPS","1970","Journal of Educational Measurement","7","4","","229","232","3","0","10.1111/j.1745-3984.1970.tb00722.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987306066&doi=10.1111%2fj.1745-3984.1970.tb00722.x&partnerID=40&md5=dbd0709d010b8127a7d0debbd657bb45","Socioeconomic data for communities are often used to define norm samples for tests. Standardization of the tests frequently occurs several years after the socioeconomic data are collected. Are the socioeconomic data sufficiently stable to be useful several years after they have been collected? To help answer this question, correlations were obtained between 1950 and 1960 census data for three socioeconomic variables for a sample of 200 communities. The socioeconomic data for 1950 and 1960 correlated approximately .90, indicating a high degree of relative stability over a 10‐year period. It was concluded that old socioeconomic data are useful for defining norm samples. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987306066"
"FISCHER F.E.","FISCHER, FREDERIC E. (57190055880)","57190055880","SOME PROPERTIES OF THE PERSONAL BISERIAL INDEX","1970","Journal of Educational Measurement","7","4","","275","277","2","1","10.1111/j.1745-3984.1970.tb00729.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85024997631&doi=10.1111%2fj.1745-3984.1970.tb00729.x&partnerID=40&md5=1b036d05a67774fd1e584f61f71f8be1","The personal biserial index is a correlation which measures the relationship between the difficulty of the items in a test for the person, as evidenced by his passes and failures, and the difficulty of the items, as evidenced by group‐determined item difficulties. Properties of the personal biserial index were studied empirically, including an examination of the reliability of the index and the effect of using the index as a predictor of college success. The findings include that the reliability of the index is quite low and that a knowledge of the index does not significantly increase the predictability of college success from SAT scores and high school averages. Evidence was provided which supports the hypothesis that the personal biserial index is sensitive to variations in the extent to which examinees guess. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-85024997631"
"SHOEMAKER D.M.","SHOEMAKER, DAVID M. (57029927000)","57029927000","ALLOCATION OF ITEMS AND EXAMINEES IN ESTIMATING A NORM DISTRIBUTION BY ITEM‐SAMPLING","1970","Journal of Educational Measurement","7","2","","123","128","5","13","10.1111/j.1745-3984.1970.tb00706.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987321949&doi=10.1111%2fj.1745-3984.1970.tb00706.x&partnerID=40&md5=79cb5b470698ddbe6f0f343b5422c332","A norm distribution consisting of test scores received by 810 college students on a 150 item dichotomously‐scored 4‐alternative multiple‐choice test was empirically estimated through several item‐examinee sampling procedures. The post mortum item‐sampling investigation was specifically designed to manipulate systematically the variables of number of subtests, number of items per subtest, and number of examinees responding to each subtest. Defining one observation as the score received by one examinee on one item, the results suggest that as the number of observations increases beyond 1.23% of the data base all procedures produce stochastically equivalent results. The results of this investigation indicate that, in estimating a norm distribution by item‐sampling, the variable of importance is not the item‐sampling procedure per se but is instead the number of observations obtained by the procedure. It should be noted, however, that in this investigation the test score norm distribution was approximately symmetrical and the possibility should not be overlooked that item‐sampling as a procedure may be robust only for symmetrical norm distributions. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987321949"
"REID J.C.","REID, J. CHRISTOPHER (7404548543)","7404548543","PRINTED COMMENTS WITH ITEM ANALYSES","1970","Journal of Educational Measurement","7","3","","159","160","1","0","10.1111/j.1745-3984.1970.tb00710.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987317317&doi=10.1111%2fj.1745-3984.1970.tb00710.x&partnerID=40&md5=dd9ee27fd2b3eaac6be71dbd33f20651","This article suggests that item analysis computer programs include, as an option, a printing of English comments alongside of the item statistics. The particular comments that appear for each item depend upon that item's statistics. These comments should provide clear directions to the classroom teacher for the improvement of the items, and they should be flexible to reflect the differing decisions required by norm‐referenced items and criterion‐referenced items. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987317317"
"HAMBLETON R.K.; ROBERTS D.M.; TRAUB R.E.","HAMBLETON, RONALD K. (7006242264); ROBERTS, DENNIS M. (55465556800); TRAUB, ROSS E. (7102034665)","7006242264; 55465556800; 7102034665","A COMPARISON OF THE RELIABILITY AND VALIDITY OF TWO METHODS FOR ASSESSING PARTIAL KNOWLEDGE ON A MULTIPLE‐CHOICE TEST","1970","Journal of Educational Measurement","7","2","","75","82","7","32","10.1111/j.1745-3984.1970.tb00698.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987318568&doi=10.1111%2fj.1745-3984.1970.tb00698.x&partnerID=40&md5=663174a4b1f88e75027fb8c749a38b20","Differential weighting of response alternatives and confidence testing have been proposed as ways to assess partial knowledge on multiple‐choice tests. 211 students in an educational measurement course took their midterm examination under one of three procedures. Results from those students administered the test under conventional directions provided a baseline for comparing, in terms of reliability and validity, the results from students who took the test under the differential weighting of response alternatives or the confidence testing instructions. Reliability was estimated by the split‐half technique. Validity was estimated by correlating midterm test scores with scores on a final examination. This investigation provides some support for the contention that validity can be improved using more sophisticated testing techniques. Suggestions for the conduct of more definitive studies were offered. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987318568"
"SPENCER R.E.; ALEAMONI L.M.","SPENCER, RICHARD E. (57189188396); ALEAMONI, LAWRENCE M. (8252944000)","57189188396; 8252944000","A STUDENT COURSE EVALUATION QUESTIONNAIRE","1970","Journal of Educational Measurement","7","3","","209","210","1","11","10.1111/j.1745-3984.1970.tb00718.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987378253&doi=10.1111%2fj.1745-3984.1970.tb00718.x&partnerID=40&md5=a77b3b9f05106ba641e3cee81b8bb157","A student course evaluation questionnaire, based upon 50 items and used at 13 different institutions, is described. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987378253"
"KEENEN C.B.; HOLMES J.E.","KEENEN, CHARLES B. (57025019500); HOLMES, JUNE E. (25952466600)","57025019500; 25952466600","PREDICTING GRADUATION WITHDRAWAL AND FAILURE IN COLLEGE BY MULTIPLE DISCRIMINANT ANALYSIS","1970","Journal of Educational Measurement","7","2","","91","95","4","4","10.1111/j.1745-3984.1970.tb00701.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70350082007&doi=10.1111%2fj.1745-3984.1970.tb00701.x&partnerID=40&md5=2ccea51dd151efb7536ed10845a3f6c7","An illustration of using multiple discriminant analysis and nonintellective data in predicting graduation, withdrawal and failure in a college of liberal arts. The nonintellective factors are qualitative content categories derived from candidates' personal application statements. Procedures are described for comparing the effectiveness of the nonintellective data with that of intellective data in differentiating among the three criterion groups and on accuracy of predicted group membership. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-70350082007"
"CARVER R.P.","CARVER, RONALD P. (7005570366)","7005570366","REJOINDER TO KNAPP'S NOTE","1970","Journal of Educational Measurement","7","1","","52","52","0","0","10.1111/j.1745-3984.1970.tb00696.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987260420&doi=10.1111%2fj.1745-3984.1970.tb00696.x&partnerID=40&md5=e6480b7f0e8c504c2233a1bea3fbcdca","Although the expression cited by Knapp () is the way to calculate amount learned within the confines of the specific mathematical formulas presented by Carver, the opinion was expressed that f (final test score) would remain one of the best indicants of amount learned under other hypothesized curvilinear models. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987260420"
"MARSO R.N.","MARSO, RONALD N. (6507581256)","6507581256","TEST ITEM ARRANGEMENT, TESTING TIME, AND PERFORMANCE","1970","Journal of Educational Measurement","7","2","","113","118","5","28","10.1111/j.1745-3984.1970.tb00704.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987260745&doi=10.1111%2fj.1745-3984.1970.tb00704.x&partnerID=40&md5=1e4319d622def2e1e750624dbc6ed2a1","Two experiments were conducted to determine if a relationship exists between test item arrangements and student performance on power tests. The primary hypotheses were: item arrangements based upon item difficulty, similarity of content, or order of class presentation do not influence test score or required testing time. In the first experiment 122 subjects were randomly assigned to three item difficulty arrangements of 139 test items with a 0–100% difficulty range, and in the second experiment 156 subjects were randomly assigned to three item content arrangements of 103 items. Results of analyses of variance with test anxiety used as a classification factor supported the hypotheses. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987260745"
"DIELMAN T.E.; WILSON W.R.","DIELMAN, T.E. (7003947477); WILSON, WARNER R. (25954978100)","7003947477; 25954978100","CONVERGENT AND DISCRIMINANT VALIDITY OF THREE MEASURES OF ABILITY, ASPIRATION‐LEVEL, ACHIEVEMENT, ADJUSTMENT AND DOMINANCE","1970","Journal of Educational Measurement","7","3","","185","190","5","2","10.1111/j.1745-3984.1970.tb00715.x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84987355478&doi=10.1111%2fj.1745-3984.1970.tb00715.x&partnerID=40&md5=9a211773fefee613dff3930efe023f02","The convergent and discriminant validity of three measures of the concepts of aspiration level, ability, achievement, adjustment, and dominance were examined in the context of a multitrait‐multimethod matrix. Self‐reports and peer‐reports on 75 Ss were employed as two measures of each trait. In addition, aspiration level was measured by the Edwards Personal Preference Schedule (EPPS) Nach scale, dominance by the EPPS (dom scale), achievement by cumulative college grade point ratio (GPR), ability by the Ohio State Psychological Examination (OSPE), and adjustment by the Bell Adjustment Inventory. Of the paper and pencil instruments, only the OSPE and EPPS (dominance scale) exhibited satisfactory convergent validity. No measure met all the requirements of discriminant validity. The desirability of establishing adequate validational evidence prior to using “trait” measures in studies relating theoretical variables was emphasized. Copyright © 1970, Wiley Blackwell. All rights reserved","","","Article","Final","","Scopus","2-s2.0-84987355478"
